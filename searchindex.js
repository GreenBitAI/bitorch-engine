Search.setIndex({"docnames": ["_autosummary/bitorch_engine", "_autosummary/bitorch_engine.functions", "_autosummary/bitorch_engine.functions.cuda", "_autosummary/bitorch_engine.functions.cuda.extension", "_autosummary/bitorch_engine.functions.cuda.extension.get_ext", "_autosummary/bitorch_engine.functions.cuda.functions", "_autosummary/bitorch_engine.functions.cuda.functions.fp32toint4", "_autosummary/bitorch_engine.functions.cuda.functions.q4_pack_tensor", "_autosummary/bitorch_engine.functions.cuda.functions.q4_unpack_and_scaling_tensor", "_autosummary/bitorch_engine.functions.cuda.functions.q4_unpack_tensor", "_autosummary/bitorch_engine.functions.cuda.functions.tensor_to_packed_uint8", "_autosummary/bitorch_engine.functions.cuda.functions.unpack_uint8_tensor", "_autosummary/bitorch_engine.layers", "_autosummary/bitorch_engine.layers.qconv", "_autosummary/bitorch_engine.layers.qconv.binary", "_autosummary/bitorch_engine.layers.qconv.binary.cpp", "_autosummary/bitorch_engine.layers.qconv.binary.cpp.extension", "_autosummary/bitorch_engine.layers.qconv.binary.cpp.extension.get_ext", "_autosummary/bitorch_engine.layers.qconv.binary.cpp.layer", "_autosummary/bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP", "_autosummary/bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dForward", "_autosummary/bitorch_engine.layers.qconv.binary.cutlass", "_autosummary/bitorch_engine.layers.qconv.binary.cutlass.extension", "_autosummary/bitorch_engine.layers.qconv.binary.cutlass.extension.get_ext", "_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer", "_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass", "_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dForward", "_autosummary/bitorch_engine.layers.qconv.binary.layer", "_autosummary/bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase", "_autosummary/bitorch_engine.layers.qconv.binary.layer.BinaryConvParameter", "_autosummary/bitorch_engine.layers.qconv.nbit", "_autosummary/bitorch_engine.layers.qconv.nbit.cutlass", "_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.extension", "_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.extension.get_ext", "_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer", "_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass", "_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward", "_autosummary/bitorch_engine.layers.qconv.nbit.layer", "_autosummary/bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase", "_autosummary/bitorch_engine.layers.qconv.nbit.layer.nBitConvParameter", "_autosummary/bitorch_engine.layers.qembedding", "_autosummary/bitorch_engine.layers.qembedding.binary", "_autosummary/bitorch_engine.layers.qembedding.binary.layer", "_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag", "_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward", "_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda", "_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingForward", "_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingParameter", "_autosummary/bitorch_engine.layers.qlinear", "_autosummary/bitorch_engine.layers.qlinear.binary", "_autosummary/bitorch_engine.layers.qlinear.binary.binary_implementation", "_autosummary/bitorch_engine.layers.qlinear.binary.binary_implementation.BinaryLinearImplementationMixin", "_autosummary/bitorch_engine.layers.qlinear.binary.cpp", "_autosummary/bitorch_engine.layers.qlinear.binary.cpp.extension", "_autosummary/bitorch_engine.layers.qlinear.binary.cpp.extension.get_ext", "_autosummary/bitorch_engine.layers.qlinear.binary.cpp.layer", "_autosummary/bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP", "_autosummary/bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearForward", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.bmm", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.extension", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.extension.get_ext", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.extension", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.extension.get_ext", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMulFunction", "_autosummary/bitorch_engine.layers.qlinear.binary.get_best_binary_implementation", "_autosummary/bitorch_engine.layers.qlinear.binary.layer", "_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase", "_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearParameter", "_autosummary/bitorch_engine.layers.qlinear.layer", "_autosummary/bitorch_engine.layers.qlinear.layer.QLinearInf", "_autosummary/bitorch_engine.layers.qlinear.nbit", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.extension", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.extension.get_ext", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCudaFunction", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.utils", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.utils.make_group_map", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.utils.pack_fp_weight", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.utils.unpack_qweight", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.extension", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.extension.get_ext", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearFunction", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMulFunction", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearFunction", "_autosummary/bitorch_engine.layers.qlinear.nbit.layer", "_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase", "_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter", "_autosummary/bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase", "_autosummary/bitorch_engine.layers.qlinear.nbit.layer.nBitLinearParameter", "_autosummary/bitorch_engine.layers.qlinear.nbit.mps", "_autosummary/bitorch_engine.layers.qlinear.nbit.mps.extension", "_autosummary/bitorch_engine.layers.qlinear.nbit.mps.extension.get_ext", "_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer", "_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx", "_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlxFunction", "_autosummary/bitorch_engine.layers.qlinear.qlinear_implementation", "_autosummary/bitorch_engine.layers.qlinear.qlinear_implementation.QLinearImplementationMixin", "_autosummary/bitorch_engine.layers.qmha", "_autosummary/bitorch_engine.layers.qmha.binary", "_autosummary/bitorch_engine.layers.qmha.binary.layer", "_autosummary/bitorch_engine.layers.qmha.binary.layer.BMHA", "_autosummary/bitorch_engine.layers.qmha.binary.layer.LearnableBias", "_autosummary/bitorch_engine.optim", "_autosummary/bitorch_engine.optim.diode_beta", "_autosummary/bitorch_engine.optim.diode_beta.DiodeMix", "_autosummary/bitorch_engine.optim.diode_beta.check_pytorch_version", "_autosummary/bitorch_engine.optim.galore_projector", "_autosummary/bitorch_engine.optim.galore_projector.GaLoreProjector", "_autosummary/bitorch_engine.utils", "_autosummary/bitorch_engine.utils.arch_helper", "_autosummary/bitorch_engine.utils.arch_helper.ARCH_CPU", "_autosummary/bitorch_engine.utils.arch_helper.check_cpu_instruction_support", "_autosummary/bitorch_engine.utils.arch_helper.linux_arch_ident", "_autosummary/bitorch_engine.utils.convert", "_autosummary/bitorch_engine.utils.convert.collect_layers", "_autosummary/bitorch_engine.utils.convert.get_mpq_config", "_autosummary/bitorch_engine.utils.convert.quantize_linear_with_binary_linear_cuda", "_autosummary/bitorch_engine.utils.convert.quantize_linear_with_mpq_linear_cuda", "_autosummary/bitorch_engine.utils.convert.quantize_linear_with_q4_linear_cutlass", "_autosummary/bitorch_engine.utils.convert.replace_layers", "_autosummary/bitorch_engine.utils.cpp_extension", "_autosummary/bitorch_engine.utils.cpp_extension.get_cpp_extension", "_autosummary/bitorch_engine.utils.cpp_extension.get_kwargs", "_autosummary/bitorch_engine.utils.cuda_extension", "_autosummary/bitorch_engine.utils.cuda_extension.gcc_version", "_autosummary/bitorch_engine.utils.cuda_extension.get_cuda_arch", "_autosummary/bitorch_engine.utils.cuda_extension.get_cuda_extension", "_autosummary/bitorch_engine.utils.cuda_extension.get_kwargs", "_autosummary/bitorch_engine.utils.cutlass_path", "_autosummary/bitorch_engine.utils.cutlass_path.check_path", "_autosummary/bitorch_engine.utils.cutlass_path.find_cutlass", "_autosummary/bitorch_engine.utils.cutlass_path.get_cutlass_include_path", "_autosummary/bitorch_engine.utils.cutlass_path.is_cutlass_available", "_autosummary/bitorch_engine.utils.mlx_extension", "_autosummary/bitorch_engine.utils.mlx_extension.get_mlx_extension", "_autosummary/bitorch_engine.utils.mlx_path", "_autosummary/bitorch_engine.utils.mlx_path.get_mlx_include_path", "_autosummary/bitorch_engine.utils.mlx_path.get_mlx_lib_path", "_autosummary/bitorch_engine.utils.mlx_path.is_mlx_available", "_autosummary/bitorch_engine.utils.model_helper", "_autosummary/bitorch_engine.utils.model_helper.binary_matmul_forward_post_processing", "_autosummary/bitorch_engine.utils.model_helper.flatten_x", "_autosummary/bitorch_engine.utils.model_helper.init_weight", "_autosummary/bitorch_engine.utils.model_helper.load_checkpoint", "_autosummary/bitorch_engine.utils.model_helper.pack_bie_layers", "_autosummary/bitorch_engine.utils.model_helper.pad_embedding_dim", "_autosummary/bitorch_engine.utils.model_helper.pad_last_2_dims_to_multiple_of_128", "_autosummary/bitorch_engine.utils.model_helper.prepare_bie_layers", "_autosummary/bitorch_engine.utils.model_helper.qweight_update_fn", "_autosummary/bitorch_engine.utils.model_helper.save_checkpoint", "_autosummary/bitorch_engine.utils.model_helper.unflatten_x", "_autosummary/bitorch_engine.utils.model_helper.update_zeros", "_autosummary/bitorch_engine.utils.quant_operators", "_autosummary/bitorch_engine.utils.quant_operators.bit_set", "_autosummary/bitorch_engine.utils.quant_operators.get_binary_col", "_autosummary/bitorch_engine.utils.quant_operators.get_binary_row", "_autosummary/bitorch_engine.utils.quant_operators.gptq_style_unpacking", "_autosummary/bitorch_engine.utils.quant_operators.gptq_style_zeros_packing", "_autosummary/bitorch_engine.utils.quant_operators.nv_tensor_quant", "_autosummary/bitorch_engine.utils.quant_operators.q4_quantization", "_autosummary/bitorch_engine.utils.quant_operators.q8_quantization", "_autosummary/bitorch_engine.utils.safe_import", "_autosummary/bitorch_engine.utils.safe_import.ExtensionModulePlaceholder", "_autosummary/bitorch_engine.utils.safe_import.import_extension", "build_options", "documentation", "index", "installation"], "filenames": ["_autosummary/bitorch_engine.rst", "_autosummary/bitorch_engine.functions.rst", "_autosummary/bitorch_engine.functions.cuda.rst", "_autosummary/bitorch_engine.functions.cuda.extension.rst", "_autosummary/bitorch_engine.functions.cuda.extension.get_ext.rst", "_autosummary/bitorch_engine.functions.cuda.functions.rst", "_autosummary/bitorch_engine.functions.cuda.functions.fp32toint4.rst", "_autosummary/bitorch_engine.functions.cuda.functions.q4_pack_tensor.rst", "_autosummary/bitorch_engine.functions.cuda.functions.q4_unpack_and_scaling_tensor.rst", "_autosummary/bitorch_engine.functions.cuda.functions.q4_unpack_tensor.rst", "_autosummary/bitorch_engine.functions.cuda.functions.tensor_to_packed_uint8.rst", "_autosummary/bitorch_engine.functions.cuda.functions.unpack_uint8_tensor.rst", "_autosummary/bitorch_engine.layers.rst", "_autosummary/bitorch_engine.layers.qconv.rst", "_autosummary/bitorch_engine.layers.qconv.binary.rst", "_autosummary/bitorch_engine.layers.qconv.binary.cpp.rst", "_autosummary/bitorch_engine.layers.qconv.binary.cpp.extension.rst", "_autosummary/bitorch_engine.layers.qconv.binary.cpp.extension.get_ext.rst", "_autosummary/bitorch_engine.layers.qconv.binary.cpp.layer.rst", "_autosummary/bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP.rst", "_autosummary/bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dForward.rst", "_autosummary/bitorch_engine.layers.qconv.binary.cutlass.rst", "_autosummary/bitorch_engine.layers.qconv.binary.cutlass.extension.rst", "_autosummary/bitorch_engine.layers.qconv.binary.cutlass.extension.get_ext.rst", "_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer.rst", "_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.rst", "_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dForward.rst", "_autosummary/bitorch_engine.layers.qconv.binary.layer.rst", "_autosummary/bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.rst", "_autosummary/bitorch_engine.layers.qconv.binary.layer.BinaryConvParameter.rst", "_autosummary/bitorch_engine.layers.qconv.nbit.rst", "_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.rst", "_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.extension.rst", "_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.extension.get_ext.rst", "_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer.rst", "_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.rst", "_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward.rst", "_autosummary/bitorch_engine.layers.qconv.nbit.layer.rst", "_autosummary/bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.rst", "_autosummary/bitorch_engine.layers.qconv.nbit.layer.nBitConvParameter.rst", "_autosummary/bitorch_engine.layers.qembedding.rst", "_autosummary/bitorch_engine.layers.qembedding.binary.rst", "_autosummary/bitorch_engine.layers.qembedding.binary.layer.rst", "_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.rst", "_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward.rst", "_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.rst", "_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingForward.rst", "_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingParameter.rst", "_autosummary/bitorch_engine.layers.qlinear.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.binary_implementation.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.binary_implementation.BinaryLinearImplementationMixin.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cpp.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cpp.extension.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cpp.extension.get_ext.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cpp.layer.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearForward.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.bmm.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.extension.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.extension.get_ext.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.extension.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.extension.get_ext.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMulFunction.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.get_best_binary_implementation.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.layer.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearParameter.rst", "_autosummary/bitorch_engine.layers.qlinear.layer.rst", "_autosummary/bitorch_engine.layers.qlinear.layer.QLinearInf.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.extension.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.extension.get_ext.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCudaFunction.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.utils.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.utils.make_group_map.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.utils.pack_fp_weight.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.utils.unpack_qweight.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.extension.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.extension.get_ext.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearFunction.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMulFunction.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearFunction.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.layer.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.layer.nBitLinearParameter.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.mps.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.mps.extension.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.mps.extension.get_ext.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlxFunction.rst", "_autosummary/bitorch_engine.layers.qlinear.qlinear_implementation.rst", "_autosummary/bitorch_engine.layers.qlinear.qlinear_implementation.QLinearImplementationMixin.rst", "_autosummary/bitorch_engine.layers.qmha.rst", "_autosummary/bitorch_engine.layers.qmha.binary.rst", "_autosummary/bitorch_engine.layers.qmha.binary.layer.rst", "_autosummary/bitorch_engine.layers.qmha.binary.layer.BMHA.rst", "_autosummary/bitorch_engine.layers.qmha.binary.layer.LearnableBias.rst", "_autosummary/bitorch_engine.optim.rst", "_autosummary/bitorch_engine.optim.diode_beta.rst", "_autosummary/bitorch_engine.optim.diode_beta.DiodeMix.rst", "_autosummary/bitorch_engine.optim.diode_beta.check_pytorch_version.rst", "_autosummary/bitorch_engine.optim.galore_projector.rst", "_autosummary/bitorch_engine.optim.galore_projector.GaLoreProjector.rst", "_autosummary/bitorch_engine.utils.rst", "_autosummary/bitorch_engine.utils.arch_helper.rst", "_autosummary/bitorch_engine.utils.arch_helper.ARCH_CPU.rst", "_autosummary/bitorch_engine.utils.arch_helper.check_cpu_instruction_support.rst", "_autosummary/bitorch_engine.utils.arch_helper.linux_arch_ident.rst", "_autosummary/bitorch_engine.utils.convert.rst", "_autosummary/bitorch_engine.utils.convert.collect_layers.rst", "_autosummary/bitorch_engine.utils.convert.get_mpq_config.rst", "_autosummary/bitorch_engine.utils.convert.quantize_linear_with_binary_linear_cuda.rst", "_autosummary/bitorch_engine.utils.convert.quantize_linear_with_mpq_linear_cuda.rst", "_autosummary/bitorch_engine.utils.convert.quantize_linear_with_q4_linear_cutlass.rst", "_autosummary/bitorch_engine.utils.convert.replace_layers.rst", "_autosummary/bitorch_engine.utils.cpp_extension.rst", "_autosummary/bitorch_engine.utils.cpp_extension.get_cpp_extension.rst", "_autosummary/bitorch_engine.utils.cpp_extension.get_kwargs.rst", "_autosummary/bitorch_engine.utils.cuda_extension.rst", "_autosummary/bitorch_engine.utils.cuda_extension.gcc_version.rst", "_autosummary/bitorch_engine.utils.cuda_extension.get_cuda_arch.rst", "_autosummary/bitorch_engine.utils.cuda_extension.get_cuda_extension.rst", "_autosummary/bitorch_engine.utils.cuda_extension.get_kwargs.rst", "_autosummary/bitorch_engine.utils.cutlass_path.rst", "_autosummary/bitorch_engine.utils.cutlass_path.check_path.rst", "_autosummary/bitorch_engine.utils.cutlass_path.find_cutlass.rst", "_autosummary/bitorch_engine.utils.cutlass_path.get_cutlass_include_path.rst", "_autosummary/bitorch_engine.utils.cutlass_path.is_cutlass_available.rst", "_autosummary/bitorch_engine.utils.mlx_extension.rst", "_autosummary/bitorch_engine.utils.mlx_extension.get_mlx_extension.rst", "_autosummary/bitorch_engine.utils.mlx_path.rst", "_autosummary/bitorch_engine.utils.mlx_path.get_mlx_include_path.rst", "_autosummary/bitorch_engine.utils.mlx_path.get_mlx_lib_path.rst", "_autosummary/bitorch_engine.utils.mlx_path.is_mlx_available.rst", "_autosummary/bitorch_engine.utils.model_helper.rst", "_autosummary/bitorch_engine.utils.model_helper.binary_matmul_forward_post_processing.rst", "_autosummary/bitorch_engine.utils.model_helper.flatten_x.rst", "_autosummary/bitorch_engine.utils.model_helper.init_weight.rst", "_autosummary/bitorch_engine.utils.model_helper.load_checkpoint.rst", "_autosummary/bitorch_engine.utils.model_helper.pack_bie_layers.rst", "_autosummary/bitorch_engine.utils.model_helper.pad_embedding_dim.rst", "_autosummary/bitorch_engine.utils.model_helper.pad_last_2_dims_to_multiple_of_128.rst", "_autosummary/bitorch_engine.utils.model_helper.prepare_bie_layers.rst", "_autosummary/bitorch_engine.utils.model_helper.qweight_update_fn.rst", "_autosummary/bitorch_engine.utils.model_helper.save_checkpoint.rst", "_autosummary/bitorch_engine.utils.model_helper.unflatten_x.rst", "_autosummary/bitorch_engine.utils.model_helper.update_zeros.rst", "_autosummary/bitorch_engine.utils.quant_operators.rst", "_autosummary/bitorch_engine.utils.quant_operators.bit_set.rst", "_autosummary/bitorch_engine.utils.quant_operators.get_binary_col.rst", "_autosummary/bitorch_engine.utils.quant_operators.get_binary_row.rst", "_autosummary/bitorch_engine.utils.quant_operators.gptq_style_unpacking.rst", "_autosummary/bitorch_engine.utils.quant_operators.gptq_style_zeros_packing.rst", "_autosummary/bitorch_engine.utils.quant_operators.nv_tensor_quant.rst", "_autosummary/bitorch_engine.utils.quant_operators.q4_quantization.rst", "_autosummary/bitorch_engine.utils.quant_operators.q8_quantization.rst", "_autosummary/bitorch_engine.utils.safe_import.rst", "_autosummary/bitorch_engine.utils.safe_import.ExtensionModulePlaceholder.rst", "_autosummary/bitorch_engine.utils.safe_import.import_extension.rst", "build_options.rst", "documentation.rst", "index.rst", "installation.rst"], "titles": ["bitorch_engine", "bitorch_engine.functions", "bitorch_engine.functions.cuda", "bitorch_engine.functions.cuda.extension", "bitorch_engine.functions.cuda.extension.get_ext", "bitorch_engine.functions.cuda.functions", "bitorch_engine.functions.cuda.functions.fp32toint4", "bitorch_engine.functions.cuda.functions.q4_pack_tensor", "bitorch_engine.functions.cuda.functions.q4_unpack_and_scaling_tensor", "bitorch_engine.functions.cuda.functions.q4_unpack_tensor", "bitorch_engine.functions.cuda.functions.tensor_to_packed_uint8", "bitorch_engine.functions.cuda.functions.unpack_uint8_tensor", "bitorch_engine.layers", "bitorch_engine.layers.qconv", "bitorch_engine.layers.qconv.binary", "bitorch_engine.layers.qconv.binary.cpp", "bitorch_engine.layers.qconv.binary.cpp.extension", "bitorch_engine.layers.qconv.binary.cpp.extension.get_ext", "bitorch_engine.layers.qconv.binary.cpp.layer", "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP", "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dForward", "bitorch_engine.layers.qconv.binary.cutlass", "bitorch_engine.layers.qconv.binary.cutlass.extension", "bitorch_engine.layers.qconv.binary.cutlass.extension.get_ext", "bitorch_engine.layers.qconv.binary.cutlass.layer", "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass", "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dForward", "bitorch_engine.layers.qconv.binary.layer", "bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase", "bitorch_engine.layers.qconv.binary.layer.BinaryConvParameter", "bitorch_engine.layers.qconv.nbit", "bitorch_engine.layers.qconv.nbit.cutlass", "bitorch_engine.layers.qconv.nbit.cutlass.extension", "bitorch_engine.layers.qconv.nbit.cutlass.extension.get_ext", "bitorch_engine.layers.qconv.nbit.cutlass.layer", "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass", "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward", "bitorch_engine.layers.qconv.nbit.layer", "bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase", "bitorch_engine.layers.qconv.nbit.layer.nBitConvParameter", "bitorch_engine.layers.qembedding", "bitorch_engine.layers.qembedding.binary", "bitorch_engine.layers.qembedding.binary.layer", "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag", "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward", "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda", "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingForward", "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingParameter", "bitorch_engine.layers.qlinear", "bitorch_engine.layers.qlinear.binary", "bitorch_engine.layers.qlinear.binary.binary_implementation", "bitorch_engine.layers.qlinear.binary.binary_implementation.BinaryLinearImplementationMixin", "bitorch_engine.layers.qlinear.binary.cpp", "bitorch_engine.layers.qlinear.binary.cpp.extension", "bitorch_engine.layers.qlinear.binary.cpp.extension.get_ext", "bitorch_engine.layers.qlinear.binary.cpp.layer", "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP", "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearForward", "bitorch_engine.layers.qlinear.binary.cuda", "bitorch_engine.layers.qlinear.binary.cuda.bmm", "bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM", "bitorch_engine.layers.qlinear.binary.cuda.extension", "bitorch_engine.layers.qlinear.binary.cuda.extension.get_ext", "bitorch_engine.layers.qlinear.binary.cuda.layer", "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda", "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward", "bitorch_engine.layers.qlinear.binary.cutlass", "bitorch_engine.layers.qlinear.binary.cutlass.extension", "bitorch_engine.layers.qlinear.binary.cutlass.extension.get_ext", "bitorch_engine.layers.qlinear.binary.cutlass.layer", "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass", "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward", "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul", "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMulFunction", "bitorch_engine.layers.qlinear.binary.get_best_binary_implementation", "bitorch_engine.layers.qlinear.binary.layer", "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase", "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearParameter", "bitorch_engine.layers.qlinear.layer", "bitorch_engine.layers.qlinear.layer.QLinearInf", "bitorch_engine.layers.qlinear.nbit", "bitorch_engine.layers.qlinear.nbit.cuda", "bitorch_engine.layers.qlinear.nbit.cuda.extension", "bitorch_engine.layers.qlinear.nbit.cuda.extension.get_ext", "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer", "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda", "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction", "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer", "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda", "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCudaFunction", "bitorch_engine.layers.qlinear.nbit.cuda.utils", "bitorch_engine.layers.qlinear.nbit.cuda.utils.make_group_map", "bitorch_engine.layers.qlinear.nbit.cuda.utils.pack_fp_weight", "bitorch_engine.layers.qlinear.nbit.cuda.utils.unpack_qweight", "bitorch_engine.layers.qlinear.nbit.cutlass", "bitorch_engine.layers.qlinear.nbit.cutlass.extension", "bitorch_engine.layers.qlinear.nbit.cutlass.extension.get_ext", "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer", "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass", "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearFunction", "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul", "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMulFunction", "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer", "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass", "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearFunction", "bitorch_engine.layers.qlinear.nbit.layer", "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase", "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter", "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase", "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearParameter", "bitorch_engine.layers.qlinear.nbit.mps", "bitorch_engine.layers.qlinear.nbit.mps.extension", "bitorch_engine.layers.qlinear.nbit.mps.extension.get_ext", "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer", "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx", "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlxFunction", "bitorch_engine.layers.qlinear.qlinear_implementation", "bitorch_engine.layers.qlinear.qlinear_implementation.QLinearImplementationMixin", "bitorch_engine.layers.qmha", "bitorch_engine.layers.qmha.binary", "bitorch_engine.layers.qmha.binary.layer", "bitorch_engine.layers.qmha.binary.layer.BMHA", "bitorch_engine.layers.qmha.binary.layer.LearnableBias", "bitorch_engine.optim", "bitorch_engine.optim.diode_beta", "bitorch_engine.optim.diode_beta.DiodeMix", "bitorch_engine.optim.diode_beta.check_pytorch_version", "bitorch_engine.optim.galore_projector", "bitorch_engine.optim.galore_projector.GaLoreProjector", "bitorch_engine.utils", "bitorch_engine.utils.arch_helper", "bitorch_engine.utils.arch_helper.ARCH_CPU", "bitorch_engine.utils.arch_helper.check_cpu_instruction_support", "bitorch_engine.utils.arch_helper.linux_arch_ident", "bitorch_engine.utils.convert", "bitorch_engine.utils.convert.collect_layers", "bitorch_engine.utils.convert.get_mpq_config", "bitorch_engine.utils.convert.quantize_linear_with_binary_linear_cuda", "bitorch_engine.utils.convert.quantize_linear_with_mpq_linear_cuda", "bitorch_engine.utils.convert.quantize_linear_with_q4_linear_cutlass", "bitorch_engine.utils.convert.replace_layers", "bitorch_engine.utils.cpp_extension", "bitorch_engine.utils.cpp_extension.get_cpp_extension", "bitorch_engine.utils.cpp_extension.get_kwargs", "bitorch_engine.utils.cuda_extension", "bitorch_engine.utils.cuda_extension.gcc_version", "bitorch_engine.utils.cuda_extension.get_cuda_arch", "bitorch_engine.utils.cuda_extension.get_cuda_extension", "bitorch_engine.utils.cuda_extension.get_kwargs", "bitorch_engine.utils.cutlass_path", "bitorch_engine.utils.cutlass_path.check_path", "bitorch_engine.utils.cutlass_path.find_cutlass", "bitorch_engine.utils.cutlass_path.get_cutlass_include_path", "bitorch_engine.utils.cutlass_path.is_cutlass_available", "bitorch_engine.utils.mlx_extension", "bitorch_engine.utils.mlx_extension.get_mlx_extension", "bitorch_engine.utils.mlx_path", "bitorch_engine.utils.mlx_path.get_mlx_include_path", "bitorch_engine.utils.mlx_path.get_mlx_lib_path", "bitorch_engine.utils.mlx_path.is_mlx_available", "bitorch_engine.utils.model_helper", "bitorch_engine.utils.model_helper.binary_matmul_forward_post_processing", "bitorch_engine.utils.model_helper.flatten_x", "bitorch_engine.utils.model_helper.init_weight", "bitorch_engine.utils.model_helper.load_checkpoint", "bitorch_engine.utils.model_helper.pack_bie_layers", "bitorch_engine.utils.model_helper.pad_embedding_dim", "bitorch_engine.utils.model_helper.pad_last_2_dims_to_multiple_of_128", "bitorch_engine.utils.model_helper.prepare_bie_layers", "bitorch_engine.utils.model_helper.qweight_update_fn", "bitorch_engine.utils.model_helper.save_checkpoint", "bitorch_engine.utils.model_helper.unflatten_x", "bitorch_engine.utils.model_helper.update_zeros", "bitorch_engine.utils.quant_operators", "bitorch_engine.utils.quant_operators.bit_set", "bitorch_engine.utils.quant_operators.get_binary_col", "bitorch_engine.utils.quant_operators.get_binary_row", "bitorch_engine.utils.quant_operators.gptq_style_unpacking", "bitorch_engine.utils.quant_operators.gptq_style_zeros_packing", "bitorch_engine.utils.quant_operators.nv_tensor_quant", "bitorch_engine.utils.quant_operators.q4_quantization", "bitorch_engine.utils.quant_operators.q8_quantization", "bitorch_engine.utils.safe_import", "bitorch_engine.utils.safe_import.ExtensionModulePlaceholder", "bitorch_engine.utils.safe_import.import_extension", "Build options", "Full Documentation", "Welcome to Bitorch Engine\u2019s documentation!", "Installation"], "terms": {"modul": [0, 1, 2, 8, 9, 12, 13, 14, 15, 21, 30, 31, 38, 40, 41, 43, 45, 48, 49, 52, 54, 58, 62, 66, 72, 80, 81, 83, 94, 100, 108, 110, 118, 119, 121, 122, 123, 129, 135, 137, 138, 139, 140, 164, 165, 168, 170, 183, 184, 187], "path": [4, 17, 23, 33, 54, 62, 68, 83, 96, 112, 142, 147, 148, 150, 151, 155, 157, 158, 159, 164, 170, 185, 188], "sourc": [4, 6, 7, 8, 9, 10, 11, 17, 19, 20, 23, 25, 26, 28, 29, 33, 35, 36, 38, 39, 43, 44, 45, 46, 47, 51, 54, 56, 57, 60, 62, 64, 65, 68, 70, 71, 72, 73, 74, 76, 77, 79, 83, 85, 86, 88, 89, 91, 92, 93, 96, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 112, 114, 115, 117, 121, 122, 125, 126, 128, 131, 132, 133, 135, 136, 137, 138, 139, 140, 142, 143, 145, 146, 147, 148, 150, 151, 152, 153, 155, 157, 158, 159, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 187], "gener": [4, 19, 25, 28, 38, 45, 56, 64, 79, 91, 106, 108, 143, 148], "specifi": [4, 33, 43, 45, 47, 51, 64, 70, 76, 79, 85, 88, 99, 114, 121, 126, 148, 151, 155, 157, 158, 161, 165, 168, 174, 176, 179, 183, 188], "paramet": [4, 6, 7, 8, 9, 10, 11, 17, 19, 20, 23, 25, 26, 28, 29, 33, 35, 36, 38, 39, 43, 44, 45, 46, 47, 51, 54, 56, 57, 62, 64, 65, 68, 70, 71, 72, 73, 76, 77, 79, 83, 85, 86, 88, 89, 91, 92, 93, 96, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 114, 115, 117, 121, 122, 125, 126, 132, 135, 136, 140, 150, 151, 155, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 187], "directori": [4, 17, 23, 33, 54, 62, 83, 96, 143, 150, 151, 155, 157, 158, 185, 188], "contain": [4, 7, 8, 9, 11, 17, 23, 25, 28, 33, 44, 46, 51, 54, 56, 64, 65, 71, 76, 79, 85, 86, 89, 91, 92, 93, 96, 99, 101, 104, 115, 117, 121, 137, 138, 139, 143, 145, 148, 150, 157, 162, 163, 165, 168, 172, 175, 177, 178, 179], "file": [4, 23, 33, 96, 143, 150, 155, 157, 158, 164, 170, 187], "return": [4, 6, 7, 8, 9, 10, 11, 17, 19, 20, 23, 25, 26, 28, 29, 33, 35, 36, 38, 39, 43, 44, 45, 46, 47, 51, 54, 56, 57, 62, 64, 65, 68, 70, 71, 72, 73, 76, 77, 79, 83, 85, 86, 88, 89, 91, 92, 93, 96, 98, 99, 100, 101, 103, 104, 107, 108, 109, 114, 115, 117, 121, 122, 125, 132, 133, 135, 136, 137, 138, 139, 140, 143, 145, 148, 150, 151, 155, 157, 158, 159, 161, 162, 163, 166, 167, 169, 170, 171, 174, 175, 176, 177, 178, 179, 180, 181, 184], "type": [4, 6, 7, 8, 9, 10, 11, 17, 19, 20, 23, 25, 26, 28, 29, 33, 35, 36, 38, 39, 43, 44, 45, 46, 47, 51, 54, 56, 57, 62, 64, 65, 68, 70, 71, 72, 73, 76, 77, 79, 83, 85, 86, 88, 89, 91, 92, 93, 96, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 114, 115, 117, 121, 122, 125, 132, 135, 140, 143, 145, 148, 150, 151, 155, 157, 158, 159, 162, 163, 165, 166, 167, 168, 169, 171, 172, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184], "input": [6, 7, 8, 9, 10, 11, 19, 20, 25, 26, 28, 35, 36, 38, 43, 44, 45, 46, 51, 56, 57, 60, 64, 65, 70, 71, 72, 73, 76, 79, 85, 86, 88, 89, 93, 98, 99, 100, 101, 103, 104, 106, 108, 114, 115, 117, 121, 122, 162, 166, 167, 171, 175, 176, 177, 178, 179, 180, 181], "tensor": [6, 7, 8, 9, 10, 11, 19, 20, 25, 26, 28, 29, 35, 36, 38, 39, 43, 44, 45, 46, 47, 56, 57, 60, 64, 65, 70, 71, 72, 73, 76, 77, 79, 85, 86, 88, 89, 91, 92, 93, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 114, 115, 121, 122, 161, 162, 163, 166, 167, 169, 171, 172, 177, 178, 179, 180, 181, 188], "convert": [6, 10, 11, 25, 28, 64, 70, 71, 76, 85, 103, 108, 161, 163, 176, 179, 187], "32": [6, 25, 70, 117, 136, 187], "bit": [6, 7, 8, 9, 10, 11, 19, 25, 28, 35, 36, 38, 39, 43, 45, 46, 60, 64, 70, 76, 79, 85, 86, 88, 89, 91, 92, 93, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 114, 115, 125, 136, 163, 165, 168, 170, 174, 175, 176, 178, 179, 180, 181, 187], "float": [6, 8, 11, 25, 28, 29, 35, 38, 39, 45, 47, 64, 70, 72, 76, 77, 85, 92, 98, 100, 106, 107, 108, 109, 121, 125, 163, 169, 180, 181], "point": [6, 11, 25, 35, 45, 64, 70, 76, 85, 86, 88, 89, 92, 98, 104, 106, 107, 108, 114, 115, 125, 163, 180, 181], "4": [6, 7, 8, 9, 35, 36, 38, 85, 86, 88, 98, 99, 100, 101, 106, 108, 114, 125, 136, 180, 187, 188], "integ": [6, 10, 11, 91, 92, 145, 174, 180, 181], "represent": [6, 7, 8, 9, 10, 11, 43, 70, 85, 98, 104, 174, 175, 176, 179], "thi": [6, 7, 8, 9, 10, 11, 19, 20, 25, 26, 28, 29, 35, 36, 38, 39, 43, 44, 45, 46, 47, 51, 56, 57, 60, 64, 65, 70, 71, 72, 73, 76, 77, 79, 85, 86, 88, 89, 91, 92, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 114, 115, 117, 121, 122, 125, 127, 132, 133, 136, 140, 143, 145, 148, 150, 151, 155, 157, 158, 159, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 174, 175, 176, 179, 183, 184, 185, 187, 188], "take": [6, 7, 101, 166], "an": [6, 7, 8, 9, 10, 11, 28, 43, 44, 46, 51, 64, 65, 70, 71, 76, 79, 85, 88, 92, 103, 106, 114, 117, 121, 133, 140, 145, 150, 151, 155, 172, 174, 175, 176, 179, 180, 181, 184, 188], "number": [6, 7, 19, 20, 28, 38, 56, 57, 70, 71, 76, 88, 91, 98, 103, 106, 108, 114, 117, 121, 122, 145, 161, 166, 167, 175, 176, 178, 179], "compress": [6, 11, 165], "effect": [6, 43, 44, 64, 65, 99, 174], "reduc": [6, 7, 8, 9, 35, 70, 89, 98, 103, 106, 115, 170, 178], "memori": [6, 19, 25, 28, 29, 35, 38, 39, 43, 47, 56, 64, 70, 77, 85, 89, 98, 103, 106, 109, 115, 127], "footprint": [6, 70, 89, 103, 106, 115], "factor": [6, 8, 11, 26, 36, 45, 46, 65, 70, 71, 85, 86, 88, 98, 99, 100, 103, 104, 106, 114, 179, 180, 181], "8": [6, 10, 11, 19, 43, 56, 70, 76, 88, 98, 100, 103, 104, 114, 136, 166, 179, 180, 181, 188], "The": [6, 7, 8, 9, 10, 11, 17, 19, 20, 23, 25, 26, 28, 29, 33, 35, 36, 38, 39, 43, 44, 45, 46, 47, 51, 56, 57, 60, 62, 64, 65, 68, 70, 71, 72, 73, 76, 77, 79, 83, 85, 86, 88, 89, 91, 92, 93, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 114, 115, 117, 121, 122, 125, 126, 132, 143, 145, 150, 151, 155, 157, 158, 161, 163, 164, 165, 167, 168, 169, 170, 171, 174, 175, 176, 177, 179, 180, 181, 183, 184, 188], "convers": [6, 25, 26, 64, 70, 71, 85, 161, 163], "process": [6, 7, 8, 9, 11, 29, 39, 46, 47, 65, 70, 77, 85, 86, 91, 98, 106, 107, 108, 109, 122, 161, 162, 163, 165, 169, 175, 176, 180, 181, 187], "involv": [6, 29, 39, 43, 44, 46, 47, 60, 65, 77, 98, 107, 109, 125, 161, 169], "find": [6, 151, 157, 158, 187, 188], "minimum": [6, 29, 39, 47, 77, 107, 109, 126, 169, 179], "maximum": [6, 179], "valu": [6, 7, 8, 9, 11, 25, 26, 28, 35, 43, 44, 46, 60, 71, 72, 73, 85, 86, 91, 98, 100, 101, 103, 106, 121, 125, 131, 133, 151, 159, 174, 175, 179, 180, 181], "normal": [6, 70, 172], "data": [6, 10, 11, 25, 28, 29, 38, 39, 45, 46, 47, 57, 64, 70, 71, 72, 76, 77, 79, 85, 86, 100, 106, 107, 108, 109, 121, 125, 161, 169, 171], "rang": [6, 26, 65, 71, 99, 101, 125, 179, 180, 181], "quantiz": [6, 7, 8, 9, 19, 25, 28, 29, 35, 36, 38, 39, 45, 47, 51, 56, 64, 70, 76, 77, 79, 83, 85, 86, 88, 89, 91, 92, 93, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 114, 115, 117, 125, 136, 164, 165, 168, 169, 170, 172, 177, 178, 179, 180, 181, 187], "A": [6, 7, 8, 9, 11, 20, 25, 28, 29, 35, 36, 39, 44, 46, 47, 51, 56, 57, 64, 65, 70, 71, 72, 76, 77, 79, 85, 89, 91, 98, 100, 101, 103, 106, 107, 108, 109, 115, 117, 121, 122, 125, 133, 143, 145, 148, 150, 151, 155, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 176, 180, 181, 183, 184, 188], "we": [6, 188], "want": [6, 185, 188], "repres": [6, 7, 11, 43, 44, 56, 76, 86, 88, 91, 92, 106, 114, 145, 150, 151, 166, 176, 183, 187], "version": [6, 43, 45, 106, 121, 126, 145, 148, 175, 188], "output": [6, 19, 20, 25, 26, 35, 36, 38, 44, 46, 56, 57, 64, 65, 70, 71, 73, 76, 79, 85, 86, 88, 89, 98, 99, 100, 101, 103, 104, 106, 108, 114, 115, 121, 122, 133, 145, 161, 163, 176, 178, 188], "us": [6, 7, 8, 9, 10, 11, 19, 20, 25, 26, 28, 29, 35, 36, 38, 39, 43, 44, 45, 46, 47, 51, 56, 57, 60, 64, 65, 70, 71, 72, 76, 77, 79, 85, 86, 88, 89, 91, 92, 98, 99, 101, 103, 104, 106, 107, 108, 109, 114, 115, 121, 125, 131, 132, 138, 143, 145, 155, 159, 161, 162, 163, 164, 165, 167, 168, 169, 170, 171, 179, 180, 181, 184, 185, 187, 188], "64": [6, 85], "store": [6, 11, 19, 43, 57, 65, 70, 71, 73, 85, 107, 108, 166, 175, 176, 188], "each": [6, 7, 11, 29, 39, 43, 44, 45, 46, 47, 77, 85, 91, 107, 109, 121, 140, 151, 165, 168, 169, 175, 176, 180, 181], "hold": [6, 91, 106], "sixteen": 6, "i": [6, 7, 8, 9, 10, 11, 19, 20, 25, 26, 28, 29, 36, 38, 39, 43, 44, 45, 46, 47, 51, 56, 57, 64, 65, 70, 71, 72, 73, 76, 77, 79, 85, 86, 88, 89, 91, 92, 98, 99, 100, 101, 104, 106, 107, 108, 109, 114, 115, 117, 121, 122, 125, 126, 127, 132, 133, 136, 143, 145, 148, 151, 155, 157, 158, 159, 161, 162, 164, 166, 167, 168, 169, 170, 171, 174, 175, 176, 179, 180, 181, 183, 184, 185, 187, 188], "assum": [6, 71, 145, 151], "flat": 6, "1d": 6, "also": [6, 25, 29, 36, 39, 47, 57, 64, 70, 71, 77, 107, 109, 121, 145, 164, 169, 170, 187, 188], "design": [6, 8, 9, 11, 28, 29, 39, 43, 44, 46, 47, 70, 72, 76, 77, 89, 98, 100, 101, 104, 106, 108, 109, 115, 121, 125, 155, 161, 183], "execut": [6, 70, 85, 88, 106, 114, 121, 133, 145, 184], "enabl": [6, 20, 71, 85, 86, 88, 106, 114], "devic": [6, 10, 28, 38, 56, 64, 70, 76, 79, 85, 86, 88, 89, 98, 100, 108, 114, 115, 188], "util": [6, 17, 19, 20, 25, 35, 36, 43, 45, 56, 60, 64, 70, 73, 79, 85, 88, 98, 103, 106, 114, 117, 187], "custom": [6, 20, 26, 29, 36, 39, 43, 44, 45, 46, 47, 57, 65, 71, 73, 77, 85, 86, 89, 99, 100, 101, 107, 109, 115, 125, 165, 188], "kernel": [6, 10, 20, 26, 28, 35, 36, 38, 60, 64, 65, 70, 71, 85, 88, 89, 104, 106, 114], "alloc": [6, 28, 38, 64, 70, 76, 100, 106, 175], "temporari": 6, "gpu": [6, 11, 36, 60, 64, 70, 88, 188], "intermedi": 6, "comput": [6, 10, 11, 19, 20, 25, 26, 28, 29, 35, 36, 38, 39, 43, 44, 47, 56, 57, 60, 64, 65, 70, 72, 73, 76, 77, 85, 86, 88, 89, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 114, 115, 121, 125, 131, 169, 178, 187, 188], "which": [6, 19, 25, 28, 38, 43, 44, 45, 46, 47, 51, 56, 64, 70, 76, 79, 86, 98, 99, 100, 104, 106, 108, 122, 131, 132, 137, 138, 139, 140, 145, 161, 164, 165, 168, 175, 188], "freed": 6, "befor": [6, 7, 25, 28, 35, 38, 46, 64, 70, 76, 85, 88, 98, 100, 103, 106, 108, 114, 161, 168, 171], "is_transpos": [7, 8, 9], "bool": [7, 8, 9, 19, 25, 26, 28, 29, 35, 36, 38, 39, 43, 44, 46, 47, 51, 56, 64, 65, 70, 71, 76, 77, 79, 85, 86, 89, 98, 99, 101, 103, 104, 106, 107, 108, 109, 115, 117, 125, 132, 133, 150, 151, 153, 159, 164, 165, 170, 179, 184], "fals": [7, 8, 9, 19, 25, 28, 35, 38, 51, 56, 64, 70, 76, 79, 98, 103, 106, 107, 108, 117, 128, 132, 133, 151, 159, 164, 170, 179, 184, 185, 188], "pack": [7, 8, 9, 10, 25, 45, 46, 64, 70, 76, 79, 92, 106, 108, 163, 164, 165, 170, 178], "format": [7, 8, 9, 11, 25, 43, 64, 70, 76, 88, 92, 93, 103, 106, 114, 161, 163, 170, 177], "acceler": [7, 25, 36, 60, 64, 70, 73, 88, 103, 114, 188], "option": [7, 8, 9, 29, 35, 36, 38, 39, 43, 45, 47, 56, 60, 64, 70, 71, 72, 76, 77, 79, 85, 86, 98, 100, 107, 109, 121, 125, 136, 164, 168, 169, 170, 172, 179, 184, 187, 188], "transpos": [7, 8, 9], "storag": [7, 103, 165, 170, 178], "requir": [7, 19, 29, 39, 43, 44, 45, 46, 47, 60, 65, 77, 85, 88, 89, 91, 101, 104, 106, 107, 109, 114, 115, 126, 140, 161, 166, 167, 171, 188], "onli": [7, 44, 46, 47, 70, 76, 79, 98, 103, 106, 108, 115, 164, 165, 170, 183, 188], "particularli": [7, 25, 29, 39, 47, 64, 70, 77, 89, 109, 115, 121, 125, 162, 164, 167, 168, 184], "neural": [7, 64, 70, 72, 98, 125, 187], "network": [7, 64, 70, 72, 85, 98, 125, 140, 187], "weight": [7, 19, 20, 25, 26, 28, 29, 35, 36, 38, 39, 43, 44, 45, 46, 47, 51, 56, 57, 60, 64, 65, 70, 71, 76, 77, 79, 85, 86, 88, 89, 91, 92, 93, 98, 99, 103, 104, 106, 107, 108, 109, 114, 115, 121, 125, 136, 163, 164, 165, 166, 169, 170, 172, 177, 178], "other": [7, 29, 39, 47, 57, 71, 77, 89, 103, 106, 107, 108, 109, 115, 143, 155, 165, 169, 183, 188], "scenario": [7, 11, 43, 89, 92, 115], "where": [7, 11, 19, 28, 46, 60, 71, 72, 73, 76, 89, 91, 98, 100, 104, 115, 121, 150, 151, 155, 157, 158, 162, 167, 170, 175, 176, 184, 187, 188], "precis": [7, 11, 25, 36, 64, 70, 85, 88, 89, 98, 100, 101, 106, 114, 115], "can": [7, 10, 19, 20, 25, 29, 35, 39, 44, 45, 46, 47, 51, 56, 57, 60, 64, 70, 71, 72, 76, 77, 85, 86, 88, 98, 103, 106, 107, 109, 114, 117, 121, 122, 132, 140, 164, 169, 170, 185, 187, 188], "trade": [7, 85], "effici": [7, 10, 11, 19, 20, 25, 28, 29, 35, 36, 38, 39, 43, 47, 57, 60, 64, 65, 70, 71, 73, 76, 77, 79, 85, 89, 98, 101, 103, 104, 106, 108, 109, 114, 115, 121, 125, 127, 165, 170, 178, 187], "without": [7, 76, 79, 92, 93, 101, 103, 106, 184, 185, 187, 188], "significantli": [7, 60, 70, 98], "affect": [7, 60, 79, 106], "applic": [7, 85, 184, 188], "": [7, 8, 9, 10, 19, 20, 25, 28, 36, 51, 64, 70, 71, 76, 79, 85, 86, 98, 103, 106, 108, 133, 155, 157, 158, 164, 170, 188], "perform": [7, 10, 11, 20, 25, 26, 35, 36, 43, 44, 46, 47, 56, 57, 60, 65, 70, 71, 73, 79, 85, 86, 88, 89, 98, 99, 100, 101, 103, 104, 106, 114, 115, 125, 161, 165, 171, 174, 179], "actual": [7, 70, 85, 88, 98, 106, 114, 161, 165, 184], "make": [7, 188], "suitabl": [7, 8, 9, 60, 64, 65, 188], "larg": [7, 29, 39, 47, 77, 106, 107, 109, 169, 187], "torch": [7, 8, 9, 10, 11, 17, 19, 25, 26, 28, 29, 35, 36, 38, 39, 44, 45, 46, 47, 56, 57, 64, 65, 70, 71, 72, 73, 76, 77, 79, 85, 86, 88, 89, 91, 92, 93, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 114, 115, 121, 125, 138, 161, 162, 163, 165, 166, 167, 168, 169, 170, 171, 177, 178, 179, 180, 181, 185, 188], "should": [7, 8, 9, 28, 29, 35, 38, 39, 43, 44, 47, 57, 64, 71, 76, 77, 85, 86, 88, 98, 106, 108, 109, 114, 122, 140, 164, 165, 170, 179, 180, 181, 188], "compat": [7, 57, 71, 76, 85, 88, 98, 103, 114], "int32": [7, 8, 9], "If": [7, 8, 9, 10, 19, 25, 26, 28, 35, 38, 51, 56, 64, 70, 72, 76, 79, 85, 92, 93, 98, 100, 103, 107, 108, 121, 125, 126, 133, 145, 151, 157, 165, 168, 179, 184, 185, 188], "true": [7, 19, 25, 28, 29, 35, 38, 39, 47, 51, 56, 64, 70, 76, 77, 79, 85, 98, 103, 106, 107, 108, 109, 117, 125, 132, 133, 151, 159, 164, 165, 170, 179, 184, 185], "need": [7, 11, 20, 86, 106, 125, 136, 155, 162, 185, 187, 188], "specif": [7, 19, 20, 25, 29, 38, 39, 43, 46, 47, 60, 64, 70, 77, 79, 86, 88, 89, 98, 99, 100, 103, 106, 107, 108, 109, 114, 115, 117, 125, 132, 133, 143, 161, 168, 169, 172, 174, 176, 184, 187, 188], "orient": 7, "subsequ": [7, 65, 70], "oper": [7, 10, 11, 19, 20, 23, 25, 26, 28, 29, 35, 36, 39, 43, 44, 46, 47, 60, 62, 64, 65, 70, 71, 72, 73, 76, 77, 79, 83, 86, 88, 89, 99, 101, 104, 106, 107, 108, 109, 114, 115, 121, 143, 161, 162, 167, 168, 169, 171, 174, 175, 183, 187, 188], "have": [7, 8, 9, 88, 91, 100, 106, 114, 168, 185, 188], "dtype": [7, 8, 9, 28, 29, 38, 39, 45, 47, 64, 70, 71, 72, 76, 77, 100, 106, 107, 108, 109, 121, 125, 138, 169], "int8": [7, 8, 9, 10, 25, 64, 65, 70, 71, 103, 163], "potenti": [7, 60, 79, 106, 143, 150, 151, 170], "half": [7, 10, 106], "element": [7, 20, 26, 28, 36, 38, 46, 85, 106, 161, 167, 175, 176, 180, 181], "last": [7, 161, 167], "dimens": [7, 19, 20, 46, 60, 64, 70, 72, 76, 79, 91, 98, 100, 103, 108, 121, 122, 161, 162, 166, 167, 175], "transposit": [7, 8, 9], "chang": [7, 43, 44, 86, 187], "shape": [7, 11, 19, 25, 35, 43, 46, 70, 71, 88, 98, 103, 114, 121, 161, 162, 171, 179], "adjust": [7, 25, 29, 39, 47, 77, 79, 86, 99, 100, 103, 106, 107, 109, 143, 148, 161, 168, 169, 179, 180, 181, 188], "accordingli": [7, 143], "scale": [8, 11, 25, 26, 35, 36, 45, 46, 64, 65, 70, 71, 85, 86, 88, 89, 98, 99, 100, 103, 104, 106, 107, 114, 115, 128, 163, 179, 180, 181, 187], "unpack": [8, 9, 11, 46, 106, 164, 170, 172], "ha": [8, 9, 29, 39, 47, 70, 77, 106, 107, 109, 169, 179, 187], "been": [8, 9, 29, 39, 47, 70, 77, 106, 107, 109, 169, 187], "previous": [8, 9, 70, 85], "its": [8, 9, 51, 71, 91, 125, 161, 166, 167, 168, 172], "origin": [8, 9, 11, 19, 25, 28, 38, 45, 46, 56, 64, 70, 79, 98, 127, 161, 162, 163, 170, 171, 174, 187], "work": [8, 9, 11, 44, 45, 46, 98, 101, 121, 188], "from": [8, 9, 19, 20, 25, 26, 28, 35, 36, 43, 44, 45, 51, 56, 64, 65, 70, 71, 73, 76, 79, 85, 88, 89, 93, 98, 99, 101, 103, 104, 106, 107, 114, 115, 121, 125, 127, 133, 161, 163, 164, 168, 174, 177, 179, 187], "standard": [8, 9, 43, 47, 65, 86, 107, 125], "down": [8, 9], "two": [8, 9, 57, 71, 100, 106, 159, 161, 162, 167], "singl": [8, 9, 125, 174], "revers": [8, 9, 171], "reconstruct": [8, 9, 85, 93, 171, 177], "new": [8, 9, 25, 28, 38, 56, 64, 70, 76, 106, 108, 138, 174], "It": [8, 9, 10, 11, 19, 25, 28, 29, 35, 36, 39, 43, 45, 46, 47, 51, 57, 64, 70, 71, 72, 73, 76, 77, 79, 85, 86, 88, 89, 91, 98, 101, 103, 106, 107, 108, 109, 114, 115, 121, 125, 140, 143, 148, 151, 158, 159, 163, 166, 169, 175, 180, 181, 183, 185, 187, 188], "must": [8, 9, 10, 25, 28, 35, 38, 43, 44, 45, 57, 64, 70, 71, 76, 79, 88, 98, 103, 108, 114, 121, 159], "multipli": 8, "indic": [8, 9, 26, 28, 29, 36, 39, 43, 44, 45, 46, 47, 51, 64, 65, 71, 76, 77, 79, 85, 86, 89, 91, 99, 101, 104, 106, 107, 108, 109, 117, 131, 132, 150, 151, 159, 164, 165, 169, 170, 179, 184], "whether": [8, 9, 28, 29, 39, 46, 47, 51, 71, 77, 85, 86, 104, 106, 107, 109, 117, 125, 150, 151, 164, 165, 169, 170, 184], "default": [8, 9, 19, 28, 29, 38, 39, 47, 64, 70, 72, 76, 77, 79, 85, 100, 103, 106, 107, 108, 109, 121, 125, 136, 143, 145, 157, 164, 165, 168, 170, 179, 184, 188], "mean": [8, 9, 72, 98, 100, 106, 108, 164], "occur": [8, 9, 145], "depend": [8, 9, 151, 155, 170, 185], "implement": [8, 9, 11, 19, 20, 25, 26, 28, 29, 35, 36, 38, 39, 43, 44, 47, 51, 56, 60, 64, 65, 71, 73, 76, 77, 85, 86, 88, 92, 98, 99, 101, 103, 104, 106, 107, 108, 109, 114, 115, 117, 121, 125, 127, 168, 169, 175, 184], "q4_unpack": [8, 9], "functions_cuda": [8, 9], "typic": [8, 9, 28, 43, 44, 70, 106, 121, 158, 175], "further": [8, 9, 11, 70, 106, 143, 164], "analysi": [8, 9, 11], "rais": [8, 9, 29, 39, 47, 77, 79, 88, 92, 93, 100, 106, 107, 109, 114, 121, 125, 126, 133, 169, 179, 183, 184], "assertionerror": [8, 9, 79, 100], "assert": [8, 9, 88, 114], "error": [8, 9, 10, 43, 44, 86, 88, 106, 114, 121, 125, 133, 145, 183], "ensur": [8, 9, 10, 20, 25, 28, 35, 38, 46, 64, 65, 70, 72, 76, 85, 88, 98, 99, 103, 106, 108, 114, 117, 121, 125, 143, 165, 167, 168, 180, 181, 183, 187], "appli": [8, 9, 11, 29, 39, 43, 44, 46, 47, 56, 57, 64, 65, 70, 72, 77, 79, 85, 98, 99, 103, 107, 109, 125, 161, 162, 164, 169, 180, 181], "correctli": [8, 9, 85, 88, 106, 114, 168], "given": [10, 19, 43, 51, 56, 64, 70, 79, 88, 91, 114, 117, 125, 132, 136, 137, 138, 139, 140, 164, 165, 168, 174, 179], "unsign": [10, 11, 179], "variou": [10, 76, 106, 157, 158], "float32": [10, 28, 38, 45, 72, 76, 100, 108, 121, 125], "bfloat16": [10, 138], "correct": [10, 29, 39, 46, 47, 77, 106, 107, 109, 125, 169, 188], "emploi": [10, 43, 44, 187], "guard": 10, "base": [10, 11, 19, 23, 25, 28, 29, 35, 36, 38, 39, 43, 44, 47, 51, 56, 60, 64, 65, 70, 71, 72, 76, 77, 79, 85, 86, 91, 98, 99, 100, 101, 104, 106, 107, 108, 109, 117, 125, 133, 143, 148, 150, 165, 169, 170, 172, 175, 176, 179, 188], "support": [10, 25, 29, 35, 39, 43, 44, 45, 46, 47, 51, 56, 60, 64, 65, 70, 71, 76, 77, 79, 85, 86, 88, 89, 93, 98, 99, 106, 108, 109, 114, 115, 125, 132, 143, 155, 165, 179, 187, 188], "termin": 10, "program": [10, 184], "messag": [10, 51, 117, 125, 184], "provid": [11, 35, 38, 46, 51, 56, 71, 76, 99, 106, 108, 117, 133, 150, 163, 164, 165, 168, 184, 188], "python": [11, 157, 158, 175, 184, 188], "interfac": 11, "backend": [11, 20, 57], "them": [11, 103, 185], "higher": [11, 188], "compact": 11, "expand": [11, 188], "batch_siz": [11, 46, 121, 162, 171], "sequence_length": [11, 121], "packed_embedding_dimens": 11, "embed": [11, 43, 44, 45, 46, 47, 166, 168], "1": [11, 28, 38, 43, 57, 71, 79, 101, 106, 107, 128, 150, 157, 166, 174, 176, 188], "sequenc": [11, 162, 171], "batch": [11, 19, 57, 70, 88, 98, 103, 114], "These": [11, 155, 161], "ar": [11, 19, 25, 26, 28, 35, 38, 43, 44, 45, 46, 47, 51, 57, 60, 64, 70, 71, 72, 73, 76, 79, 88, 89, 93, 98, 99, 101, 103, 104, 106, 107, 108, 114, 115, 117, 121, 125, 136, 140, 143, 155, 158, 159, 164, 165, 167, 168, 175, 179, 183, 184, 187, 188], "0": [11, 28, 29, 38, 39, 47, 64, 70, 76, 77, 103, 107, 109, 125, 127, 128, 145, 169, 174, 175, 176, 188], "directli": [11, 43, 44, 57, 71, 99, 101, 125, 135, 137, 138, 139, 140, 150, 187], "offer": [11, 60, 72, 106], "signific": [11, 25, 64, 70, 174, 187], "speedup": [11, 170], "compar": [11, 187], "cpu": [11, 56, 131, 132, 133, 143], "function": [16, 19, 20, 22, 25, 29, 32, 35, 36, 39, 44, 45, 46, 47, 49, 51, 53, 56, 57, 61, 64, 65, 67, 70, 71, 72, 73, 77, 79, 82, 85, 86, 88, 89, 90, 91, 92, 95, 98, 99, 101, 103, 104, 106, 107, 109, 111, 114, 115, 117, 124, 130, 132, 134, 136, 140, 141, 143, 144, 145, 148, 149, 150, 151, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 170, 171, 173, 175, 176, 179, 180, 181, 182, 184, 187], "retriev": [17, 46, 54, 57, 71, 73, 133], "c": [17, 19, 20, 35, 54, 56, 57, 127, 148, 155, 175, 176, 188], "convolut": [17, 19, 20, 23, 25, 26, 28, 35, 36, 38, 76, 165, 168], "code": [17, 143, 188], "cpp_extens": [17, 187], "cppextens": [17, 155], "class": [18, 19, 20, 24, 25, 26, 27, 28, 29, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 50, 51, 55, 56, 57, 59, 60, 63, 64, 65, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 84, 85, 86, 87, 88, 89, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 113, 114, 115, 116, 117, 120, 121, 122, 124, 125, 127, 128, 130, 131, 133, 140, 163, 165, 168, 182, 183], "arg": [19, 20, 25, 26, 35, 36, 43, 44, 45, 46, 51, 57, 64, 65, 70, 71, 72, 73, 85, 86, 88, 89, 98, 99, 100, 101, 103, 104, 114, 115, 117, 121, 136, 161], "kwarg": [19, 20, 25, 26, 35, 36, 43, 44, 45, 46, 51, 57, 64, 65, 70, 71, 72, 73, 85, 86, 88, 89, 98, 99, 100, 101, 103, 104, 114, 115, 117, 121], "pytorch": [19, 20, 26, 36, 43, 44, 47, 72, 100, 126, 166, 167, 170, 179, 187, 188], "optim": [19, 28, 29, 35, 38, 39, 43, 44, 45, 46, 47, 60, 64, 65, 70, 73, 76, 77, 79, 85, 86, 88, 89, 106, 107, 108, 109, 114, 115, 122, 143, 169, 170, 187], "extens": [19, 70, 155, 170, 183, 184, 187], "inherit": [19, 25, 51, 56, 79, 88, 98, 103, 114], "binaryconv2dbas": [19, 25], "leverag": [19, 25, 51, 60, 64, 70, 104, 125], "common": [19, 56, 88, 106, 114, 117], "ad": [19, 20, 26, 28, 36, 38, 122, 125, 161, 166, 167], "bits_binary_word": [19, 25, 64, 70, 76], "defin": [19, 20, 25, 26, 29, 35, 39, 47, 56, 57, 64, 70, 71, 77, 85, 92, 98, 101, 103, 106, 107, 109, 117, 169, 180, 181, 184], "size": [19, 20, 28, 29, 35, 36, 38, 39, 43, 45, 47, 57, 70, 77, 85, 86, 88, 91, 98, 103, 106, 107, 109, 114, 115, 121, 136, 163, 167, 169, 170, 172, 175, 176, 178, 187], "word": [19, 64, 70, 76, 175, 176], "int": [19, 20, 26, 28, 36, 38, 43, 45, 46, 56, 57, 64, 70, 71, 76, 79, 85, 86, 88, 89, 91, 106, 107, 108, 114, 115, 121, 122, 161, 167, 174, 175, 176, 178, 179, 188], "method": [19, 20, 25, 26, 28, 29, 35, 36, 38, 39, 43, 44, 45, 46, 47, 51, 56, 57, 64, 65, 70, 71, 72, 73, 76, 77, 79, 85, 86, 88, 89, 92, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 114, 115, 117, 121, 122, 125, 128, 133, 165, 168, 169, 174, 179, 183], "attribut": [19, 20, 25, 26, 28, 29, 35, 36, 38, 39, 43, 44, 45, 46, 47, 56, 57, 60, 64, 65, 70, 71, 72, 73, 76, 77, 79, 85, 86, 88, 89, 92, 93, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 114, 115, 121, 122, 125, 131, 172, 183], "__init__": [19, 25, 28, 35, 38, 43, 45, 56, 64, 70, 72, 76, 79, 85, 88, 98, 100, 103, 106, 107, 108, 114, 121, 122, 125, 128, 183], "initi": [19, 25, 28, 29, 35, 38, 39, 43, 45, 47, 56, 64, 70, 72, 76, 77, 79, 85, 88, 98, 100, 103, 106, 108, 109, 114, 121, 122, 125, 163, 168, 176, 183, 188], "argument": [19, 25, 26, 35, 44, 57, 64, 71, 72, 85, 88, 89, 100, 114, 115, 121, 143, 148], "forward": [19, 20, 25, 26, 35, 36, 38, 43, 44, 45, 46, 56, 57, 64, 65, 70, 71, 72, 73, 76, 79, 85, 86, 88, 89, 98, 99, 100, 101, 103, 104, 106, 114, 115, 121, 122], "addition": [19, 70, 86, 148], "set": [19, 25, 28, 38, 57, 64, 70, 71, 72, 76, 79, 85, 88, 98, 100, 103, 106, 108, 114, 121, 132, 136, 143, 148, 155, 164, 168, 174, 175, 176, 183, 185, 188], "up": [19, 28, 57, 71, 79, 88, 98, 103, 106, 114, 121, 155, 167, 168, 188], "variabl": [19, 25, 26, 35, 64, 85, 86, 99, 100, 104, 121, 151, 157, 158, 174, 185, 188], "length": [19, 25, 35, 64, 85, 100, 121, 176], "list": [19, 25, 35, 64, 85, 86, 100, 107, 121, 135, 137, 138, 139, 140, 143, 151, 155, 158, 161, 162, 165, 168, 171], "pass": [19, 20, 25, 26, 29, 35, 36, 38, 39, 44, 45, 46, 47, 56, 57, 64, 65, 70, 71, 72, 73, 76, 77, 79, 85, 86, 88, 89, 98, 99, 100, 101, 103, 104, 106, 109, 114, 115, 121, 122, 143], "arbitrari": [19, 20, 25, 35, 57, 64, 71, 85, 100, 121], "keyword": [19, 25, 35, 64, 85, 88, 100, 114, 121, 143, 148], "x": [19, 25, 26, 28, 35, 36, 38, 56, 64, 70, 72, 73, 76, 79, 85, 86, 88, 89, 98, 99, 100, 101, 103, 104, 108, 114, 115, 122, 162, 171, 175, 188], "n": [19, 20, 25, 35, 38, 39, 57, 79, 108, 109, 125, 165, 168, 175], "c_in": [19, 25], "h": [19, 25, 35, 150, 157], "w": [19, 25, 35, 172], "channel": [19, 20, 28, 38, 122], "height": 19, "width": [19, 38, 64, 70, 79, 85, 88, 89, 106, 107, 108, 114, 115], "determin": [19, 29, 39, 43, 44, 47, 51, 70, 77, 107, 109, 117, 132, 133, 145, 151, 158, 159, 169, 175, 176], "generate_quantized_weight": [19, 25, 28, 35, 38, 56, 64, 70, 76, 79, 98, 103, 106, 108, 165], "qweight_onli": [19, 25, 28, 35, 38, 56, 64, 70, 76, 79, 98, 103, 106, 108, 164, 165, 170], "none": [19, 25, 26, 28, 29, 35, 36, 38, 39, 43, 44, 45, 46, 47, 51, 56, 57, 64, 65, 70, 71, 72, 76, 77, 79, 85, 86, 88, 89, 92, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 114, 115, 121, 125, 135, 136, 138, 157, 158, 159, 164, 165, 168, 169, 170, 172, 179, 180, 181, 183, 188], "current": [19, 28, 29, 38, 39, 44, 45, 47, 57, 64, 71, 76, 77, 79, 92, 106, 107, 108, 109, 115, 117, 126, 133, 136, 158, 166, 169, 188], "nn": [19, 25, 28, 29, 35, 38, 39, 43, 45, 47, 64, 70, 72, 76, 77, 88, 98, 100, 103, 107, 108, 109, 114, 121, 122, 125, 163, 168, 169, 170], "gradient": [19, 20, 26, 29, 36, 39, 43, 44, 46, 47, 65, 71, 73, 76, 77, 86, 89, 99, 101, 104, 106, 107, 109, 115, 125, 127, 169, 172, 188], "discard": [19, 25, 28, 38, 64, 70, 98], "save": [19, 25, 26, 28, 35, 36, 38, 44, 46, 56, 57, 64, 65, 70, 71, 73, 86, 89, 98, 99, 101, 104, 106, 115, 165, 170], "prepare_param": [19, 25, 28, 35, 38, 45, 56, 64, 70, 76, 79, 85, 88, 98, 103, 106, 108, 114, 168], "prepar": [19, 25, 28, 35, 38, 45, 56, 64, 70, 76, 79, 85, 88, 98, 103, 106, 108, 114, 163, 165, 167, 168, 188], "model": [19, 25, 28, 29, 35, 36, 38, 39, 43, 44, 45, 47, 56, 60, 64, 65, 70, 76, 77, 85, 91, 98, 99, 101, 103, 106, 107, 108, 109, 121, 125, 133, 135, 143, 162, 164, 165, 168, 169, 170, 187], "train": [19, 25, 26, 28, 35, 36, 38, 43, 44, 45, 46, 47, 56, 64, 65, 70, 71, 76, 86, 89, 98, 99, 101, 103, 104, 106, 108, 115, 122, 125, 127, 163, 164, 165, 168, 170, 187, 188], "One": [19, 25, 35, 45, 56, 64, 70, 85, 88, 98, 103, 106, 114], "prepare_bie_lay": [19, 25, 35, 45, 56, 64, 70, 85, 88, 98, 103, 106, 114], "project_root": [19, 25, 35, 45, 56, 64, 70, 85, 88, 98, 103, 106, 114], "model_help": [19, 25, 35, 45, 56, 64, 70, 85, 88, 98, 103, 106, 114, 187], "call": [19, 25, 28, 35, 38, 45, 56, 64, 70, 76, 79, 85, 88, 98, 103, 106, 108, 114, 125, 135, 137, 138, 139, 140, 159, 165, 168], "autograd": [20, 36, 44, 46, 57, 65, 71, 73, 86, 89, 101, 115], "2d": [20, 162, 171], "static": [20, 26, 29, 36, 39, 44, 46, 47, 57, 64, 65, 71, 73, 77, 85, 86, 89, 99, 101, 104, 107, 109, 115, 133], "carri": 20, "out": [20, 43, 121, 125, 132, 143], "activ": [20, 25, 35, 38, 47, 64, 65, 70, 71, 79, 88, 89, 98, 99, 100, 103, 104, 106, 108, 114, 115, 188], "No": 20, "level": [20, 60, 85], "ctx": [20, 26, 36, 44, 46, 57, 65, 71, 73, 86, 89, 99, 101, 104, 115], "m": [20, 57, 185], "k": [20, 57, 161, 175], "kernel_s": [20, 26, 28, 36, 38], "stride": [20, 26, 28, 36, 38], "pad": [20, 26, 28, 36, 38, 43, 45, 73, 161, 166, 167], "dilat": [20, 26, 28, 36, 38], "output_edg": 20, "binary_conv_cpp": 20, "automat": [20, 60, 155], "integr": [20, 26, 71, 72, 187], "mechan": [20, 36, 43, 44, 108, 121, 184], "context": [20, 26, 36, 44, 46, 47, 57, 65, 71, 73, 86, 89, 98, 99, 101, 104, 115], "object": [20, 26, 33, 36, 46, 51, 57, 64, 65, 71, 73, 79, 89, 92, 93, 99, 101, 104, 115, 117, 140, 172, 177, 184], "stash": [20, 26], "inform": [20, 26, 36, 57, 65, 73, 85, 86, 89, 91, 93, 107, 115, 132, 133, 177, 184, 187, 188], "backward": [20, 26, 29, 36, 39, 44, 46, 47, 57, 65, 71, 73, 77, 86, 89, 99, 101, 104, 109, 115], "you": [20, 57, 71, 162, 174, 185, 187, 188], "cach": 20, "save_for_backward": [20, 57, 71], "featur": [20, 56, 57, 64, 70, 76, 79, 88, 98, 103, 106, 108, 114, 117, 132, 143, 178], "map": [20, 85, 86, 91, 107, 133], "spatial": 20, "conv": [20, 29, 39], "zero": [20, 28, 35, 43, 45, 46, 85, 86, 88, 89, 98, 99, 100, 101, 103, 104, 106, 107, 114, 115, 122, 167, 172, 178, 180, 181], "both": [20, 28, 35, 36, 43, 44, 45, 51, 64, 70, 71, 76, 86, 89, 98, 99, 100, 101, 104, 108, 115, 148, 159, 164, 168, 179], "side": [20, 26, 28, 36, 38], "space": [20, 26, 28, 36, 38, 106], "between": [20, 26, 28, 36, 38, 46, 85, 98, 143, 179, 187], "edg": [20, 89, 98, 115, 187], "match": [20, 103, 122, 165, 168], "expect": [20, 29, 39, 45, 46, 47, 65, 71, 77, 85, 91, 107, 109, 125, 150, 162, 169], "result": [20, 36, 43, 44, 45, 46, 65, 72, 73, 85, 88, 89, 100, 101, 114, 115, 161, 175, 180, 181], "part": [20, 47, 85], "pair": [20, 91], "correspond": [20, 79, 133, 175, 176, 180, 181], "obtain": 23, "cuda": [23, 33, 68, 96, 148, 187], "necessari": [23, 26, 28, 45, 46, 85, 93, 98, 106, 108, 117, 155, 167, 168, 177], "special": [25, 29, 35, 39, 43, 44, 46, 47, 51, 64, 70, 73, 77, 85, 106, 109, 179, 187], "librari": [25, 71, 98, 114, 132, 143, 148, 151, 155, 157, 158, 159, 187, 188], "add": [25, 70, 98, 103, 122, 143, 188], "possibli": [25, 85], "uint8_t": 25, "bias_a": [25, 35, 64, 70, 98, 103], "bia": [25, 29, 35, 39, 47, 64, 65, 70, 77, 79, 88, 98, 103, 106, 107, 109, 114, 117, 122, 125, 169], "scale_a": [25, 26, 35, 36, 64, 65, 70, 71, 98, 99, 103, 104, 180, 181], "scale_w": [25, 26, 35, 36, 45, 64, 65, 70, 71, 98, 99, 103, 104], "addit": [25, 73, 88, 106, 107, 114, 143, 161, 187, 188], "param": [25, 125, 136, 137, 138, 139], "init_weight": [25, 45, 64, 70], "achiev": [25, 64, 70, 163], "reduct": [25, 43, 64, 70, 163], "usag": [25, 29, 39, 47, 57, 64, 70, 71, 77, 85, 86, 98, 109], "essenti": [25, 46, 64, 70, 93, 168], "maintain": [25, 35, 64, 70, 71, 100, 101, 103, 108, 187], "numer": [25, 29, 39, 47, 64, 70, 77, 103, 107, 109, 125, 169, 175], "fidel": [25, 64, 70], "lower": [25, 64, 70, 106, 180, 181, 188], "benefici": [25, 64, 70], "infer": [25, 35, 64, 70, 76, 79, 85, 86, 88, 104, 106, 108, 114, 163, 164, 168, 170, 187], "hardwar": [25, 60, 64, 70, 73, 76, 85, 88, 98, 103, 106, 114, 188], "arithmet": [25, 43, 44, 64, 70, 98, 101], "after": [25, 28, 35, 38, 43, 44, 45, 46, 56, 57, 64, 70, 71, 76, 79, 86, 98, 99, 103, 106, 108, 122, 166, 171, 188], "start": [25, 28, 35, 38, 64, 70, 76, 91, 98, 103, 108, 174], "properli": [25, 28, 35, 38, 64, 70, 76, 98, 103, 108, 121, 165], "set_activ": [25, 35, 64, 70, 98, 103], "set_weight_data": [25, 28, 38, 64, 70, 76, 79, 108], "re": [25, 175, 185], "pre": [25, 98, 163, 175], "avail": [25, 38, 60, 70, 89, 115, 159, 163, 168], "includ": [26, 43, 45, 65, 72, 76, 79, 85, 106, 117, 125, 140, 143, 148, 150, 151, 155, 157, 159, 161, 168, 170, 172, 188], "dure": [26, 45, 46, 47, 57, 60, 70, 71, 76, 85, 88, 99, 101, 106, 108, 114, 122, 145, 161, 183, 184, 188], "backwardcfunct": [26, 36, 44, 46, 65, 71, 73, 86, 89, 99, 101, 104, 115], "output_gradi": [26, 36, 44, 46, 65, 71, 73, 86, 89, 99, 101, 104, 115], "tupl": [26, 36, 44, 46, 51, 57, 65, 71, 73, 86, 89, 99, 101, 104, 115, 117, 121, 125, 145, 150, 151, 162, 163, 177, 179], "loss": [26, 29, 36, 39, 44, 46, 47, 65, 71, 73, 77, 89, 99, 101, 104, 106, 107, 109, 115, 125, 169, 187], "respect": [26, 36, 44, 46, 65, 71, 73, 86, 89, 99, 100, 101, 104, 115, 148], "non": [26, 36, 46, 85, 175, 176], "is_train": [26, 36, 44, 46, 65, 71, 86, 89, 99, 101, 104, 115], "filter": 26, "flag": [26, 29, 36, 39, 44, 46, 47, 71, 77, 85, 86, 89, 99, 101, 104, 106, 107, 109, 115, 132, 143, 148, 164, 165, 170, 179, 184], "all": [26, 38, 57, 71, 93, 106, 135, 137, 138, 139, 140, 165, 168, 177, 187, 188], "four": 26, "in_channel": [28, 38, 106, 108], "out_channel": [28, 38, 106, 108], "symmetr": [28, 64, 70, 76, 106, 115], "serv": [28, 106, 183], "configur": [28, 51, 64, 70, 76, 79, 85, 106, 117, 143, 155, 188], "imag": [28, 188], "produc": [28, 108], "convolv": 28, "desir": [28, 38, 60, 100, 135, 170], "logic": [28, 38, 43, 44, 85, 175, 176], "form": [28, 184], "abstract": [28, 117], "subclass": [28, 38, 57, 71, 106, 108, 117], "properti": [28, 38, 64, 70, 76, 79, 108], "opt_weight": [28, 38, 76, 79, 108], "check": [28, 51, 98, 106, 117, 125, 126, 132, 133, 143, 145, 150, 151, 157, 159, 165, 188], "mode": [28, 36, 38, 46, 56, 71, 76, 85, 86, 89, 99, 101, 106, 108, 115, 179], "appropri": [28, 70, 72, 106, 143, 184], "reset_paramet": [28, 38, 43, 45, 76, 108], "reset": [28, 38, 43, 45, 76, 108], "reiniti": 28, "random": 28, "set_bits_binary_word": [28, 76], "num_bit": [28, 76, 179], "set_quantized_weight_data": [28, 38, 76, 79, 108], "requires_grad": [29, 39, 47, 77, 106, 107, 109, 188], "extend": [29, 35, 39, 47, 51, 57, 64, 70, 71, 77, 85, 98, 107, 109, 117], "techniqu": [29, 39, 47, 77, 106, 109], "updat": [29, 39, 43, 44, 46, 47, 65, 76, 77, 85, 89, 106, 107, 109, 115, 125, 169, 172], "qweight": [29, 39, 44, 45, 46, 47, 70, 76, 77, 85, 86, 88, 89, 92, 93, 106, 107, 109, 114, 115, 125, 169, 172, 177], "exp_avg_": [29, 39, 47, 77, 107, 109, 169], "exp_avg_l": [29, 39, 47, 77, 107, 109, 169], "step": [29, 39, 43, 44, 47, 73, 77, 88, 106, 107, 109, 114, 125, 161, 168, 169, 172, 188], "lr": [29, 39, 47, 77, 107, 109, 125, 169], "0001": [29, 39, 47, 77, 107, 109, 125, 169], "weight_decai": [29, 39, 47, 77, 107, 109, 125, 169], "beta1": [29, 39, 47, 77, 107, 109, 169], "99": [29, 39, 47, 77, 107, 109, 125, 169], "beta2": [29, 39, 47, 77, 107, 109, 169], "9999": [29, 39, 47, 77, 107, 109, 125, 169], "ep": [29, 35, 39, 47, 77, 98, 99, 100, 101, 103, 104, 107, 109, 125, 169, 180, 181], "1e": [29, 39, 47, 77, 107, 109, 125, 169], "06": [29, 39, 47, 77, 107, 109, 125, 169], "float16": [29, 39, 47, 77, 106, 107, 109, 169], "correct_bia": [29, 39, 47, 77, 107, 109, 125, 169], "projector": [29, 39, 47, 77, 107, 109, 169], "grad": [29, 39, 47, 77, 107, 109, 169], "how": [29, 39, 46, 47, 70, 77, 85, 106, 107, 109, 143, 169, 187], "mai": [29, 39, 44, 45, 46, 47, 65, 70, 77, 79, 86, 107, 109, 169, 170, 188], "momentum": [29, 39, 47, 77, 107, 109, 125, 169], "some": [29, 39, 47, 77, 107, 109, 169, 188], "algorithm": [29, 39, 47, 77, 107, 109, 169], "exponenti": [29, 39, 47, 77, 107, 109, 169], "move": [29, 39, 47, 77, 107, 109, 169], "averag": [29, 39, 47, 77, 107, 109, 125, 163, 169], "squar": [29, 39, 47, 77, 107, 109, 125, 169], "like": [29, 39, 43, 44, 47, 77, 92, 106, 107, 109, 125, 158, 162, 165, 169, 175, 176, 185, 188], "adam": [29, 39, 47, 77, 107, 109, 125, 169], "iter": [29, 39, 47, 77, 107, 109, 125, 137, 138, 139, 140, 151, 155, 165, 168, 169, 175, 176], "learn": [29, 39, 47, 60, 65, 77, 88, 107, 109, 114, 125, 169], "rate": [29, 39, 47, 77, 107, 109, 125, 169], "condit": [29, 39, 47, 77, 88, 107, 109, 114, 169], "hyperparamet": [29, 39, 47, 77, 107, 109, 169], "while": [29, 35, 39, 43, 44, 47, 73, 77, 85, 89, 101, 107, 109, 115, 169, 185], "toward": [29, 39, 47, 77, 107, 109, 125, 169], "decai": [29, 39, 47, 77, 107, 109, 125, 169], "l2": [29, 39, 47, 77, 107, 109, 125, 169], "penalti": [29, 39, 47, 77, 107, 109, 125, 169], "regular": [29, 39, 47, 77, 107, 109, 169], "term": [29, 39, 47, 65, 77, 106, 107, 109, 122, 125, 132, 169], "help": [29, 39, 47, 77, 100, 107, 109, 169], "prevent": [29, 35, 39, 47, 77, 100, 103, 107, 109, 121, 169, 180, 181], "overfit": [29, 39, 47, 77, 107, 109, 121, 169], "penal": [29, 39, 47, 77, 107, 109, 169], "first": [29, 39, 47, 57, 71, 72, 73, 77, 100, 107, 109, 162, 164, 169, 170, 180, 181, 188], "moment": [29, 39, 47, 77, 107, 109, 169], "estim": [29, 39, 47, 77, 107, 109, 169], "second": [29, 39, 47, 72, 73, 77, 100, 107, 109, 161, 167, 169, 175], "anoth": [29, 39, 47, 77, 107, 109, 169], "small": [29, 35, 39, 47, 77, 98, 100, 103, 107, 109, 169, 180, 181], "constant": [29, 39, 47, 77, 107, 109, 161, 169], "stabil": [29, 39, 47, 64, 77, 103, 107, 109, 125, 169], "certain": [29, 39, 43, 44, 47, 77, 98, 107, 109, 117, 121, 135, 167, 169, 188], "bert": [29, 39, 47, 77, 107, 109, 162, 169], "optin": [29, 39, 47, 77, 107, 109, 169], "place": [29, 39, 47, 77, 107, 109, 169], "doe": [29, 39, 47, 77, 107, 109, 159, 166, 169], "anyth": [29, 39, 47, 77, 107, 109, 169], "notimplementederror": [29, 39, 47, 77, 92, 93, 106, 107, 109, 169], "yet": [29, 39, 47, 77, 93, 106, 107, 108, 109, 169, 184, 188], "get": [33, 62, 68, 83], "nbitconv2dbas": 35, "aim": [35, 60, 100, 103, 106, 133, 163], "improv": [35, 101, 121, 125], "accuraci": [35, 70, 85, 101, 103, 187], "epsilon": [35, 98, 99, 100, 101, 103, 104, 125], "divis": [35, 98, 99, 100, 101, 103, 104, 117, 121, 180, 181], "calcul": [35, 36, 44, 65, 71, 86, 88, 91, 100, 101, 106, 107, 114, 163, 166, 179], "releas": [35, 187], "especi": [35, 60, 76, 98, 106], "runtim": [35, 56, 155, 183], "shift": [35, 174, 187], "learnabl": [35, 98, 103, 122], "intend": [36, 57, 70, 71, 170], "low": [36, 70, 89, 98, 100, 101, 108, 115, 127, 187], "primit": 36, "placehold": [36, 44, 65, 71, 89, 99, 101, 104, 106, 115, 183, 184], "differenti": 36, "functionctx": [36, 57], "a_bit": [38, 79, 88, 89, 106, 108, 114], "w_bit": [38, 79, 88, 89, 106, 107, 108, 114, 115, 178], "creat": [38, 46, 56, 64, 79, 91, 140, 155, 185, 188], "overridden": [38, 57, 71], "proper": [38, 99], "evalu": [38, 43, 70], "otherwis": [38, 79, 117, 132, 133, 158, 159, 176, 188], "kaim": [38, 76, 108], "uniform": [38, 76, 108, 180, 181], "num_embed": [43, 45], "embedding_dim": [43, 45], "padding_idx": [43, 45], "bag": [43, 44], "binar": [43, 44, 45, 65, 71, 175, 176], "boolean": [43, 44, 51, 117, 150, 151, 164, 165], "experiment": [43, 44, 45, 46, 86, 121, 188], "guarante": [43, 86], "free": [43, 44, 86], "alwai": [43, 44, 45, 46], "due": [43, 44, 46, 51, 91], "natur": [43, 44, 46, 71], "note": [43, 44, 45, 46, 99, 121, 161], "char": 43, "occupi": 43, "per": [43, 85, 176], "thu": [43, 65], "despit": 43, "being": [43, 86, 106, 155], "truli": 43, "import": [43, 168, 184], "consid": [43, 47, 60, 73, 98, 99, 106, 132, 159, 164, 165], "when": [43, 44, 76, 85, 86, 135, 137, 138, 139, 140, 188], "same": 43, "4x": [43, 163], "tradit": [43, 44, 187], "descent": [43, 44, 125], "cannot": [43, 44, 51, 117, 133, 157, 158, 184], "sinc": [43, 44, 65], "do": [43, 44, 64, 89, 99, 100, 101, 104, 115], "instead": [43, 44, 57, 71, 125, 184], "decid": [43, 44], "state": [43, 44, 45, 64, 70, 76, 79, 85, 100, 106, 108, 164, 170, 183], "criteria": [43, 44, 117], "rule": [43, 44], "deriv": [43, 44, 56], "might": [43, 44, 91, 151, 157, 162, 188], "strategi": [43, 44, 106, 136, 138], "flip": [43, 44], "presenc": [43, 44, 151], "absenc": [43, 44, 184], "vote": [43, 44], "system": [43, 44, 133, 143, 145, 157, 158, 188], "across": [43, 44, 85], "multipl": [43, 44, 60, 64, 65, 72, 73, 85, 89, 100, 101, 106, 114, 115, 121, 161, 166, 167], "develop": [43, 44, 183, 185], "care": [43, 44, 46], "consider": [43, 44], "adher": [43, 44, 88, 114], "limit": [43, 44, 117, 170], "characterist": [43, 44, 60], "algebra": [43, 44], "dictionari": [43, 45, 85, 143, 148, 170], "vector": [43, 45, 121], "index": [43, 45, 46, 64, 91, 92, 107, 176, 187], "intern": [43, 45, 70, 100, 108], "share": [43, 45, 100, 108, 179], "scriptmodul": [43, 45, 100, 108], "fetch": [43, 132, 133], "lookup": [44, 46], "major": [44, 145], "ones": 44, "slice": [44, 175], "simpli": 44, "unchang": 44, "futur": [44, 88, 106, 114, 188], "sparse_update_embedding_qweight": [44, 46], "ani": [44, 51, 54, 56, 57, 62, 64, 71, 79, 83, 86, 117, 125, 142, 143, 147, 148, 151, 157, 158, 161, 165, 168, 183, 184, 185, 187], "stage": [45, 121], "uint8": [45, 46, 163], "row": [45, 85, 86, 91, 107, 175, 176], "wise": [45, 64, 70, 86, 175], "setup": [45, 46, 88, 114], "checkpoint": [45, 98, 106, 164, 170], "load": [45, 85, 98, 106, 164, 170, 183], "fill": [45, 166], "seq_length": [46, 162, 171], "matrix": [46, 56, 60, 64, 65, 72, 73, 85, 89, 100, 101, 106, 107, 114, 115, 161, 166], "embed_scal": 46, "ori_embedding_dim": 46, "handl": [46, 57, 64, 65, 71, 73, 79, 85, 91, 92, 103, 125, 179, 184], "flow": [46, 99], "behavior": [46, 86, 151, 183], "conjunct": [46, 89, 115], "most": [46, 70, 106], "suggest": 46, "approach": [46, 106, 187], "here": [46, 100, 151, 188], "exampl": [46, 91, 132, 174, 175, 176, 184, 188], "xor": 46, "grad_weight": [46, 65], "mask": [46, 121], "identifi": [46, 70, 71, 133, 145, 183], "posit": [46, 121, 174, 175, 176, 180, 181], "keep": [46, 98, 188], "elsewher": 46, "manipul": 46, "dynam": [46, 70, 86, 100, 148, 183, 184], "original_embedding_dim": 46, "active_indic": 47, "allow": [47, 56, 60, 85, 89, 101, 106, 115, 164, 165, 168, 170, 174, 183, 184, 187, 188], "spars": [47, 125], "enhanc": [47, 70, 187], "focus": [47, 79, 168], "mixin": [51, 117], "linear": [51, 54, 56, 57, 62, 64, 65, 68, 70, 71, 76, 77, 79, 83, 85, 86, 88, 89, 96, 98, 99, 103, 104, 106, 108, 109, 114, 115, 117, 121, 137, 138, 139, 165, 168], "qlinearimplementationmixin": [51, 79], "clone": [51, 56, 64, 79, 117, 188], "sign": [51, 65, 71, 125, 175, 176, 179], "swishsign": 51, "can_clon": [51, 117], "accord": 51, "recip": [51, 56, 64, 79, 117], "explicitli": 51, "abc": [51, 117], "classmethod": [51, 56, 64, 79, 117], "layerrecip": [51, 56, 64, 79, 117], "str": [51, 117, 126, 132, 136, 137, 138, 139, 140, 142, 143, 147, 148, 150, 151, 152, 155, 157, 158, 164, 170, 183, 184], "among": 51, "either": [51, 57, 71, 106, 151, 163, 168, 174, 187, 188], "along": [51, 121, 122], "string": [51, 117, 136, 145, 150, 151, 158], "empti": [51, 135, 137, 138, 139, 140, 150, 151], "unsupport": 51, "detail": [54, 57, 71, 86, 132, 188], "input_featur": [56, 64, 70, 76, 79], "out_featur": [56, 64, 70, 76, 79, 178], "binarylinearbas": [56, 64, 70, 79], "mix": [56, 64, 85, 86, 88, 89, 92, 93, 106, 114, 115], "binarylinearimplementationmixin": [56, 64], "itself": 56, "easi": 56, "replic": 56, "modif": [56, 183], "divid": [56, 166], "create_clone_from": [56, 64, 79], "instanc": [56, 64, 79, 140, 155, 168, 184, 187], "transform": [56, 57, 65, 79, 85, 88, 98, 114, 121, 162, 168, 175], "clear": 56, "There": [57, 71], "wai": [57, 71], "combin": [57, 60, 71, 162], "staticmethod": [57, 71], "def": [57, 71], "accept": [57, 71], "follow": [57, 71, 91, 157, 158, 188], "see": [57, 71, 138, 151, 188], "more": [57, 60, 71, 85, 100, 106, 188], "2": [57, 71, 85, 88, 100, 101, 106, 107, 114, 127, 136, 143, 150, 157, 161, 187, 188], "separ": [57, 71, 151, 158], "setup_context": [57, 71], "longer": [57, 71], "overrid": [57, 71], "though": [57, 71], "enforc": [57, 71, 85], "thei": [57, 71, 72, 88, 106, 114, 179], "equival": [57, 71, 174, 175, 176], "vjp": [57, 71], "save_for_forward": [57, 71], "jvp": [57, 71], "enumer": [60, 65], "select": [60, 70, 106, 188], "choic": 60, "differ": [60, 79, 85, 89, 91, 106, 115, 125, 179, 185], "underli": [60, 79], "constraint": [60, 65, 85, 98, 117], "bstc32": 60, "softwar": 60, "core": 60, "simul": 60, "flexibl": [60, 85], "cost": [60, 70, 98, 106], "raw": 60, "btc32": 60, "nvidia": [60, 179, 188], "high": [60, 98, 100, 106], "adapt": [60, 64, 85, 106, 125, 188], "best": 60, "capabl": [60, 65, 98, 187, 188], "deep": [60, 65, 88, 114, 125], "preval": 60, "bmm_type": [64, 65], "bmm": [64, 65], "cutlass": [64, 150, 151, 188], "manag": [64, 85, 98, 188], "enum": [64, 133], "hidden": [64, 70, 76, 79, 106, 121], "around": [64, 70, 76], "deploi": [64, 187], "copi": 64, "device_id": 64, "bias": [64, 70, 165], "job": 64, "w_pack": 64, "eval": 65, "receiv": [65, 99], "grad_input": 65, "doesn": 65, "t": [65, 188], "grad_scale_a": 65, "account": [65, 101], "clip": [65, 71, 72, 73, 101], "remain": [65, 176], "within": [65, 70, 71, 91, 98, 106, 125, 132, 135, 137, 138, 139, 140, 150, 157, 158, 168, 174, 180, 181, 188], "reflect": [65, 106], "direct": 65, "incorpor": [70, 170], "gemm": [70, 71], "gemm_kernel_id": [70, 71], "aid": 70, "select_gemm_kernel": 70, "readi": [70, 106, 188], "full": [70, 85, 155, 184, 187], "facilit": [70, 76, 108], "leav": 70, "choos": 70, "one": [70, 98, 106, 185, 187, 188], "id": 70, "warmup": 70, "phase": 70, "begin": [70, 150], "preprocess": 70, "statist": [70, 106], "influenc": 70, "backpropag": [71, 107], "flatten": [71, 162, 171], "back": [71, 85, 121, 161, 171], "reli": 71, "three": [71, 92, 145, 150], "through": [71, 76, 79, 151, 165], "wrap": 72, "binarymatmulfunct": 72, "benefit": 72, "x_clip": [72, 73, 100, 101], "y_clip": [72, 73, 100, 101], "y": [72, 73, 100, 101, 175, 188], "set_activation_scal": [72, 100], "alreadi": [72, 165, 188], "absolut": [72, 98, 157, 179, 188], "e": [73, 107, 132, 159, 185, 188], "g": [73, 107, 132, 185, 188], "128": [73, 136, 167, 181], "better": 73, "threshold": [73, 180, 181], "creation": 76, "foundat": [76, 187], "fulli": [76, 98, 99, 163, 187, 188], "connect": [76, 98, 99], "output_featur": 76, "extern": 76, "_check_forward": [76, 98, 103], "valid": [76, 85, 88, 100, 106, 114, 121, 125], "modifi": [76, 174, 175, 183], "purpos": 76, "disabl": [76, 106], "binari": [79, 86, 125, 161, 163, 165, 168, 174, 175, 176, 185, 187], "access": [79, 91, 183], "use_mbw": [85, 86], "group": [85, 86, 89, 91, 92, 106, 107, 115, 136, 178], "rows_pack": 85, "bitwidth": [85, 86, 100, 108], "mbwq": [85, 86], "mpqlinearbas": [85, 88, 114], "scheme": [85, 104], "run": [85, 125, 133, 145, 184, 188], "fine": [85, 106, 187], "grain": 85, "control": [85, 106], "over": [85, 106, 168, 175], "off": [85, 188], "7": [85, 180], "about": [85, 91, 187], "distribut": [85, 86], "permut": [85, 86, 107], "check_paramet": [85, 88, 106, 114], "chosen": 85, "load_state_dict": 85, "set_scal": 85, "set_zero": 85, "q42fp_weight": 85, "fp": 85, "q4": 85, "exl2fp_weight": 85, "exl2": 85, "against": [85, 143], "q_perm": [85, 86, 107], "q_group_map": [85, 86, 107], "were": [85, 137, 138, 139], "de": 85, "complex": 85, "perhap": 85, "translat": 85, "order": [85, 157, 158], "state_dict": 85, "strict": 85, "case": [85, 86, 145, 184], "dict": [85, 143, 148, 164], "kei": [85, 121, 148, 187], "group_siz": [85, 86, 106, 107, 115, 178], "accur": [85, 106], "associ": [85, 106, 157], "togeth": 85, "crucial": [85, 106, 108, 121], "reshap": [85, 161], "action": 85, "taken": 85, "consist": [86, 91], "privileged_grad": [86, 89, 107], "reorder": 86, "q_weight": 86, "prioriti": 86, "subject": 86, "advanc": 86, "mpq": [88, 89, 106, 114, 115, 136, 138], "fix": [88, 104, 114], "16": [88, 106, 114, 187], "task": [88, 114, 125], "asymmetr": [88, 89, 106, 107, 114, 115], "meet": [88, 114, 117, 126], "decompress": [88, 106, 114], "met": [88, 98, 114], "mainli": [88, 106, 114], "qscale": [88, 106, 114], "qzero": [88, 106, 114], "could": [88, 106, 114], "simplifi": [88, 106, 114, 155], "elimin": [88, 106, 114], "power": [89, 115], "constrain": [89, 115, 121, 187], "environ": [89, 98, 115, 121, 151, 157, 158, 185, 187, 188], "privileg": [89, 107, 115], "mpq_adamw": [89, 115], "g_idx": [89, 107], "asym": [89, 106, 107], "q_group": 91, "num_qrow": 91, "irregular": 91, "organ": 91, "assign": 91, "total": 91, "overal": 91, "short": 91, "invers": [91, 180, 181], "mpqweightparamet": [92, 93, 115], "unpacked_zero": 92, "fp16": [92, 93, 177, 179], "qweightparamet": 92, "main": [92, 106], "gptq": [92, 93, 106, 177, 178], "style": [92, 93, 177, 178, 187], "g_index": [92, 93], "valueerror": [92, 93, 121, 125, 179], "layer_typ": [92, 107, 135], "invalid": 92, "present": [92, 151], "For": [92, 93, 125, 143, 159, 165, 176, 187, 188], "unimpl": 92, "miss": 93, "q": [96, 107], "avoid": [98, 99, 101, 104, 179, 180, 181, 185], "regist": 98, "buffer": [98, 106], "nbitlinearbas": [98, 103, 106], "introduc": [98, 103, 106, 122, 187], "speed": [98, 188], "critic": 98, "remov": [98, 161, 188], "everi": 98, "retain": 98, "q4linear": 99, "parent": [100, 117, 121, 135, 137, 138, 139, 140], "than": [100, 148, 166, 179, 183], "alpha": 100, "ab": 100, "math": 100, "sqrt": 100, "qp": 100, "127": [100, 181], "matmul": 101, "dequant": 101, "reason": [101, 106], "instanti": 101, "q_linear_cutlass": 101, "magnitud": [103, 163], "00001": 103, "verifi": [103, 159], "alter": 103, "use_gba_qu": 106, "dq_group_siz": 106, "dq_mode": 106, "disable_bia": 106, "languag": [106, 187], "llm": [106, 127, 187], "bitwis": [106, 174], "tailor": [106, 143], "platform": [106, 184], "name": [106, 133, 135, 137, 138, 139, 140, 155, 170, 183, 184, 188], "correspondingli": 106, "dimension": [106, 121], "entir": [106, 132], "treat": 106, "gba": 106, "compliant": 106, "doubl": [106, 136], "granular": 106, "cater": 106, "llama": 106, "altern": [106, 188], "init_gptq": 106, "init_gba": 106, "accommod": 106, "asymmetri": 106, "set_qweight_data": 106, "dim": 106, "facter": 106, "symmetri": 106, "relev": 106, "tune": [106, 187], "minim": 106, "infrastructur": 106, "recent": 106, "qscales_zero": 107, "qscales_scal": 107, "qzeros_zero": 107, "qzeros_scal": 107, "affin": 107, "mpqlinear": 107, "mbwqlinear": 107, "rest": 107, "awar": 108, "qat": 108, "framework": 108, "trigger": 108, "mlx": [114, 115, 155, 157, 158, 159, 187], "appl": 114, "accel": 115, "customimplementationmixin": 117, "relat": 117, "describ": 117, "explain": 117, "why": 117, "input_dim": 121, "hidden_dim": 121, "num_head": 121, "multi": 121, "head": 121, "attent": 121, "mha": 121, "deploy": [121, 168], "resourc": [121, 187], "head_dim": 121, "q_linear": 121, "queri": 121, "binarylinearcutlass": 121, "v_linear": 121, "k_linear": 121, "dropout": 121, "final": [121, 166], "project": [121, 127, 187, 188], "still": [121, 185], "evenli": 121, "align": 121, "alert": 121, "user": [121, 125, 184, 188], "hidden_st": 121, "exclud": [121, 165], "score": 121, "out_chn": 122, "beta": 125, "suit": 125, "diod": 125, "reinvent": 125, "guo": 125, "nianhui": 125, "et": 125, "al": 125, "2024": [125, 127], "coeffici": 125, "denomin": 125, "6": [125, 174, 188], "closur": 125, "guid": 125, "sparseadam": 125, "callabl": [125, 140], "reevalu": 125, "required_vers": 126, "except": [126, 133], "below": 126, "galor": 127, "repo": 127, "apach": 127, "licens": 127, "misc": 127, "zhao2024galor": 127, "titl": 127, "rank": [127, 128], "author": [127, 179], "jiawei": 127, "zhao": 127, "zhenyu": 127, "zhang": 127, "beidi": 127, "chen": 127, "zhangyang": 127, "wang": 127, "anima": 127, "anandkumar": 127, "yuandong": 127, "tian": 127, "year": 127, "eprint": 127, "2403": 127, "03507": 127, "archiveprefix": 127, "arxiv": 127, "primaryclass": 127, "lg": 127, "verbos": [128, 132], "update_proj_gap": 128, "200": 128, "proj_typ": 128, "std": 128, "architectur": [131, 133, 143, 148, 165, 187], "search_term": 132, "instruct": [132, 143, 188], "cpuinfo": 132, "search": [132, 150, 151, 157, 158, 187], "sse4_2": 132, "avx2": [132, 143], "found": [132, 145, 150, 151, 157, 158, 184], "print": [132, 184], "get_cpu_info": 132, "quit": 132, "comment": [132, 143], "statement": 132, "product": 132, "linux": [133, 143, 187], "arm": [133, 143], "get_arm_model": 133, "arch_cpu": 133, "predefin": [133, 151, 155, 165, 168, 184], "attempt": [133, 150, 157, 158, 183, 184], "lscpu": 133, "command": [133, 145], "pars": [133, 145], "recogn": 133, "is_arm": 133, "parent_nam": [135, 137, 138, 139, 140], "collect": [135, 145], "layer": [135, 136, 137, 138, 139, 140, 164, 165, 168, 170, 172, 185, 187, 188], "recurs": [135, 140, 188], "usual": [135, 137, 138, 139, 140, 170], "mpq_strategi": [136, 138], "known": [136, 184], "256": 136, "names_to_replac": [137, 138, 139, 140], "replac": [137, 138, 139, 140, 161], "binarylinearcuda": 137, "mpqlinearcuda": 138, "get_mpq_config": 138, "q4linearcutlass": 139, "class_": 140, "replace_fn": 140, "whose": [140, 165, 174], "construct": [140, 148], "done": 140, "collect_lay": 140, "sub": [140, 165], "root_path": [142, 147, 155], "relative_nam": [142, 147, 155], "relative_sourc": [142, 147, 155], "compil": [143, 145, 148, 155, 188], "maco": [143, 187], "include_dir": 143, "look": [143, 157, 158], "header": [143, 150, 157], "link": [143, 155], "vari": 143, "omp": 143, "gomp": 143, "extra_compile_arg": [143, 148], "warn": [143, 148, 184], "openmp": [143, 148, 188], "armv8": 143, "detect": [143, 148], "a55": 143, "a76": 143, "snippet": 143, "show": 143, "condition": [143, 148, 184], "gcc": [145, 148, 188], "gnu": 145, "instal": [145, 157, 158, 185, 187], "subprocess": 145, "extract": 145, "clang": [145, 188], "masquerad": 145, "minor": 145, "patch": 145, "extra": 148, "nvcc": 148, "suppress": 148, "deprec": 148, "declar": 148, "host": 148, "11": [148, 188], "greater": [148, 166], "nest": 148, "cxx": [148, 188], "p": [150, 151, 188], "exist": [150, 151, 183], "locat": [150, 151, 155, 157, 158], "rel": [150, 155, 185, 188], "insid": 150, "3": [150, 157, 188], "structur": [150, 171], "wa": [150, 151], "check_onli": 151, "usr": 151, "local": 151, "cpath": [151, 157, 188], "upon": 151, "union": 151, "check_path": 151, "shown": 151, "success": [151, 184], "root": [155, 188], "resolv": 155, "prefix": [155, 157, 158, 184, 188], "constitut": 155, "possibl": 157, "packag": [157, 158, 168, 185, 188], "submodul": [157, 158], "under": [157, 158, 188], "scan": 157, "libmlx": 158, "dylib": 158, "hypothet": 158, "lib": [158, 188], "In": [158, 187, 188], "library_path": 158, "colon": 158, "unix": 158, "get_mlx_include_path": 159, "get_mlx_lib_path": 159, "shape_pr": 161, "x_pad_sec_last": 161, "y_pad_sec_last": 161, "post": 161, "sever": 161, "truncat": 161, "domain": 161, "formula": 161, "revert": 161, "3d": [162, 171], "hidden_s": 162, "later": [162, 188], "unflatten": [162, 171], "cl": 163, "32x": 163, "preserv": 163, "checkpoint_path": 164, "resum": [164, 170], "invok": 165, "prior": 165, "smallest": 166, "equal": 166, "so": [166, 185], "remaind": 166, "column": [166, 175], "nearest": [167, 180, 181], "round": [167, 180, 181], "those": 168, "well": [168, 188], "comprehens": 168, "statu": 170, "inclus": 170, "filenam": 170, "pth": 170, "abil": 170, "flatten_x": 171, "output_s": 171, "norm_grad": 172, "step_siz": 172, "z_unpack": 172, "var": 174, "po": 174, "val": 174, "OR": 174, "least": 174, "lsb": 174, "0b0010": 174, "0b0110": 174, "nd_col": 175, "binary_col": 175, "dim_n": 175, "dim_k": 175, "bits_per_binary_word": [175, 176], "arrai": [175, 176], "columnar": 175, "encod": 175, "segment": [175, 176], "neg": [175, 176, 179], "v": [175, 185, 188], "proce": 175, "block": 175, "binary_word": [175, 176], "rvalu": [175, 176], "b": 175, "col": 175, "bit_set": [175, 176], "b_col": 175, "nd_row": 176, "binary_row": 176, "nd_size": 176, "ndarrai": 176, "j": [176, 188], "b_row": 176, "amax": 179, "narrow_rang": 179, "narrow": 179, "tensorquantfunct": 179, "faketensorquantfunct": 179, "nv_pytorch_quant": 179, "http": [179, 188], "github": [179, 188], "com": [179, 188], "tensorrt": 179, "blob": 179, "master": 179, "tool": 179, "pytorch_quant": 179, "tensor_qu": 179, "py": 179, "l315": 179, "typeerror": 179, "encount": 179, "fp32": 179, "overflow": 179, "bf16": 179, "smaller": 179, "too": [180, 181], "close": [180, 181], "clamp": [180, 181], "ideal": [180, 181], "fit": [180, 181], "intercept": 183, "misus": 183, "suppos": 183, "promptli": 183, "_name": 183, "__getattr__": 183, "runtimeerror": 183, "__setattr__": 183, "module_nam": 184, "not_yet_impl": 184, "safe": 184, "built": 184, "mark": 184, "importerror": 184, "continu": 184, "gracefulli": 184, "extension_prefix": 184, "immedi": 184, "extensionmoduleplacehold": 184, "binary_linear_cuda": 184, "consol": 184, "issu": 184, "interrupt": 184, "cpp": [185, 188], "bie_build_onli": 185, "bitorch_engin": [185, 187, 188], "qlinear": [185, 187], "pip": [185, 188], "To": [185, 188], "arch": 185, "bie_cuda_arch": 185, "sm_75": 185, "sm_80": 185, "sm_86": 185, "is_avail": 185, "hpc": 185, "docker": [185, 187], "bie_force_cuda": 185, "just": 185, "rebuild": 185, "bie_skip_build": 185, "python3": 185, "isol": 185, "wheel": 185, "would": 185, "try": [185, 188], "bie": 187, "cut": 187, "build": 187, "strength": 187, "technologi": 187, "pioneer": 187, "push": 187, "boundari": 187, "green": 187, "trainer": 187, "leap": 187, "field": 187, "unlik": 187, "few": 187, "trainabl": 187, "lora": 187, "innov": 187, "paradigm": 187, "tightli": 187, "schema": 187, "outset": 187, "showcas": 187, "adept": 187, "stand": 187, "testament": 187, "delic": 187, "balanc": 187, "address": 187, "challeng": 187, "sophist": 187, "track": 187, "changelog": 187, "conda": 187, "forc": 187, "skip": 187, "qconv": 187, "qembed": 187, "qmha": 187, "diode_beta": 187, "galore_projector": 187, "arch_help": 187, "cuda_extens": 187, "cutlass_path": 187, "mlx_extens": 187, "mlx_path": 187, "quant_oper": 187, "safe_import": 187, "page": 187, "enjoi": 187, "explor": 187, "our": [187, 188], "17": 188, "9": 188, "newer": 188, "12": 188, "pleas": 188, "your": 188, "m1": 188, "chip": 188, "recommend": 188, "toolkit": 188, "plan": 188, "10": 188, "bitorch": 188, "engin": 188, "As": 188, "workspac": 188, "dir": 188, "export": 188, "bitorch_workspac": 188, "home": 188, "mkdir": 188, "cd": 188, "env": 188, "label": 188, "url": 188, "greenbit": 188, "ai": 188, "whl": 188, "cu121": 188, "cp310": 188, "linux_x86_64": 188, "pypi": 188, "cuda_hom": 188, "everyth": 188, "etc": 188, "wish": 188, "cu118": 188, "cp39": 188, "cutlass_hom": 188, "older": 188, "cutlass_nvcc_arch": 188, "git": 188, "depth": 188, "branch": 188, "v2": 188, "cmake": 188, "dcmake_install_prefix": 188, "dcutlass_enable_test": 188, "dcutlass_enable_exampl": 188, "dcutlass_nvcc_arch": 188, "75": 188, "80": 188, "86": 188, "difficulti": 188, "offici": 188, "document": 188, "abov": 188, "repositori": 188, "hide": 188, "sure": 188, "greenbitai": 188, "cc": 188, "conda_prefix": 188, "dockerfil": 188, "rm": 188, "volum": 188, "latest": 188, "readm": 188, "virtual": 188, "virtualenv": 188, "macosx": 188, "macosx_11_0_arm64": 188, "homebrew": 188, "brew": 188, "libomp": 188, "remind": 188, "someth": 188, "ldflag": 188, "l": 188, "opt": 188, "cppflag": 188, "mpqlinearlay": 188, "forg": 188, "test": 188, "howev": 188, "5": 188, "now": 188, "abl": 188, "click": 188}, "objects": {"": [[0, 0, 0, "-", "bitorch_engine"]], "bitorch_engine": [[1, 0, 0, "-", "functions"], [12, 0, 0, "-", "layers"], [123, 0, 0, "-", "optim"], [129, 0, 0, "-", "utils"]], "bitorch_engine.functions": [[2, 0, 0, "-", "cuda"]], "bitorch_engine.functions.cuda": [[3, 0, 0, "-", "extension"], [5, 0, 0, "-", "functions"]], "bitorch_engine.functions.cuda.extension": [[4, 1, 1, "", "get_ext"]], "bitorch_engine.functions.cuda.functions": [[6, 1, 1, "", "fp32toint4"], [7, 1, 1, "", "q4_pack_tensor"], [8, 1, 1, "", "q4_unpack_and_scaling_tensor"], [9, 1, 1, "", "q4_unpack_tensor"], [10, 1, 1, "", "tensor_to_packed_uint8"], [11, 1, 1, "", "unpack_uint8_tensor"]], "bitorch_engine.layers": [[13, 0, 0, "-", "qconv"], [40, 0, 0, "-", "qembedding"], [48, 0, 0, "-", "qlinear"], [118, 0, 0, "-", "qmha"]], "bitorch_engine.layers.qconv": [[14, 0, 0, "-", "binary"], [30, 0, 0, "-", "nbit"]], "bitorch_engine.layers.qconv.binary": [[15, 0, 0, "-", "cpp"], [21, 0, 0, "-", "cutlass"], [27, 0, 0, "-", "layer"]], "bitorch_engine.layers.qconv.binary.cpp": [[16, 0, 0, "-", "extension"], [18, 0, 0, "-", "layer"]], "bitorch_engine.layers.qconv.binary.cpp.extension": [[17, 1, 1, "", "get_ext"]], "bitorch_engine.layers.qconv.binary.cpp.layer": [[19, 2, 1, "", "BinaryConv2dCPP"], [20, 2, 1, "", "BinaryConv2dForward"]], "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP": [[19, 3, 1, "", "__init__"], [19, 4, 1, "", "bits_binary_word"], [19, 3, 1, "", "forward"], [19, 3, 1, "", "generate_quantized_weight"], [19, 3, 1, "", "prepare_params"]], "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dForward": [[20, 3, 1, "", "forward"]], "bitorch_engine.layers.qconv.binary.cutlass": [[22, 0, 0, "-", "extension"], [24, 0, 0, "-", "layer"]], "bitorch_engine.layers.qconv.binary.cutlass.extension": [[23, 1, 1, "", "get_ext"]], "bitorch_engine.layers.qconv.binary.cutlass.layer": [[25, 2, 1, "", "BinaryConv2dCutlass"], [26, 2, 1, "", "BinaryConv2dForward"]], "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass": [[25, 3, 1, "", "__init__"], [25, 4, 1, "", "bias_a"], [25, 4, 1, "", "bits_binary_word"], [25, 3, 1, "", "forward"], [25, 3, 1, "", "generate_quantized_weight"], [25, 3, 1, "", "prepare_params"], [25, 4, 1, "", "scale_a"], [25, 4, 1, "", "scale_w"], [25, 3, 1, "", "set_activation"], [25, 3, 1, "", "set_weight_data"]], "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dForward": [[26, 3, 1, "", "backward"], [26, 3, 1, "", "forward"]], "bitorch_engine.layers.qconv.binary.layer": [[28, 2, 1, "", "BinaryConv2dBase"], [29, 2, 1, "", "BinaryConvParameter"]], "bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase": [[28, 3, 1, "", "__init__"], [28, 3, 1, "", "generate_quantized_weight"], [28, 5, 1, "", "opt_weight"], [28, 3, 1, "", "prepare_params"], [28, 3, 1, "", "reset_parameters"], [28, 3, 1, "", "set_bits_binary_word"], [28, 3, 1, "", "set_quantized_weight_data"], [28, 3, 1, "", "set_weight_data"]], "bitorch_engine.layers.qconv.binary.layer.BinaryConvParameter": [[29, 3, 1, "", "update"]], "bitorch_engine.layers.qconv.nbit": [[31, 0, 0, "-", "cutlass"], [37, 0, 0, "-", "layer"]], "bitorch_engine.layers.qconv.nbit.cutlass": [[32, 0, 0, "-", "extension"], [34, 0, 0, "-", "layer"]], "bitorch_engine.layers.qconv.nbit.cutlass.extension": [[33, 1, 1, "", "get_ext"]], "bitorch_engine.layers.qconv.nbit.cutlass.layer": [[35, 2, 1, "", "Q4Conv2dCutlass"], [36, 2, 1, "", "Q4Conv2dCutlassForward"]], "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass": [[35, 3, 1, "", "__init__"], [35, 4, 1, "", "bias_a"], [35, 4, 1, "", "eps"], [35, 3, 1, "", "forward"], [35, 3, 1, "", "generate_quantized_weight"], [35, 3, 1, "", "prepare_params"], [35, 4, 1, "", "scale_a"], [35, 4, 1, "", "scale_w"], [35, 3, 1, "", "set_activation"]], "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward": [[36, 3, 1, "id0", "backward"], [36, 3, 1, "id1", "forward"]], "bitorch_engine.layers.qconv.nbit.layer": [[38, 2, 1, "", "nBitConv2dBase"], [39, 2, 1, "", "nBitConvParameter"]], "bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase": [[38, 3, 1, "", "__init__"], [38, 3, 1, "", "generate_quantized_weight"], [38, 5, 1, "", "opt_weight"], [38, 3, 1, "", "prepare_params"], [38, 3, 1, "", "reset_parameters"], [38, 3, 1, "", "set_quantized_weight_data"], [38, 3, 1, "", "set_weight_data"]], "bitorch_engine.layers.qconv.nbit.layer.nBitConvParameter": [[39, 3, 1, "", "update"]], "bitorch_engine.layers.qembedding": [[41, 0, 0, "-", "binary"]], "bitorch_engine.layers.qembedding.binary": [[42, 0, 0, "-", "layer"]], "bitorch_engine.layers.qembedding.binary.layer": [[43, 2, 1, "", "BinaryEmbeddingBag"], [44, 2, 1, "", "BinaryEmbeddingBagForward"], [45, 2, 1, "", "BinaryEmbeddingCuda"], [46, 2, 1, "", "BinaryEmbeddingForward"], [47, 2, 1, "", "BinaryEmbeddingParameter"]], "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag": [[43, 3, 1, "", "__init__"], [43, 3, 1, "", "forward"], [43, 3, 1, "", "reset_parameters"]], "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward": [[44, 3, 1, "", "backward"], [44, 3, 1, "", "forward"]], "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda": [[45, 3, 1, "", "__init__"], [45, 3, 1, "", "forward"], [45, 3, 1, "", "init_weight"], [45, 3, 1, "", "prepare_params"], [45, 4, 1, "", "qweight"], [45, 3, 1, "", "reset_parameters"], [45, 4, 1, "", "scale_w"], [45, 4, 1, "", "weight"]], "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingForward": [[46, 3, 1, "", "backward"], [46, 3, 1, "", "forward"]], "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingParameter": [[47, 4, 1, "", "active_indices"], [47, 3, 1, "", "update"]], "bitorch_engine.layers.qlinear": [[49, 0, 0, "-", "binary"], [78, 0, 0, "-", "layer"], [80, 0, 0, "-", "nbit"], [116, 0, 0, "-", "qlinear_implementation"]], "bitorch_engine.layers.qlinear.binary": [[50, 0, 0, "-", "binary_implementation"], [52, 0, 0, "-", "cpp"], [58, 0, 0, "-", "cuda"], [66, 0, 0, "-", "cutlass"], [74, 1, 1, "", "get_best_binary_implementation"], [75, 0, 0, "-", "layer"]], "bitorch_engine.layers.qlinear.binary.binary_implementation": [[51, 2, 1, "", "BinaryLinearImplementationMixin"]], "bitorch_engine.layers.qlinear.binary.binary_implementation.BinaryLinearImplementationMixin": [[51, 3, 1, "id0", "can_clone"]], "bitorch_engine.layers.qlinear.binary.cpp": [[53, 0, 0, "-", "extension"], [55, 0, 0, "-", "layer"]], "bitorch_engine.layers.qlinear.binary.cpp.extension": [[54, 1, 1, "", "get_ext"]], "bitorch_engine.layers.qlinear.binary.cpp.layer": [[56, 2, 1, "", "BinaryLinearCPP"], [57, 2, 1, "", "BinaryLinearForward"]], "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP": [[56, 3, 1, "", "__init__"], [56, 3, 1, "", "create_clone_from"], [56, 3, 1, "", "forward"], [56, 3, 1, "", "generate_quantized_weight"], [56, 3, 1, "", "prepare_params"]], "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearForward": [[57, 3, 1, "", "forward"]], "bitorch_engine.layers.qlinear.binary.cuda": [[59, 0, 0, "-", "bmm"], [61, 0, 0, "-", "extension"], [63, 0, 0, "-", "layer"]], "bitorch_engine.layers.qlinear.binary.cuda.bmm": [[60, 2, 1, "", "BMM"]], "bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM": [[60, 4, 1, "", "ADAPTIVE"], [60, 4, 1, "", "BSTC32"], [60, 4, 1, "", "BTC32"]], "bitorch_engine.layers.qlinear.binary.cuda.extension": [[62, 1, 1, "", "get_ext"]], "bitorch_engine.layers.qlinear.binary.cuda.layer": [[64, 2, 1, "", "BinaryLinearCuda"], [65, 2, 1, "", "BinaryLinearForward"]], "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda": [[64, 3, 1, "", "__init__"], [64, 4, 1, "", "bias_a"], [64, 4, 1, "", "bits_binary_word"], [64, 4, 1, "", "bmm_type"], [64, 3, 1, "", "create_clone_from"], [64, 5, 1, "", "device_id"], [64, 3, 1, "", "forward"], [64, 3, 1, "", "generate_quantized_weight"], [64, 3, 1, "", "prepare_params"], [64, 4, 1, "", "scale_a"], [64, 4, 1, "", "scale_w"], [64, 3, 1, "", "set_activation"], [64, 3, 1, "", "set_weight_data"], [64, 3, 1, "", "w_pack"]], "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward": [[65, 3, 1, "", "backward"], [65, 4, 1, "", "bmm_type"], [65, 4, 1, "", "ctx"], [65, 3, 1, "", "forward"], [65, 4, 1, "", "input"], [65, 4, 1, "", "is_train"], [65, 4, 1, "", "scale_a"], [65, 4, 1, "", "scale_w"], [65, 4, 1, "", "weight"]], "bitorch_engine.layers.qlinear.binary.cutlass": [[67, 0, 0, "-", "extension"], [69, 0, 0, "-", "layer"]], "bitorch_engine.layers.qlinear.binary.cutlass.extension": [[68, 1, 1, "", "get_ext"]], "bitorch_engine.layers.qlinear.binary.cutlass.layer": [[70, 2, 1, "", "BinaryLinearCutlass"], [71, 2, 1, "", "BinaryLinearForward"], [72, 2, 1, "", "BinaryMatMul"], [73, 2, 1, "", "BinaryMatMulFunction"]], "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass": [[70, 3, 1, "", "__init__"], [70, 4, 1, "", "bias_a"], [70, 4, 1, "", "bits_binary_word"], [70, 3, 1, "id0", "forward"], [70, 4, 1, "", "gemm_kernel_id"], [70, 3, 1, "id1", "generate_quantized_weight"], [70, 3, 1, "id2", "prepare_params"], [70, 4, 1, "", "scale_a"], [70, 4, 1, "", "scale_w"], [70, 3, 1, "id3", "select_gemm_kernel"], [70, 3, 1, "id4", "set_activation"], [70, 3, 1, "id5", "set_weight_data"]], "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward": [[71, 3, 1, "", "backward"], [71, 3, 1, "", "forward"]], "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul": [[72, 3, 1, "", "__init__"], [72, 4, 1, "", "dtype"], [72, 3, 1, "", "forward"], [72, 3, 1, "", "set_activation_scale"], [72, 4, 1, "", "x_clip"], [72, 4, 1, "", "y_clip"]], "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMulFunction": [[73, 3, 1, "", "backward"], [73, 3, 1, "", "forward"]], "bitorch_engine.layers.qlinear.binary.layer": [[76, 2, 1, "", "BinaryLinearBase"], [77, 2, 1, "", "BinaryLinearParameter"]], "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase": [[76, 3, 1, "", "__init__"], [76, 3, 1, "", "_check_forward"], [76, 4, 1, "", "bits_binary_word"], [76, 4, 1, "", "device"], [76, 4, 1, "", "dtype"], [76, 3, 1, "id0", "generate_quantized_weight"], [76, 4, 1, "", "input_features"], [76, 5, 1, "id1", "opt_weight"], [76, 4, 1, "", "output_features"], [76, 3, 1, "", "prepare_params"], [76, 4, 1, "", "qweight"], [76, 3, 1, "id2", "reset_parameters"], [76, 3, 1, "id3", "set_bits_binary_word"], [76, 3, 1, "id4", "set_quantized_weight_data"], [76, 3, 1, "id5", "set_weight_data"], [76, 4, 1, "", "symmetric"], [76, 4, 1, "", "weight"]], "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearParameter": [[77, 3, 1, "", "update"]], "bitorch_engine.layers.qlinear.layer": [[79, 2, 1, "", "QLinearInf"]], "bitorch_engine.layers.qlinear.layer.QLinearInf": [[79, 3, 1, "", "__init__"], [79, 3, 1, "", "create_clone_from"], [79, 3, 1, "", "forward"], [79, 3, 1, "", "generate_quantized_weight"], [79, 5, 1, "", "opt_weight"], [79, 3, 1, "", "prepare_params"], [79, 3, 1, "", "set_quantized_weight_data"], [79, 3, 1, "", "set_weight_data"], [79, 5, 1, "", "weight"]], "bitorch_engine.layers.qlinear.nbit": [[81, 0, 0, "-", "cuda"], [94, 0, 0, "-", "cutlass"], [105, 0, 0, "-", "layer"], [110, 0, 0, "-", "mps"]], "bitorch_engine.layers.qlinear.nbit.cuda": [[82, 0, 0, "-", "extension"], [84, 0, 0, "-", "mbwq_layer"], [87, 0, 0, "-", "mpq_layer"], [90, 0, 0, "-", "utils"]], "bitorch_engine.layers.qlinear.nbit.cuda.extension": [[83, 1, 1, "", "get_ext"]], "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer": [[85, 2, 1, "", "MBWQLinearCuda"], [86, 2, 1, "", "MBWQLinearCudaFunction"]], "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda": [[85, 3, 1, "", "__init__"], [85, 3, 1, "id0", "check_parameters"], [85, 3, 1, "id1", "exl2fp_weight"], [85, 3, 1, "id2", "forward"], [85, 3, 1, "id3", "load_state_dict"], [85, 3, 1, "id4", "prepare_params"], [85, 3, 1, "id5", "q42fp_weight"], [85, 4, 1, "", "qweight"], [85, 4, 1, "", "rows"], [85, 4, 1, "", "scales"], [85, 3, 1, "id6", "set_scales"], [85, 3, 1, "id7", "set_zeros"], [85, 4, 1, "", "use_mbw"], [85, 4, 1, "", "zeros"]], "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction": [[86, 3, 1, "", "backward"], [86, 3, 1, "", "forward"]], "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer": [[88, 2, 1, "", "MPQLinearCuda"], [89, 2, 1, "", "MPQLinearCudaFunction"]], "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda": [[88, 3, 1, "", "__init__"], [88, 4, 1, "", "a_bit"], [88, 3, 1, "id0", "check_parameters"], [88, 3, 1, "id1", "forward"], [88, 3, 1, "id2", "prepare_params"], [88, 4, 1, "", "qweight"], [88, 4, 1, "", "scales"], [88, 4, 1, "", "w_bit"], [88, 4, 1, "", "zeros"]], "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCudaFunction": [[89, 3, 1, "", "backward"], [89, 3, 1, "", "forward"]], "bitorch_engine.layers.qlinear.nbit.cuda.utils": [[91, 1, 1, "", "make_group_map"], [92, 1, 1, "", "pack_fp_weight"], [93, 1, 1, "", "unpack_qweight"]], "bitorch_engine.layers.qlinear.nbit.cutlass": [[95, 0, 0, "-", "extension"], [97, 0, 0, "-", "q4_layer"], [102, 0, 0, "-", "q8_layer"]], "bitorch_engine.layers.qlinear.nbit.cutlass.extension": [[96, 1, 1, "", "get_ext"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer": [[98, 2, 1, "", "Q4LinearCutlass"], [99, 2, 1, "", "Q4LinearFunction"], [100, 2, 1, "", "Q4MatMul"], [101, 2, 1, "", "Q4MatMulFunction"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass": [[98, 3, 1, "", "__init__"], [98, 3, 1, "", "_check_forward"], [98, 4, 1, "", "bias_a"], [98, 4, 1, "", "eps"], [98, 3, 1, "id0", "forward"], [98, 3, 1, "id1", "generate_quantized_weight"], [98, 3, 1, "id2", "prepare_params"], [98, 4, 1, "", "scale_a"], [98, 4, 1, "", "scale_w"], [98, 3, 1, "id3", "set_activation"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearFunction": [[99, 3, 1, "", "backward"], [99, 3, 1, "", "forward"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul": [[100, 3, 1, "", "__init__"], [100, 4, 1, "", "device"], [100, 4, 1, "", "dtype"], [100, 4, 1, "", "eps"], [100, 3, 1, "", "forward"], [100, 3, 1, "", "set_activation_scale"], [100, 4, 1, "", "x_clip"], [100, 4, 1, "", "y_clip"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMulFunction": [[101, 3, 1, "", "backward"], [101, 3, 1, "", "forward"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer": [[103, 2, 1, "", "Q8LinearCutlass"], [104, 2, 1, "", "Q8LinearFunction"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass": [[103, 3, 1, "", "__init__"], [103, 3, 1, "", "_check_forward"], [103, 4, 1, "", "bias_a"], [103, 4, 1, "", "eps"], [103, 3, 1, "id0", "forward"], [103, 3, 1, "id1", "generate_quantized_weight"], [103, 3, 1, "id2", "prepare_params"], [103, 4, 1, "", "scale_a"], [103, 4, 1, "", "scale_w"], [103, 3, 1, "id3", "set_activation"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearFunction": [[104, 3, 1, "", "backward"], [104, 3, 1, "", "forward"]], "bitorch_engine.layers.qlinear.nbit.layer": [[106, 2, 1, "", "MPQLinearBase"], [107, 2, 1, "", "MPQWeightParameter"], [108, 2, 1, "", "nBitLinearBase"], [109, 2, 1, "", "nBitLinearParameter"]], "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase": [[106, 3, 1, "", "__init__"], [106, 4, 1, "", "a_bit"], [106, 4, 1, "", "asym"], [106, 3, 1, "id0", "check_parameters"], [106, 4, 1, "", "disable_bias"], [106, 4, 1, "", "dq_group_size"], [106, 4, 1, "", "dq_mode"], [106, 4, 1, "", "dtype"], [106, 3, 1, "id1", "generate_quantized_weight"], [106, 4, 1, "", "group_size"], [106, 4, 1, "", "in_channels"], [106, 3, 1, "id2", "init_gba"], [106, 3, 1, "id3", "init_gptq"], [106, 3, 1, "id4", "initialize"], [106, 4, 1, "", "out_channels"], [106, 3, 1, "id5", "prepare_params"], [106, 3, 1, "id6", "set_qweight_data"], [106, 4, 1, "", "use_gba_quant"], [106, 4, 1, "", "w_bit"]], "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter": [[107, 3, 1, "", "__init__"], [107, 4, 1, "", "asym"], [107, 4, 1, "", "g_idx"], [107, 4, 1, "", "group_size"], [107, 4, 1, "", "layer_type"], [107, 4, 1, "", "privileged_grad"], [107, 4, 1, "", "q_group_map"], [107, 4, 1, "", "q_perm"], [107, 4, 1, "", "rows"], [107, 3, 1, "", "update"], [107, 4, 1, "", "w_bit"]], "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase": [[108, 3, 1, "", "__init__"], [108, 4, 1, "", "a_bit"], [108, 4, 1, "", "device"], [108, 4, 1, "", "dtype"], [108, 3, 1, "", "generate_quantized_weight"], [108, 4, 1, "", "in_channels"], [108, 5, 1, "", "opt_weight"], [108, 4, 1, "", "out_channels"], [108, 3, 1, "", "prepare_params"], [108, 3, 1, "", "reset_parameters"], [108, 3, 1, "", "set_quantized_weight_data"], [108, 3, 1, "", "set_weight_data"], [108, 4, 1, "", "w_bit"]], "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearParameter": [[109, 3, 1, "", "update"]], "bitorch_engine.layers.qlinear.nbit.mps": [[111, 0, 0, "-", "extension"], [113, 0, 0, "-", "mpq_layer"]], "bitorch_engine.layers.qlinear.nbit.mps.extension": [[112, 1, 1, "", "get_ext"]], "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer": [[114, 2, 1, "", "MPQLinearMlx"], [115, 2, 1, "", "MPQLinearMlxFunction"]], "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx": [[114, 3, 1, "", "__init__"], [114, 4, 1, "", "a_bit"], [114, 3, 1, "id0", "check_parameters"], [114, 3, 1, "id1", "forward"], [114, 3, 1, "id2", "prepare_params"], [114, 4, 1, "", "qweight"], [114, 4, 1, "", "scales"], [114, 4, 1, "", "w_bit"], [114, 4, 1, "", "zeros"]], "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlxFunction": [[115, 3, 1, "", "backward"], [115, 3, 1, "", "forward"]], "bitorch_engine.layers.qlinear.qlinear_implementation": [[117, 2, 1, "", "QLinearImplementationMixin"]], "bitorch_engine.layers.qlinear.qlinear_implementation.QLinearImplementationMixin": [[117, 3, 1, "", "can_clone"]], "bitorch_engine.layers.qmha": [[119, 0, 0, "-", "binary"]], "bitorch_engine.layers.qmha.binary": [[120, 0, 0, "-", "layer"]], "bitorch_engine.layers.qmha.binary.layer": [[121, 2, 1, "", "BMHA"], [122, 2, 1, "", "LearnableBias"]], "bitorch_engine.layers.qmha.binary.layer.BMHA": [[121, 3, 1, "", "__init__"], [121, 4, 1, "", "dropout"], [121, 4, 1, "", "dtype"], [121, 3, 1, "", "forward"], [121, 4, 1, "", "head_dim"], [121, 4, 1, "", "hidden_dim"], [121, 4, 1, "", "input_dim"], [121, 4, 1, "", "k_linear"], [121, 4, 1, "", "num_heads"], [121, 4, 1, "", "out"], [121, 4, 1, "", "q_linear"], [121, 4, 1, "", "v_linear"]], "bitorch_engine.layers.qmha.binary.layer.LearnableBias": [[122, 3, 1, "", "__init__"], [122, 4, 1, "", "bias"], [122, 3, 1, "", "forward"]], "bitorch_engine.optim": [[124, 0, 0, "-", "diode_beta"], [127, 0, 0, "-", "galore_projector"]], "bitorch_engine.optim.diode_beta": [[125, 2, 1, "", "DiodeMix"], [126, 1, 1, "", "check_pytorch_version"]], "bitorch_engine.optim.diode_beta.DiodeMix": [[125, 3, 1, "id0", "__init__"], [125, 4, 1, "", "betas"], [125, 4, 1, "", "correct_bias"], [125, 4, 1, "", "dtype"], [125, 4, 1, "", "eps"], [125, 4, 1, "", "lr"], [125, 4, 1, "", "params"], [125, 3, 1, "id1", "step"], [125, 4, 1, "", "weight_decay"]], "bitorch_engine.optim.galore_projector": [[128, 2, 1, "", "GaLoreProjector"]], "bitorch_engine.optim.galore_projector.GaLoreProjector": [[128, 3, 1, "", "__init__"]], "bitorch_engine.utils": [[130, 0, 0, "-", "arch_helper"], [134, 0, 0, "-", "convert"], [141, 0, 0, "-", "cpp_extension"], [144, 0, 0, "-", "cuda_extension"], [149, 0, 0, "-", "cutlass_path"], [154, 0, 0, "-", "mlx_extension"], [156, 0, 0, "-", "mlx_path"], [160, 0, 0, "-", "model_helper"], [173, 0, 0, "-", "quant_operators"], [182, 0, 0, "-", "safe_import"]], "bitorch_engine.utils.arch_helper": [[131, 2, 1, "", "ARCH_CPU"], [132, 1, 1, "", "check_cpu_instruction_support"], [133, 2, 1, "", "linux_arch_ident"]], "bitorch_engine.utils.arch_helper.linux_arch_ident": [[133, 3, 1, "", "get_arm_model"], [133, 3, 1, "", "is_arm"]], "bitorch_engine.utils.convert": [[135, 1, 1, "", "collect_layers"], [136, 1, 1, "", "get_mpq_config"], [137, 1, 1, "", "quantize_linear_with_binary_linear_cuda"], [138, 1, 1, "", "quantize_linear_with_mpq_linear_cuda"], [139, 1, 1, "", "quantize_linear_with_q4_linear_cutlass"], [140, 1, 1, "", "replace_layers"]], "bitorch_engine.utils.cpp_extension": [[142, 1, 1, "", "get_cpp_extension"], [143, 1, 1, "", "get_kwargs"]], "bitorch_engine.utils.cuda_extension": [[145, 1, 1, "", "gcc_version"], [146, 1, 1, "", "get_cuda_arch"], [147, 1, 1, "", "get_cuda_extension"], [148, 1, 1, "", "get_kwargs"]], "bitorch_engine.utils.cutlass_path": [[150, 1, 1, "", "check_path"], [151, 1, 1, "", "find_cutlass"], [152, 1, 1, "", "get_cutlass_include_path"], [153, 1, 1, "", "is_cutlass_available"]], "bitorch_engine.utils.mlx_extension": [[155, 1, 1, "", "get_mlx_extension"]], "bitorch_engine.utils.mlx_path": [[157, 1, 1, "", "get_mlx_include_path"], [158, 1, 1, "", "get_mlx_lib_path"], [159, 1, 1, "", "is_mlx_available"]], "bitorch_engine.utils.model_helper": [[161, 1, 1, "", "binary_matmul_forward_post_processing"], [162, 1, 1, "", "flatten_x"], [163, 1, 1, "", "init_weight"], [164, 1, 1, "", "load_checkpoint"], [165, 1, 1, "", "pack_bie_layers"], [166, 1, 1, "", "pad_embedding_dim"], [167, 1, 1, "", "pad_last_2_dims_to_multiple_of_128"], [168, 1, 1, "", "prepare_bie_layers"], [169, 1, 1, "", "qweight_update_fn"], [170, 1, 1, "", "save_checkpoint"], [171, 1, 1, "", "unflatten_x"], [172, 1, 1, "", "update_zeros"]], "bitorch_engine.utils.quant_operators": [[174, 1, 1, "", "bit_set"], [175, 1, 1, "", "get_binary_col"], [176, 1, 1, "", "get_binary_row"], [177, 1, 1, "", "gptq_style_unpacking"], [178, 1, 1, "", "gptq_style_zeros_packing"], [179, 1, 1, "", "nv_tensor_quant"], [180, 1, 1, "", "q4_quantization"], [181, 1, 1, "", "q8_quantization"]], "bitorch_engine.utils.safe_import": [[183, 2, 1, "", "ExtensionModulePlaceholder"], [184, 1, 1, "", "import_extension"]], "bitorch_engine.utils.safe_import.ExtensionModulePlaceholder": [[183, 3, 1, "", "__getattr__"], [183, 3, 1, "id0", "__init__"], [183, 3, 1, "", "__setattr__"], [183, 4, 1, "", "_name"]]}, "objtypes": {"0": "py:module", "1": "py:function", "2": "py:class", "3": "py:method", "4": "py:attribute", "5": "py:property"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "function", "Python function"], "2": ["py", "class", "Python class"], "3": ["py", "method", "Python method"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "property", "Python property"]}, "titleterms": {"bitorch_engin": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184], "function": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "cuda": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 58, 59, 60, 61, 62, 63, 64, 65, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 185, 188], "extens": [3, 4, 16, 17, 22, 23, 32, 33, 53, 54, 61, 62, 67, 68, 82, 83, 95, 96, 111, 112, 185], "get_ext": [4, 17, 23, 33, 54, 62, 68, 83, 96, 112], "fp32toint4": 6, "q4_pack_tensor": 7, "q4_unpack_and_scaling_tensor": 8, "q4_unpack_tensor": 9, "tensor_to_packed_uint8": 10, "unpack_uint8_tensor": 11, "layer": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122], "qconv": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39], "binari": [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 119, 120, 121, 122, 188], "cpp": [15, 16, 17, 18, 19, 20, 52, 53, 54, 55, 56, 57], "binaryconv2dcpp": 19, "binaryconv2dforward": [20, 26], "cutlass": [21, 22, 23, 24, 25, 26, 31, 32, 33, 34, 35, 36, 66, 67, 68, 69, 70, 71, 72, 73, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104], "binaryconv2dcutlass": 25, "binaryconv2dbas": 28, "binaryconvparamet": 29, "nbit": [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], "q4conv2dcutlass": 35, "q4conv2dcutlassforward": 36, "nbitconv2dbas": 38, "nbitconvparamet": 39, "qembed": [40, 41, 42, 43, 44, 45, 46, 47], "binaryembeddingbag": 43, "binaryembeddingbagforward": 44, "binaryembeddingcuda": 45, "binaryembeddingforward": 46, "binaryembeddingparamet": 47, "qlinear": [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "binary_implement": [50, 51], "binarylinearimplementationmixin": 51, "binarylinearcpp": 56, "binarylinearforward": [57, 65, 71], "bmm": [59, 60], "binarylinearcuda": 64, "binarylinearcutlass": 70, "binarymatmul": 72, "binarymatmulfunct": 73, "get_best_binary_implement": 74, "binarylinearbas": 76, "binarylinearparamet": 77, "qlinearinf": 79, "mbwq_layer": [84, 85, 86], "mbwqlinearcuda": 85, "mbwqlinearcudafunct": 86, "mpq_layer": [87, 88, 89, 113, 114, 115], "mpqlinearcuda": 88, "mpqlinearcudafunct": 89, "util": [90, 91, 92, 93, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184], "make_group_map": 91, "pack_fp_weight": 92, "unpack_qweight": 93, "q4_layer": [97, 98, 99, 100, 101], "q4linearcutlass": 98, "q4linearfunct": 99, "q4matmul": 100, "q4matmulfunct": 101, "q8_layer": [102, 103, 104], "q8linearcutlass": 103, "q8linearfunct": 104, "mpqlinearbas": 106, "mpqweightparamet": 107, "nbitlinearbas": 108, "nbitlinearparamet": 109, "mp": [110, 111, 112, 113, 114, 115], "mpqlinearmlx": 114, "mpqlinearmlxfunct": 115, "qlinear_implement": [116, 117], "qlinearimplementationmixin": 117, "qmha": [118, 119, 120, 121, 122], "bmha": 121, "learnablebia": 122, "optim": [123, 124, 125, 126, 127, 128], "diode_beta": [124, 125, 126], "diodemix": 125, "check_pytorch_vers": 126, "galore_projector": [127, 128], "galoreprojector": 128, "arch_help": [130, 131, 132, 133], "arch_cpu": 131, "check_cpu_instruction_support": 132, "linux_arch_id": 133, "convert": [134, 135, 136, 137, 138, 139, 140], "collect_lay": 135, "get_mpq_config": 136, "quantize_linear_with_binary_linear_cuda": 137, "quantize_linear_with_mpq_linear_cuda": 138, "quantize_linear_with_q4_linear_cutlass": 139, "replace_lay": 140, "cpp_extens": [141, 142, 143], "get_cpp_extens": 142, "get_kwarg": [143, 148], "cuda_extens": [144, 145, 146, 147, 148], "gcc_version": 145, "get_cuda_arch": 146, "get_cuda_extens": 147, "cutlass_path": [149, 150, 151, 152, 153], "check_path": 150, "find_cutlass": 151, "get_cutlass_include_path": 152, "is_cutlass_avail": 153, "mlx_extens": [154, 155], "get_mlx_extens": 155, "mlx_path": [156, 157, 158, 159], "get_mlx_include_path": 157, "get_mlx_lib_path": 158, "is_mlx_avail": 159, "model_help": [160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172], "binary_matmul_forward_post_process": 161, "flatten_x": 162, "init_weight": 163, "load_checkpoint": 164, "pack_bie_lay": 165, "pad_embedding_dim": 166, "pad_last_2_dims_to_multiple_of_128": 167, "prepare_bie_lay": 168, "qweight_update_fn": 169, "save_checkpoint": 170, "unflatten_x": 171, "update_zero": 172, "quant_oper": [173, 174, 175, 176, 177, 178, 179, 180, 181], "bit_set": 174, "get_binary_col": 175, "get_binary_row": 176, "gptq_style_unpack": 177, "gptq_style_zeros_pack": 178, "nv_tensor_qu": 179, "q4_quantiz": 180, "q8_quantiz": 181, "safe_import": [182, 183, 184], "extensionmoduleplacehold": 183, "import_extens": 184, "build": [185, 188], "option": 185, "specif": 185, "architectur": 185, "forc": 185, "modul": 185, "skip": 185, "librari": 185, "file": 185, "full": 186, "document": [186, 187], "welcom": 187, "bitorch": 187, "engin": 187, "": 187, "content": 187, "indic": 187, "tabl": 187, "instal": 188, "releas": 188, "from": 188, "sourc": 188, "conda": 188, "linux": 188, "docker": 188, "maco": 188, "mlx": 188}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx.ext.intersphinx": 1, "sphinx": 60}, "alltitles": {"bitorch_engine": [[0, "module-bitorch_engine"]], "bitorch_engine.functions": [[1, "module-bitorch_engine.functions"]], "bitorch_engine.functions.cuda": [[2, "module-bitorch_engine.functions.cuda"]], "bitorch_engine.functions.cuda.extension": [[3, "module-bitorch_engine.functions.cuda.extension"]], "bitorch_engine.functions.cuda.extension.get_ext": [[4, "bitorch-engine-functions-cuda-extension-get-ext"]], "bitorch_engine.functions.cuda.functions": [[5, "module-bitorch_engine.functions.cuda.functions"]], "bitorch_engine.functions.cuda.functions.fp32toint4": [[6, "bitorch-engine-functions-cuda-functions-fp32toint4"]], "bitorch_engine.functions.cuda.functions.q4_pack_tensor": [[7, "bitorch-engine-functions-cuda-functions-q4-pack-tensor"]], "bitorch_engine.functions.cuda.functions.q4_unpack_and_scaling_tensor": [[8, "bitorch-engine-functions-cuda-functions-q4-unpack-and-scaling-tensor"]], "bitorch_engine.functions.cuda.functions.q4_unpack_tensor": [[9, "bitorch-engine-functions-cuda-functions-q4-unpack-tensor"]], "bitorch_engine.functions.cuda.functions.tensor_to_packed_uint8": [[10, "bitorch-engine-functions-cuda-functions-tensor-to-packed-uint8"]], "bitorch_engine.functions.cuda.functions.unpack_uint8_tensor": [[11, "bitorch-engine-functions-cuda-functions-unpack-uint8-tensor"]], "bitorch_engine.layers": [[12, "module-bitorch_engine.layers"]], "bitorch_engine.layers.qconv": [[13, "module-bitorch_engine.layers.qconv"]], "bitorch_engine.layers.qconv.binary": [[14, "module-bitorch_engine.layers.qconv.binary"]], "bitorch_engine.layers.qconv.binary.cpp": [[15, "module-bitorch_engine.layers.qconv.binary.cpp"]], "bitorch_engine.layers.qconv.binary.cpp.extension": [[16, "module-bitorch_engine.layers.qconv.binary.cpp.extension"]], "bitorch_engine.layers.qconv.binary.cpp.extension.get_ext": [[17, "bitorch-engine-layers-qconv-binary-cpp-extension-get-ext"]], "bitorch_engine.layers.qconv.binary.cpp.layer": [[18, "module-bitorch_engine.layers.qconv.binary.cpp.layer"]], "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP": [[19, "bitorch-engine-layers-qconv-binary-cpp-layer-binaryconv2dcpp"]], "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dForward": [[20, "bitorch-engine-layers-qconv-binary-cpp-layer-binaryconv2dforward"]], "bitorch_engine.layers.qconv.binary.cutlass": [[21, "module-bitorch_engine.layers.qconv.binary.cutlass"]], "bitorch_engine.layers.qconv.binary.cutlass.extension": [[22, "module-bitorch_engine.layers.qconv.binary.cutlass.extension"]], "bitorch_engine.layers.qconv.binary.cutlass.extension.get_ext": [[23, "bitorch-engine-layers-qconv-binary-cutlass-extension-get-ext"]], "bitorch_engine.layers.qconv.binary.cutlass.layer": [[24, "module-bitorch_engine.layers.qconv.binary.cutlass.layer"]], "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass": [[25, "bitorch-engine-layers-qconv-binary-cutlass-layer-binaryconv2dcutlass"]], "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dForward": [[26, "bitorch-engine-layers-qconv-binary-cutlass-layer-binaryconv2dforward"]], "bitorch_engine.layers.qconv.binary.layer": [[27, "module-bitorch_engine.layers.qconv.binary.layer"]], "bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase": [[28, "bitorch-engine-layers-qconv-binary-layer-binaryconv2dbase"]], "bitorch_engine.layers.qconv.binary.layer.BinaryConvParameter": [[29, "bitorch-engine-layers-qconv-binary-layer-binaryconvparameter"]], "bitorch_engine.layers.qconv.nbit": [[30, "module-bitorch_engine.layers.qconv.nbit"]], "bitorch_engine.layers.qconv.nbit.cutlass": [[31, "module-bitorch_engine.layers.qconv.nbit.cutlass"]], "bitorch_engine.layers.qconv.nbit.cutlass.extension": [[32, "module-bitorch_engine.layers.qconv.nbit.cutlass.extension"]], "bitorch_engine.layers.qconv.nbit.cutlass.extension.get_ext": [[33, "bitorch-engine-layers-qconv-nbit-cutlass-extension-get-ext"]], "bitorch_engine.layers.qconv.nbit.cutlass.layer": [[34, "module-bitorch_engine.layers.qconv.nbit.cutlass.layer"]], "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass": [[35, "bitorch-engine-layers-qconv-nbit-cutlass-layer-q4conv2dcutlass"]], "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward": [[36, "bitorch-engine-layers-qconv-nbit-cutlass-layer-q4conv2dcutlassforward"]], "bitorch_engine.layers.qconv.nbit.layer": [[37, "module-bitorch_engine.layers.qconv.nbit.layer"]], "bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase": [[38, "bitorch-engine-layers-qconv-nbit-layer-nbitconv2dbase"]], "bitorch_engine.layers.qconv.nbit.layer.nBitConvParameter": [[39, "bitorch-engine-layers-qconv-nbit-layer-nbitconvparameter"]], "bitorch_engine.layers.qembedding": [[40, "module-bitorch_engine.layers.qembedding"]], "bitorch_engine.layers.qembedding.binary": [[41, "module-bitorch_engine.layers.qembedding.binary"]], "bitorch_engine.layers.qembedding.binary.layer": [[42, "module-bitorch_engine.layers.qembedding.binary.layer"]], "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag": [[43, "bitorch-engine-layers-qembedding-binary-layer-binaryembeddingbag"]], "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward": [[44, "bitorch-engine-layers-qembedding-binary-layer-binaryembeddingbagforward"]], "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda": [[45, "bitorch-engine-layers-qembedding-binary-layer-binaryembeddingcuda"]], "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingForward": [[46, "bitorch-engine-layers-qembedding-binary-layer-binaryembeddingforward"]], "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingParameter": [[47, "bitorch-engine-layers-qembedding-binary-layer-binaryembeddingparameter"]], "bitorch_engine.layers.qlinear": [[48, "module-bitorch_engine.layers.qlinear"]], "bitorch_engine.layers.qlinear.binary": [[49, "module-bitorch_engine.layers.qlinear.binary"]], "bitorch_engine.layers.qlinear.binary.binary_implementation": [[50, "module-bitorch_engine.layers.qlinear.binary.binary_implementation"]], "bitorch_engine.layers.qlinear.binary.binary_implementation.BinaryLinearImplementationMixin": [[51, "bitorch-engine-layers-qlinear-binary-binary-implementation-binarylinearimplementationmixin"]], "bitorch_engine.layers.qlinear.binary.cpp": [[52, "module-bitorch_engine.layers.qlinear.binary.cpp"]], "bitorch_engine.layers.qlinear.binary.cpp.extension": [[53, "module-bitorch_engine.layers.qlinear.binary.cpp.extension"]], "bitorch_engine.layers.qlinear.binary.cpp.extension.get_ext": [[54, "bitorch-engine-layers-qlinear-binary-cpp-extension-get-ext"]], "bitorch_engine.layers.qlinear.binary.cpp.layer": [[55, "module-bitorch_engine.layers.qlinear.binary.cpp.layer"]], "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP": [[56, "bitorch-engine-layers-qlinear-binary-cpp-layer-binarylinearcpp"]], "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearForward": [[57, "bitorch-engine-layers-qlinear-binary-cpp-layer-binarylinearforward"]], "bitorch_engine.layers.qlinear.binary.cuda": [[58, "module-bitorch_engine.layers.qlinear.binary.cuda"]], "bitorch_engine.layers.qlinear.binary.cuda.bmm": [[59, "module-bitorch_engine.layers.qlinear.binary.cuda.bmm"]], "bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM": [[60, "bitorch-engine-layers-qlinear-binary-cuda-bmm-bmm"]], "bitorch_engine.layers.qlinear.binary.cuda.extension": [[61, "module-bitorch_engine.layers.qlinear.binary.cuda.extension"]], "bitorch_engine.layers.qlinear.binary.cuda.extension.get_ext": [[62, "bitorch-engine-layers-qlinear-binary-cuda-extension-get-ext"]], "bitorch_engine.layers.qlinear.binary.cuda.layer": [[63, "module-bitorch_engine.layers.qlinear.binary.cuda.layer"]], "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda": [[64, "bitorch-engine-layers-qlinear-binary-cuda-layer-binarylinearcuda"]], "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward": [[65, "bitorch-engine-layers-qlinear-binary-cuda-layer-binarylinearforward"]], "bitorch_engine.layers.qlinear.binary.cutlass": [[66, "module-bitorch_engine.layers.qlinear.binary.cutlass"]], "bitorch_engine.layers.qlinear.binary.cutlass.extension": [[67, "module-bitorch_engine.layers.qlinear.binary.cutlass.extension"]], "bitorch_engine.layers.qlinear.binary.cutlass.extension.get_ext": [[68, "bitorch-engine-layers-qlinear-binary-cutlass-extension-get-ext"]], "bitorch_engine.layers.qlinear.binary.cutlass.layer": [[69, "module-bitorch_engine.layers.qlinear.binary.cutlass.layer"]], "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass": [[70, "bitorch-engine-layers-qlinear-binary-cutlass-layer-binarylinearcutlass"]], "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward": [[71, "bitorch-engine-layers-qlinear-binary-cutlass-layer-binarylinearforward"]], "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul": [[72, "bitorch-engine-layers-qlinear-binary-cutlass-layer-binarymatmul"]], "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMulFunction": [[73, "bitorch-engine-layers-qlinear-binary-cutlass-layer-binarymatmulfunction"]], "bitorch_engine.layers.qlinear.binary.get_best_binary_implementation": [[74, "bitorch-engine-layers-qlinear-binary-get-best-binary-implementation"]], "bitorch_engine.layers.qlinear.binary.layer": [[75, "module-bitorch_engine.layers.qlinear.binary.layer"]], "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase": [[76, "bitorch-engine-layers-qlinear-binary-layer-binarylinearbase"]], "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearParameter": [[77, "bitorch-engine-layers-qlinear-binary-layer-binarylinearparameter"]], "bitorch_engine.layers.qlinear.layer": [[78, "module-bitorch_engine.layers.qlinear.layer"]], "bitorch_engine.layers.qlinear.layer.QLinearInf": [[79, "bitorch-engine-layers-qlinear-layer-qlinearinf"]], "bitorch_engine.layers.qlinear.nbit": [[80, "module-bitorch_engine.layers.qlinear.nbit"]], "bitorch_engine.layers.qlinear.nbit.cuda": [[81, "module-bitorch_engine.layers.qlinear.nbit.cuda"]], "bitorch_engine.layers.qlinear.nbit.cuda.extension": [[82, "module-bitorch_engine.layers.qlinear.nbit.cuda.extension"]], "bitorch_engine.layers.qlinear.nbit.cuda.extension.get_ext": [[83, "bitorch-engine-layers-qlinear-nbit-cuda-extension-get-ext"]], "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer": [[84, "module-bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer"]], "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda": [[85, "bitorch-engine-layers-qlinear-nbit-cuda-mbwq-layer-mbwqlinearcuda"]], "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction": [[86, "bitorch-engine-layers-qlinear-nbit-cuda-mbwq-layer-mbwqlinearcudafunction"]], "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer": [[87, "module-bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer"]], "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda": [[88, "bitorch-engine-layers-qlinear-nbit-cuda-mpq-layer-mpqlinearcuda"]], "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCudaFunction": [[89, "bitorch-engine-layers-qlinear-nbit-cuda-mpq-layer-mpqlinearcudafunction"]], "bitorch_engine.layers.qlinear.nbit.cuda.utils": [[90, "module-bitorch_engine.layers.qlinear.nbit.cuda.utils"]], "bitorch_engine.layers.qlinear.nbit.cuda.utils.make_group_map": [[91, "bitorch-engine-layers-qlinear-nbit-cuda-utils-make-group-map"]], "bitorch_engine.layers.qlinear.nbit.cuda.utils.pack_fp_weight": [[92, "bitorch-engine-layers-qlinear-nbit-cuda-utils-pack-fp-weight"]], "bitorch_engine.layers.qlinear.nbit.cuda.utils.unpack_qweight": [[93, "bitorch-engine-layers-qlinear-nbit-cuda-utils-unpack-qweight"]], "bitorch_engine.layers.qlinear.nbit.cutlass": [[94, "module-bitorch_engine.layers.qlinear.nbit.cutlass"]], "bitorch_engine.layers.qlinear.nbit.cutlass.extension": [[95, "module-bitorch_engine.layers.qlinear.nbit.cutlass.extension"]], "bitorch_engine.layers.qlinear.nbit.cutlass.extension.get_ext": [[96, "bitorch-engine-layers-qlinear-nbit-cutlass-extension-get-ext"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer": [[97, "module-bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass": [[98, "bitorch-engine-layers-qlinear-nbit-cutlass-q4-layer-q4linearcutlass"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearFunction": [[99, "bitorch-engine-layers-qlinear-nbit-cutlass-q4-layer-q4linearfunction"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul": [[100, "bitorch-engine-layers-qlinear-nbit-cutlass-q4-layer-q4matmul"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMulFunction": [[101, "bitorch-engine-layers-qlinear-nbit-cutlass-q4-layer-q4matmulfunction"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer": [[102, "module-bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass": [[103, "bitorch-engine-layers-qlinear-nbit-cutlass-q8-layer-q8linearcutlass"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearFunction": [[104, "bitorch-engine-layers-qlinear-nbit-cutlass-q8-layer-q8linearfunction"]], "bitorch_engine.layers.qlinear.nbit.layer": [[105, "module-bitorch_engine.layers.qlinear.nbit.layer"]], "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase": [[106, "bitorch-engine-layers-qlinear-nbit-layer-mpqlinearbase"]], "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter": [[107, "bitorch-engine-layers-qlinear-nbit-layer-mpqweightparameter"]], "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase": [[108, "bitorch-engine-layers-qlinear-nbit-layer-nbitlinearbase"]], "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearParameter": [[109, "bitorch-engine-layers-qlinear-nbit-layer-nbitlinearparameter"]], "bitorch_engine.layers.qlinear.nbit.mps": [[110, "module-bitorch_engine.layers.qlinear.nbit.mps"]], "bitorch_engine.layers.qlinear.nbit.mps.extension": [[111, "module-bitorch_engine.layers.qlinear.nbit.mps.extension"]], "bitorch_engine.layers.qlinear.nbit.mps.extension.get_ext": [[112, "bitorch-engine-layers-qlinear-nbit-mps-extension-get-ext"]], "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer": [[113, "module-bitorch_engine.layers.qlinear.nbit.mps.mpq_layer"]], "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx": [[114, "bitorch-engine-layers-qlinear-nbit-mps-mpq-layer-mpqlinearmlx"]], "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlxFunction": [[115, "bitorch-engine-layers-qlinear-nbit-mps-mpq-layer-mpqlinearmlxfunction"]], "bitorch_engine.layers.qlinear.qlinear_implementation": [[116, "module-bitorch_engine.layers.qlinear.qlinear_implementation"]], "bitorch_engine.layers.qlinear.qlinear_implementation.QLinearImplementationMixin": [[117, "bitorch-engine-layers-qlinear-qlinear-implementation-qlinearimplementationmixin"]], "bitorch_engine.layers.qmha": [[118, "module-bitorch_engine.layers.qmha"]], "bitorch_engine.layers.qmha.binary": [[119, "module-bitorch_engine.layers.qmha.binary"]], "bitorch_engine.layers.qmha.binary.layer": [[120, "module-bitorch_engine.layers.qmha.binary.layer"]], "bitorch_engine.layers.qmha.binary.layer.BMHA": [[121, "bitorch-engine-layers-qmha-binary-layer-bmha"]], "bitorch_engine.layers.qmha.binary.layer.LearnableBias": [[122, "bitorch-engine-layers-qmha-binary-layer-learnablebias"]], "bitorch_engine.optim": [[123, "module-bitorch_engine.optim"]], "bitorch_engine.optim.diode_beta": [[124, "module-bitorch_engine.optim.diode_beta"]], "bitorch_engine.optim.diode_beta.DiodeMix": [[125, "bitorch-engine-optim-diode-beta-diodemix"]], "bitorch_engine.optim.diode_beta.check_pytorch_version": [[126, "bitorch-engine-optim-diode-beta-check-pytorch-version"]], "bitorch_engine.optim.galore_projector": [[127, "module-bitorch_engine.optim.galore_projector"]], "bitorch_engine.optim.galore_projector.GaLoreProjector": [[128, "bitorch-engine-optim-galore-projector-galoreprojector"]], "bitorch_engine.utils": [[129, "module-bitorch_engine.utils"]], "bitorch_engine.utils.arch_helper": [[130, "module-bitorch_engine.utils.arch_helper"]], "bitorch_engine.utils.arch_helper.ARCH_CPU": [[131, "bitorch-engine-utils-arch-helper-arch-cpu"]], "bitorch_engine.utils.arch_helper.check_cpu_instruction_support": [[132, "bitorch-engine-utils-arch-helper-check-cpu-instruction-support"]], "bitorch_engine.utils.arch_helper.linux_arch_ident": [[133, "bitorch-engine-utils-arch-helper-linux-arch-ident"]], "bitorch_engine.utils.convert": [[134, "module-bitorch_engine.utils.convert"]], "bitorch_engine.utils.convert.collect_layers": [[135, "bitorch-engine-utils-convert-collect-layers"]], "bitorch_engine.utils.convert.get_mpq_config": [[136, "bitorch-engine-utils-convert-get-mpq-config"]], "bitorch_engine.utils.convert.quantize_linear_with_binary_linear_cuda": [[137, "bitorch-engine-utils-convert-quantize-linear-with-binary-linear-cuda"]], "bitorch_engine.utils.convert.quantize_linear_with_mpq_linear_cuda": [[138, "bitorch-engine-utils-convert-quantize-linear-with-mpq-linear-cuda"]], "bitorch_engine.utils.convert.quantize_linear_with_q4_linear_cutlass": [[139, "bitorch-engine-utils-convert-quantize-linear-with-q4-linear-cutlass"]], "bitorch_engine.utils.convert.replace_layers": [[140, "bitorch-engine-utils-convert-replace-layers"]], "bitorch_engine.utils.cpp_extension": [[141, "module-bitorch_engine.utils.cpp_extension"]], "bitorch_engine.utils.cpp_extension.get_cpp_extension": [[142, "bitorch-engine-utils-cpp-extension-get-cpp-extension"]], "bitorch_engine.utils.cpp_extension.get_kwargs": [[143, "bitorch-engine-utils-cpp-extension-get-kwargs"]], "bitorch_engine.utils.cuda_extension": [[144, "module-bitorch_engine.utils.cuda_extension"]], "bitorch_engine.utils.cuda_extension.gcc_version": [[145, "bitorch-engine-utils-cuda-extension-gcc-version"]], "bitorch_engine.utils.cuda_extension.get_cuda_arch": [[146, "bitorch-engine-utils-cuda-extension-get-cuda-arch"]], "bitorch_engine.utils.cuda_extension.get_cuda_extension": [[147, "bitorch-engine-utils-cuda-extension-get-cuda-extension"]], "bitorch_engine.utils.cuda_extension.get_kwargs": [[148, "bitorch-engine-utils-cuda-extension-get-kwargs"]], "bitorch_engine.utils.cutlass_path": [[149, "module-bitorch_engine.utils.cutlass_path"]], "bitorch_engine.utils.cutlass_path.check_path": [[150, "bitorch-engine-utils-cutlass-path-check-path"]], "bitorch_engine.utils.cutlass_path.find_cutlass": [[151, "bitorch-engine-utils-cutlass-path-find-cutlass"]], "bitorch_engine.utils.cutlass_path.get_cutlass_include_path": [[152, "bitorch-engine-utils-cutlass-path-get-cutlass-include-path"]], "bitorch_engine.utils.cutlass_path.is_cutlass_available": [[153, "bitorch-engine-utils-cutlass-path-is-cutlass-available"]], "bitorch_engine.utils.mlx_extension": [[154, "module-bitorch_engine.utils.mlx_extension"]], "bitorch_engine.utils.mlx_extension.get_mlx_extension": [[155, "bitorch-engine-utils-mlx-extension-get-mlx-extension"]], "bitorch_engine.utils.mlx_path": [[156, "module-bitorch_engine.utils.mlx_path"]], "bitorch_engine.utils.mlx_path.get_mlx_include_path": [[157, "bitorch-engine-utils-mlx-path-get-mlx-include-path"]], "bitorch_engine.utils.mlx_path.get_mlx_lib_path": [[158, "bitorch-engine-utils-mlx-path-get-mlx-lib-path"]], "bitorch_engine.utils.mlx_path.is_mlx_available": [[159, "bitorch-engine-utils-mlx-path-is-mlx-available"]], "bitorch_engine.utils.model_helper": [[160, "module-bitorch_engine.utils.model_helper"]], "bitorch_engine.utils.model_helper.binary_matmul_forward_post_processing": [[161, "bitorch-engine-utils-model-helper-binary-matmul-forward-post-processing"]], "bitorch_engine.utils.model_helper.flatten_x": [[162, "bitorch-engine-utils-model-helper-flatten-x"]], "bitorch_engine.utils.model_helper.init_weight": [[163, "bitorch-engine-utils-model-helper-init-weight"]], "bitorch_engine.utils.model_helper.load_checkpoint": [[164, "bitorch-engine-utils-model-helper-load-checkpoint"]], "bitorch_engine.utils.model_helper.pack_bie_layers": [[165, "bitorch-engine-utils-model-helper-pack-bie-layers"]], "bitorch_engine.utils.model_helper.pad_embedding_dim": [[166, "bitorch-engine-utils-model-helper-pad-embedding-dim"]], "bitorch_engine.utils.model_helper.pad_last_2_dims_to_multiple_of_128": [[167, "bitorch-engine-utils-model-helper-pad-last-2-dims-to-multiple-of-128"]], "bitorch_engine.utils.model_helper.prepare_bie_layers": [[168, "bitorch-engine-utils-model-helper-prepare-bie-layers"]], "bitorch_engine.utils.model_helper.qweight_update_fn": [[169, "bitorch-engine-utils-model-helper-qweight-update-fn"]], "bitorch_engine.utils.model_helper.save_checkpoint": [[170, "bitorch-engine-utils-model-helper-save-checkpoint"]], "bitorch_engine.utils.model_helper.unflatten_x": [[171, "bitorch-engine-utils-model-helper-unflatten-x"]], "bitorch_engine.utils.model_helper.update_zeros": [[172, "bitorch-engine-utils-model-helper-update-zeros"]], "bitorch_engine.utils.quant_operators": [[173, "module-bitorch_engine.utils.quant_operators"]], "bitorch_engine.utils.quant_operators.bit_set": [[174, "bitorch-engine-utils-quant-operators-bit-set"]], "bitorch_engine.utils.quant_operators.get_binary_col": [[175, "bitorch-engine-utils-quant-operators-get-binary-col"]], "bitorch_engine.utils.quant_operators.get_binary_row": [[176, "bitorch-engine-utils-quant-operators-get-binary-row"]], "bitorch_engine.utils.quant_operators.gptq_style_unpacking": [[177, "bitorch-engine-utils-quant-operators-gptq-style-unpacking"]], "bitorch_engine.utils.quant_operators.gptq_style_zeros_packing": [[178, "bitorch-engine-utils-quant-operators-gptq-style-zeros-packing"]], "bitorch_engine.utils.quant_operators.nv_tensor_quant": [[179, "bitorch-engine-utils-quant-operators-nv-tensor-quant"]], "bitorch_engine.utils.quant_operators.q4_quantization": [[180, "bitorch-engine-utils-quant-operators-q4-quantization"]], "bitorch_engine.utils.quant_operators.q8_quantization": [[181, "bitorch-engine-utils-quant-operators-q8-quantization"]], "bitorch_engine.utils.safe_import": [[182, "module-bitorch_engine.utils.safe_import"]], "bitorch_engine.utils.safe_import.ExtensionModulePlaceholder": [[183, "bitorch-engine-utils-safe-import-extensionmoduleplaceholder"]], "bitorch_engine.utils.safe_import.import_extension": [[184, "bitorch-engine-utils-safe-import-import-extension"]], "Build options": [[185, "build-options"]], "Building Specific Extensions": [[185, "building-specific-extensions"]], "Building for a Specific CUDA Architecture": [[185, "building-for-a-specific-cuda-architecture"]], "Force Building CUDA Modules": [[185, "force-building-cuda-modules"]], "Skip Library File Building": [[185, "skip-library-file-building"]], "Full Documentation": [[186, "full-documentation"]], "Welcome to Bitorch Engine\u2019s documentation!": [[187, "welcome-to-bitorch-engine-s-documentation"]], "Contents:": [[187, null]], "Indices and tables": [[187, "indices-and-tables"]], "Installation": [[188, "installation"]], "Binary Release": [[188, "binary-release"]], "Build From Source": [[188, "build-from-source"]], "Conda on Linux (with CUDA)": [[188, "conda-on-linux-with-cuda"]], "Docker (with CUDA)": [[188, "docker-with-cuda"]], "Conda on MacOS (with MLX)": [[188, "conda-on-macos-with-mlx"]]}, "indexentries": {"bitorch_engine": [[0, "module-bitorch_engine"]], "module": [[0, "module-bitorch_engine"], [1, "module-bitorch_engine.functions"], [2, "module-bitorch_engine.functions.cuda"], [3, "module-bitorch_engine.functions.cuda.extension"], [5, "module-bitorch_engine.functions.cuda.functions"], [12, "module-bitorch_engine.layers"], [13, "module-bitorch_engine.layers.qconv"], [14, "module-bitorch_engine.layers.qconv.binary"], [15, "module-bitorch_engine.layers.qconv.binary.cpp"], [16, "module-bitorch_engine.layers.qconv.binary.cpp.extension"], [18, "module-bitorch_engine.layers.qconv.binary.cpp.layer"], [21, "module-bitorch_engine.layers.qconv.binary.cutlass"], [22, "module-bitorch_engine.layers.qconv.binary.cutlass.extension"], [24, "module-bitorch_engine.layers.qconv.binary.cutlass.layer"], [27, "module-bitorch_engine.layers.qconv.binary.layer"], [30, "module-bitorch_engine.layers.qconv.nbit"], [31, "module-bitorch_engine.layers.qconv.nbit.cutlass"], [32, "module-bitorch_engine.layers.qconv.nbit.cutlass.extension"], [34, "module-bitorch_engine.layers.qconv.nbit.cutlass.layer"], [37, "module-bitorch_engine.layers.qconv.nbit.layer"], [40, "module-bitorch_engine.layers.qembedding"], [41, "module-bitorch_engine.layers.qembedding.binary"], [42, "module-bitorch_engine.layers.qembedding.binary.layer"], [48, "module-bitorch_engine.layers.qlinear"], [49, "module-bitorch_engine.layers.qlinear.binary"], [50, "module-bitorch_engine.layers.qlinear.binary.binary_implementation"], [52, "module-bitorch_engine.layers.qlinear.binary.cpp"], [53, "module-bitorch_engine.layers.qlinear.binary.cpp.extension"], [55, "module-bitorch_engine.layers.qlinear.binary.cpp.layer"], [58, "module-bitorch_engine.layers.qlinear.binary.cuda"], [59, "module-bitorch_engine.layers.qlinear.binary.cuda.bmm"], [61, "module-bitorch_engine.layers.qlinear.binary.cuda.extension"], [63, "module-bitorch_engine.layers.qlinear.binary.cuda.layer"], [66, "module-bitorch_engine.layers.qlinear.binary.cutlass"], [67, "module-bitorch_engine.layers.qlinear.binary.cutlass.extension"], [69, "module-bitorch_engine.layers.qlinear.binary.cutlass.layer"], [75, "module-bitorch_engine.layers.qlinear.binary.layer"], [78, "module-bitorch_engine.layers.qlinear.layer"], [80, "module-bitorch_engine.layers.qlinear.nbit"], [81, "module-bitorch_engine.layers.qlinear.nbit.cuda"], [82, "module-bitorch_engine.layers.qlinear.nbit.cuda.extension"], [84, "module-bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer"], [87, "module-bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer"], [90, "module-bitorch_engine.layers.qlinear.nbit.cuda.utils"], [94, "module-bitorch_engine.layers.qlinear.nbit.cutlass"], [95, "module-bitorch_engine.layers.qlinear.nbit.cutlass.extension"], [97, "module-bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer"], [102, "module-bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer"], [105, "module-bitorch_engine.layers.qlinear.nbit.layer"], [110, "module-bitorch_engine.layers.qlinear.nbit.mps"], [111, "module-bitorch_engine.layers.qlinear.nbit.mps.extension"], [113, "module-bitorch_engine.layers.qlinear.nbit.mps.mpq_layer"], [116, "module-bitorch_engine.layers.qlinear.qlinear_implementation"], [118, "module-bitorch_engine.layers.qmha"], [119, "module-bitorch_engine.layers.qmha.binary"], [120, "module-bitorch_engine.layers.qmha.binary.layer"], [123, "module-bitorch_engine.optim"], [124, "module-bitorch_engine.optim.diode_beta"], [127, "module-bitorch_engine.optim.galore_projector"], [129, "module-bitorch_engine.utils"], [130, "module-bitorch_engine.utils.arch_helper"], [134, "module-bitorch_engine.utils.convert"], [141, "module-bitorch_engine.utils.cpp_extension"], [144, "module-bitorch_engine.utils.cuda_extension"], [149, "module-bitorch_engine.utils.cutlass_path"], [154, "module-bitorch_engine.utils.mlx_extension"], [156, "module-bitorch_engine.utils.mlx_path"], [160, "module-bitorch_engine.utils.model_helper"], [173, "module-bitorch_engine.utils.quant_operators"], [182, "module-bitorch_engine.utils.safe_import"]], "bitorch_engine.functions": [[1, "module-bitorch_engine.functions"]], "bitorch_engine.functions.cuda": [[2, "module-bitorch_engine.functions.cuda"]], "bitorch_engine.functions.cuda.extension": [[3, "module-bitorch_engine.functions.cuda.extension"]], "get_ext() (in module bitorch_engine.functions.cuda.extension)": [[4, "bitorch_engine.functions.cuda.extension.get_ext"]], "bitorch_engine.functions.cuda.functions": [[5, "module-bitorch_engine.functions.cuda.functions"]], "fp32toint4() (in module bitorch_engine.functions.cuda.functions)": [[6, "bitorch_engine.functions.cuda.functions.fp32toint4"]], "q4_pack_tensor() (in module bitorch_engine.functions.cuda.functions)": [[7, "bitorch_engine.functions.cuda.functions.q4_pack_tensor"]], "q4_unpack_and_scaling_tensor() (in module bitorch_engine.functions.cuda.functions)": [[8, "bitorch_engine.functions.cuda.functions.q4_unpack_and_scaling_tensor"]], "q4_unpack_tensor() (in module bitorch_engine.functions.cuda.functions)": [[9, "bitorch_engine.functions.cuda.functions.q4_unpack_tensor"]], "tensor_to_packed_uint8() (in module bitorch_engine.functions.cuda.functions)": [[10, "bitorch_engine.functions.cuda.functions.tensor_to_packed_uint8"]], "unpack_uint8_tensor() (in module bitorch_engine.functions.cuda.functions)": [[11, "bitorch_engine.functions.cuda.functions.unpack_uint8_tensor"]], "bitorch_engine.layers": [[12, "module-bitorch_engine.layers"]], "bitorch_engine.layers.qconv": [[13, "module-bitorch_engine.layers.qconv"]], "bitorch_engine.layers.qconv.binary": [[14, "module-bitorch_engine.layers.qconv.binary"]], "bitorch_engine.layers.qconv.binary.cpp": [[15, "module-bitorch_engine.layers.qconv.binary.cpp"]], "bitorch_engine.layers.qconv.binary.cpp.extension": [[16, "module-bitorch_engine.layers.qconv.binary.cpp.extension"]], "get_ext() (in module bitorch_engine.layers.qconv.binary.cpp.extension)": [[17, "bitorch_engine.layers.qconv.binary.cpp.extension.get_ext"]], "bitorch_engine.layers.qconv.binary.cpp.layer": [[18, "module-bitorch_engine.layers.qconv.binary.cpp.layer"]], "binaryconv2dcpp (class in bitorch_engine.layers.qconv.binary.cpp.layer)": [[19, "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP"]], "__init__() (bitorch_engine.layers.qconv.binary.cpp.layer.binaryconv2dcpp method)": [[19, "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP.__init__"]], "bits_binary_word (bitorch_engine.layers.qconv.binary.cpp.layer.binaryconv2dcpp attribute)": [[19, "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP.bits_binary_word"]], "forward() (bitorch_engine.layers.qconv.binary.cpp.layer.binaryconv2dcpp method)": [[19, "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP.forward"]], "generate_quantized_weight() (bitorch_engine.layers.qconv.binary.cpp.layer.binaryconv2dcpp method)": [[19, "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP.generate_quantized_weight"]], "prepare_params() (bitorch_engine.layers.qconv.binary.cpp.layer.binaryconv2dcpp method)": [[19, "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP.prepare_params"]], "binaryconv2dforward (class in bitorch_engine.layers.qconv.binary.cpp.layer)": [[20, "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dForward"]], "forward() (bitorch_engine.layers.qconv.binary.cpp.layer.binaryconv2dforward static method)": [[20, "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dForward.forward"]], "bitorch_engine.layers.qconv.binary.cutlass": [[21, "module-bitorch_engine.layers.qconv.binary.cutlass"]], "bitorch_engine.layers.qconv.binary.cutlass.extension": [[22, "module-bitorch_engine.layers.qconv.binary.cutlass.extension"]], "get_ext() (in module bitorch_engine.layers.qconv.binary.cutlass.extension)": [[23, "bitorch_engine.layers.qconv.binary.cutlass.extension.get_ext"]], "bitorch_engine.layers.qconv.binary.cutlass.layer": [[24, "module-bitorch_engine.layers.qconv.binary.cutlass.layer"]], "binaryconv2dcutlass (class in bitorch_engine.layers.qconv.binary.cutlass.layer)": [[25, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass"]], "__init__() (bitorch_engine.layers.qconv.binary.cutlass.layer.binaryconv2dcutlass method)": [[25, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.__init__"]], "bias_a (bitorch_engine.layers.qconv.binary.cutlass.layer.binaryconv2dcutlass attribute)": [[25, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.bias_a"]], "bits_binary_word (bitorch_engine.layers.qconv.binary.cutlass.layer.binaryconv2dcutlass attribute)": [[25, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.bits_binary_word"]], "forward() (bitorch_engine.layers.qconv.binary.cutlass.layer.binaryconv2dcutlass method)": [[25, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.forward"]], "generate_quantized_weight() (bitorch_engine.layers.qconv.binary.cutlass.layer.binaryconv2dcutlass method)": [[25, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.generate_quantized_weight"]], "prepare_params() (bitorch_engine.layers.qconv.binary.cutlass.layer.binaryconv2dcutlass method)": [[25, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.prepare_params"]], "scale_a (bitorch_engine.layers.qconv.binary.cutlass.layer.binaryconv2dcutlass attribute)": [[25, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.scale_a"]], "scale_w (bitorch_engine.layers.qconv.binary.cutlass.layer.binaryconv2dcutlass attribute)": [[25, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.scale_w"]], "set_activation() (bitorch_engine.layers.qconv.binary.cutlass.layer.binaryconv2dcutlass method)": [[25, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.set_activation"]], "set_weight_data() (bitorch_engine.layers.qconv.binary.cutlass.layer.binaryconv2dcutlass method)": [[25, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.set_weight_data"]], "binaryconv2dforward (class in bitorch_engine.layers.qconv.binary.cutlass.layer)": [[26, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dForward"]], "backward() (bitorch_engine.layers.qconv.binary.cutlass.layer.binaryconv2dforward static method)": [[26, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dForward.backward"]], "forward() (bitorch_engine.layers.qconv.binary.cutlass.layer.binaryconv2dforward static method)": [[26, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dForward.forward"]], "bitorch_engine.layers.qconv.binary.layer": [[27, "module-bitorch_engine.layers.qconv.binary.layer"]], "binaryconv2dbase (class in bitorch_engine.layers.qconv.binary.layer)": [[28, "bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase"]], "__init__() (bitorch_engine.layers.qconv.binary.layer.binaryconv2dbase method)": [[28, "bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.__init__"]], "generate_quantized_weight() (bitorch_engine.layers.qconv.binary.layer.binaryconv2dbase method)": [[28, "bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.generate_quantized_weight"]], "opt_weight (bitorch_engine.layers.qconv.binary.layer.binaryconv2dbase property)": [[28, "bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.opt_weight"]], "prepare_params() (bitorch_engine.layers.qconv.binary.layer.binaryconv2dbase method)": [[28, "bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.prepare_params"]], "reset_parameters() (bitorch_engine.layers.qconv.binary.layer.binaryconv2dbase method)": [[28, "bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.reset_parameters"]], "set_bits_binary_word() (bitorch_engine.layers.qconv.binary.layer.binaryconv2dbase method)": [[28, "bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.set_bits_binary_word"]], "set_quantized_weight_data() (bitorch_engine.layers.qconv.binary.layer.binaryconv2dbase method)": [[28, "bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.set_quantized_weight_data"]], "set_weight_data() (bitorch_engine.layers.qconv.binary.layer.binaryconv2dbase method)": [[28, "bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.set_weight_data"]], "binaryconvparameter (class in bitorch_engine.layers.qconv.binary.layer)": [[29, "bitorch_engine.layers.qconv.binary.layer.BinaryConvParameter"]], "update() (bitorch_engine.layers.qconv.binary.layer.binaryconvparameter static method)": [[29, "bitorch_engine.layers.qconv.binary.layer.BinaryConvParameter.update"]], "bitorch_engine.layers.qconv.nbit": [[30, "module-bitorch_engine.layers.qconv.nbit"]], "bitorch_engine.layers.qconv.nbit.cutlass": [[31, "module-bitorch_engine.layers.qconv.nbit.cutlass"]], "bitorch_engine.layers.qconv.nbit.cutlass.extension": [[32, "module-bitorch_engine.layers.qconv.nbit.cutlass.extension"]], "get_ext() (in module bitorch_engine.layers.qconv.nbit.cutlass.extension)": [[33, "bitorch_engine.layers.qconv.nbit.cutlass.extension.get_ext"]], "bitorch_engine.layers.qconv.nbit.cutlass.layer": [[34, "module-bitorch_engine.layers.qconv.nbit.cutlass.layer"]], "q4conv2dcutlass (class in bitorch_engine.layers.qconv.nbit.cutlass.layer)": [[35, "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass"]], "__init__() (bitorch_engine.layers.qconv.nbit.cutlass.layer.q4conv2dcutlass method)": [[35, "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.__init__"]], "bias_a (bitorch_engine.layers.qconv.nbit.cutlass.layer.q4conv2dcutlass attribute)": [[35, "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.bias_a"]], "eps (bitorch_engine.layers.qconv.nbit.cutlass.layer.q4conv2dcutlass attribute)": [[35, "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.eps"]], "forward() (bitorch_engine.layers.qconv.nbit.cutlass.layer.q4conv2dcutlass method)": [[35, "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.forward"]], "generate_quantized_weight() (bitorch_engine.layers.qconv.nbit.cutlass.layer.q4conv2dcutlass method)": [[35, "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.generate_quantized_weight"]], "prepare_params() (bitorch_engine.layers.qconv.nbit.cutlass.layer.q4conv2dcutlass method)": [[35, "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.prepare_params"]], "scale_a (bitorch_engine.layers.qconv.nbit.cutlass.layer.q4conv2dcutlass attribute)": [[35, "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.scale_a"]], "scale_w (bitorch_engine.layers.qconv.nbit.cutlass.layer.q4conv2dcutlass attribute)": [[35, "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.scale_w"]], "set_activation() (bitorch_engine.layers.qconv.nbit.cutlass.layer.q4conv2dcutlass method)": [[35, "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.set_activation"]], "q4conv2dcutlassforward (class in bitorch_engine.layers.qconv.nbit.cutlass.layer)": [[36, "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward"]], "backward (bitorch_engine.layers.qconv.nbit.cutlass.layer.q4conv2dcutlassforward attribute)": [[36, "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward.backward"]], "backward() (bitorch_engine.layers.qconv.nbit.cutlass.layer.q4conv2dcutlassforward static method)": [[36, "id0"]], "forward (bitorch_engine.layers.qconv.nbit.cutlass.layer.q4conv2dcutlassforward attribute)": [[36, "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward.forward"]], "forward() (bitorch_engine.layers.qconv.nbit.cutlass.layer.q4conv2dcutlassforward static method)": [[36, "id1"]], "bitorch_engine.layers.qconv.nbit.layer": [[37, "module-bitorch_engine.layers.qconv.nbit.layer"]], "__init__() (bitorch_engine.layers.qconv.nbit.layer.nbitconv2dbase method)": [[38, "bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.__init__"]], "generate_quantized_weight() (bitorch_engine.layers.qconv.nbit.layer.nbitconv2dbase method)": [[38, "bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.generate_quantized_weight"]], "nbitconv2dbase (class in bitorch_engine.layers.qconv.nbit.layer)": [[38, "bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase"]], "opt_weight (bitorch_engine.layers.qconv.nbit.layer.nbitconv2dbase property)": [[38, "bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.opt_weight"]], "prepare_params() (bitorch_engine.layers.qconv.nbit.layer.nbitconv2dbase method)": [[38, "bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.prepare_params"]], "reset_parameters() (bitorch_engine.layers.qconv.nbit.layer.nbitconv2dbase method)": [[38, "bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.reset_parameters"]], "set_quantized_weight_data() (bitorch_engine.layers.qconv.nbit.layer.nbitconv2dbase method)": [[38, "bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.set_quantized_weight_data"]], "set_weight_data() (bitorch_engine.layers.qconv.nbit.layer.nbitconv2dbase method)": [[38, "bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.set_weight_data"]], "nbitconvparameter (class in bitorch_engine.layers.qconv.nbit.layer)": [[39, "bitorch_engine.layers.qconv.nbit.layer.nBitConvParameter"]], "update() (bitorch_engine.layers.qconv.nbit.layer.nbitconvparameter static method)": [[39, "bitorch_engine.layers.qconv.nbit.layer.nBitConvParameter.update"]], "bitorch_engine.layers.qembedding": [[40, "module-bitorch_engine.layers.qembedding"]], "bitorch_engine.layers.qembedding.binary": [[41, "module-bitorch_engine.layers.qembedding.binary"]], "bitorch_engine.layers.qembedding.binary.layer": [[42, "module-bitorch_engine.layers.qembedding.binary.layer"]], "binaryembeddingbag (class in bitorch_engine.layers.qembedding.binary.layer)": [[43, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag"]], "__init__() (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingbag method)": [[43, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.__init__"]], "forward() (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingbag method)": [[43, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.forward"]], "reset_parameters() (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingbag method)": [[43, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.reset_parameters"]], "binaryembeddingbagforward (class in bitorch_engine.layers.qembedding.binary.layer)": [[44, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward"]], "backward() (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingbagforward static method)": [[44, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward.backward"]], "forward() (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingbagforward static method)": [[44, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward.forward"]], "binaryembeddingcuda (class in bitorch_engine.layers.qembedding.binary.layer)": [[45, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda"]], "__init__() (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingcuda method)": [[45, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.__init__"]], "forward() (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingcuda method)": [[45, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.forward"]], "init_weight() (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingcuda method)": [[45, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.init_weight"]], "prepare_params() (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingcuda method)": [[45, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.prepare_params"]], "qweight (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingcuda attribute)": [[45, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.qweight"]], "reset_parameters() (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingcuda method)": [[45, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.reset_parameters"]], "scale_w (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingcuda attribute)": [[45, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.scale_w"]], "weight (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingcuda attribute)": [[45, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.weight"]], "binaryembeddingforward (class in bitorch_engine.layers.qembedding.binary.layer)": [[46, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingForward"]], "backward() (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingforward static method)": [[46, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingForward.backward"]], "forward() (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingforward static method)": [[46, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingForward.forward"]], "binaryembeddingparameter (class in bitorch_engine.layers.qembedding.binary.layer)": [[47, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingParameter"]], "active_indices (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingparameter attribute)": [[47, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingParameter.active_indices"]], "update() (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingparameter static method)": [[47, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingParameter.update"]], "bitorch_engine.layers.qlinear": [[48, "module-bitorch_engine.layers.qlinear"]], "bitorch_engine.layers.qlinear.binary": [[49, "module-bitorch_engine.layers.qlinear.binary"]], "bitorch_engine.layers.qlinear.binary.binary_implementation": [[50, "module-bitorch_engine.layers.qlinear.binary.binary_implementation"]], "binarylinearimplementationmixin (class in bitorch_engine.layers.qlinear.binary.binary_implementation)": [[51, "bitorch_engine.layers.qlinear.binary.binary_implementation.BinaryLinearImplementationMixin"]], "can_clone() (bitorch_engine.layers.qlinear.binary.binary_implementation.binarylinearimplementationmixin class method)": [[51, "id0"]], "can_clone() (bitorch_engine.layers.qlinear.binary.binary_implementation.binarylinearimplementationmixin method)": [[51, "bitorch_engine.layers.qlinear.binary.binary_implementation.BinaryLinearImplementationMixin.can_clone"]], "bitorch_engine.layers.qlinear.binary.cpp": [[52, "module-bitorch_engine.layers.qlinear.binary.cpp"]], "bitorch_engine.layers.qlinear.binary.cpp.extension": [[53, "module-bitorch_engine.layers.qlinear.binary.cpp.extension"]], "get_ext() (in module bitorch_engine.layers.qlinear.binary.cpp.extension)": [[54, "bitorch_engine.layers.qlinear.binary.cpp.extension.get_ext"]], "bitorch_engine.layers.qlinear.binary.cpp.layer": [[55, "module-bitorch_engine.layers.qlinear.binary.cpp.layer"]], "binarylinearcpp (class in bitorch_engine.layers.qlinear.binary.cpp.layer)": [[56, "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP"]], "__init__() (bitorch_engine.layers.qlinear.binary.cpp.layer.binarylinearcpp method)": [[56, "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP.__init__"]], "create_clone_from() (bitorch_engine.layers.qlinear.binary.cpp.layer.binarylinearcpp class method)": [[56, "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP.create_clone_from"]], "forward() (bitorch_engine.layers.qlinear.binary.cpp.layer.binarylinearcpp method)": [[56, "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP.forward"]], "generate_quantized_weight() (bitorch_engine.layers.qlinear.binary.cpp.layer.binarylinearcpp method)": [[56, "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP.generate_quantized_weight"]], "prepare_params() (bitorch_engine.layers.qlinear.binary.cpp.layer.binarylinearcpp method)": [[56, "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP.prepare_params"]], "binarylinearforward (class in bitorch_engine.layers.qlinear.binary.cpp.layer)": [[57, "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearForward"]], "forward() (bitorch_engine.layers.qlinear.binary.cpp.layer.binarylinearforward static method)": [[57, "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearForward.forward"]], "bitorch_engine.layers.qlinear.binary.cuda": [[58, "module-bitorch_engine.layers.qlinear.binary.cuda"]], "bitorch_engine.layers.qlinear.binary.cuda.bmm": [[59, "module-bitorch_engine.layers.qlinear.binary.cuda.bmm"]], "adaptive (bitorch_engine.layers.qlinear.binary.cuda.bmm.bmm attribute)": [[60, "bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM.ADAPTIVE"]], "bmm (class in bitorch_engine.layers.qlinear.binary.cuda.bmm)": [[60, "bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM"]], "bstc32 (bitorch_engine.layers.qlinear.binary.cuda.bmm.bmm attribute)": [[60, "bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM.BSTC32"]], "btc32 (bitorch_engine.layers.qlinear.binary.cuda.bmm.bmm attribute)": [[60, "bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM.BTC32"]], "bitorch_engine.layers.qlinear.binary.cuda.extension": [[61, "module-bitorch_engine.layers.qlinear.binary.cuda.extension"]], "get_ext() (in module bitorch_engine.layers.qlinear.binary.cuda.extension)": [[62, "bitorch_engine.layers.qlinear.binary.cuda.extension.get_ext"]], "bitorch_engine.layers.qlinear.binary.cuda.layer": [[63, "module-bitorch_engine.layers.qlinear.binary.cuda.layer"]], "binarylinearcuda (class in bitorch_engine.layers.qlinear.binary.cuda.layer)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda"]], "__init__() (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda method)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.__init__"]], "bias_a (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda attribute)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.bias_a"]], "bits_binary_word (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda attribute)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.bits_binary_word"]], "bmm_type (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda attribute)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.bmm_type"]], "create_clone_from() (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda class method)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.create_clone_from"]], "device_id (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda property)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.device_id"]], "forward() (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda method)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.forward"]], "generate_quantized_weight() (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda method)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.generate_quantized_weight"]], "prepare_params() (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda method)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.prepare_params"]], "scale_a (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda attribute)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.scale_a"]], "scale_w (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda attribute)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.scale_w"]], "set_activation() (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda method)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.set_activation"]], "set_weight_data() (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda method)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.set_weight_data"]], "w_pack() (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda static method)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.w_pack"]], "binarylinearforward (class in bitorch_engine.layers.qlinear.binary.cuda.layer)": [[65, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward"]], "backward() (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearforward static method)": [[65, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.backward"]], "bmm_type (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearforward attribute)": [[65, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.bmm_type"]], "ctx (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearforward attribute)": [[65, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.ctx"]], "forward() (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearforward static method)": [[65, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.forward"]], "input (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearforward attribute)": [[65, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.input"]], "is_train (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearforward attribute)": [[65, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.is_train"]], "scale_a (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearforward attribute)": [[65, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.scale_a"]], "scale_w (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearforward attribute)": [[65, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.scale_w"]], "weight (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearforward attribute)": [[65, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.weight"]], "bitorch_engine.layers.qlinear.binary.cutlass": [[66, "module-bitorch_engine.layers.qlinear.binary.cutlass"]], "bitorch_engine.layers.qlinear.binary.cutlass.extension": [[67, "module-bitorch_engine.layers.qlinear.binary.cutlass.extension"]], "get_ext() (in module bitorch_engine.layers.qlinear.binary.cutlass.extension)": [[68, "bitorch_engine.layers.qlinear.binary.cutlass.extension.get_ext"]], "bitorch_engine.layers.qlinear.binary.cutlass.layer": [[69, "module-bitorch_engine.layers.qlinear.binary.cutlass.layer"]], "binarylinearcutlass (class in bitorch_engine.layers.qlinear.binary.cutlass.layer)": [[70, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass"]], "__init__() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearcutlass method)": [[70, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.__init__"]], "bias_a (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearcutlass attribute)": [[70, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.bias_a"]], "bits_binary_word (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearcutlass attribute)": [[70, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.bits_binary_word"]], "forward() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearcutlass method)": [[70, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.forward"], [70, "id0"]], "gemm_kernel_id (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearcutlass attribute)": [[70, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.gemm_kernel_id"]], "generate_quantized_weight() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearcutlass method)": [[70, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.generate_quantized_weight"], [70, "id1"]], "prepare_params() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearcutlass method)": [[70, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.prepare_params"], [70, "id2"]], "scale_a (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearcutlass attribute)": [[70, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.scale_a"]], "scale_w (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearcutlass attribute)": [[70, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.scale_w"]], "select_gemm_kernel() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearcutlass method)": [[70, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.select_gemm_kernel"], [70, "id3"]], "set_activation() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearcutlass method)": [[70, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.set_activation"], [70, "id4"]], "set_weight_data() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearcutlass method)": [[70, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.set_weight_data"], [70, "id5"]], "binarylinearforward (class in bitorch_engine.layers.qlinear.binary.cutlass.layer)": [[71, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward"]], "backward() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearforward static method)": [[71, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward.backward"]], "forward() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearforward static method)": [[71, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward.forward"]], "binarymatmul (class in bitorch_engine.layers.qlinear.binary.cutlass.layer)": [[72, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul"]], "__init__() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarymatmul method)": [[72, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul.__init__"]], "dtype (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarymatmul attribute)": [[72, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul.dtype"]], "forward() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarymatmul method)": [[72, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul.forward"]], "set_activation_scale() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarymatmul method)": [[72, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul.set_activation_scale"]], "x_clip (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarymatmul attribute)": [[72, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul.x_clip"]], "y_clip (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarymatmul attribute)": [[72, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul.y_clip"]], "binarymatmulfunction (class in bitorch_engine.layers.qlinear.binary.cutlass.layer)": [[73, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMulFunction"]], "backward() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarymatmulfunction static method)": [[73, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMulFunction.backward"]], "forward() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarymatmulfunction static method)": [[73, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMulFunction.forward"]], "get_best_binary_implementation() (in module bitorch_engine.layers.qlinear.binary)": [[74, "bitorch_engine.layers.qlinear.binary.get_best_binary_implementation"]], "bitorch_engine.layers.qlinear.binary.layer": [[75, "module-bitorch_engine.layers.qlinear.binary.layer"]], "binarylinearbase (class in bitorch_engine.layers.qlinear.binary.layer)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase"]], "__init__() (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase method)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.__init__"]], "_check_forward() (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase method)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase._check_forward"]], "bits_binary_word (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase attribute)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.bits_binary_word"]], "device (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase attribute)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.device"]], "dtype (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase attribute)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.dtype"]], "generate_quantized_weight() (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase method)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.generate_quantized_weight"], [76, "id0"]], "input_features (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase attribute)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.input_features"]], "opt_weight (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase property)": [[76, "id1"]], "opt_weight() (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase method)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.opt_weight"]], "output_features (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase attribute)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.output_features"]], "prepare_params() (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase method)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.prepare_params"]], "qweight (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase attribute)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.qweight"]], "reset_parameters() (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase method)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.reset_parameters"], [76, "id2"]], "set_bits_binary_word() (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase method)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.set_bits_binary_word"], [76, "id3"]], "set_quantized_weight_data() (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase method)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.set_quantized_weight_data"], [76, "id4"]], "set_weight_data() (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase method)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.set_weight_data"], [76, "id5"]], "symmetric (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase attribute)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.symmetric"]], "weight (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase attribute)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.weight"]], "binarylinearparameter (class in bitorch_engine.layers.qlinear.binary.layer)": [[77, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearParameter"]], "update() (bitorch_engine.layers.qlinear.binary.layer.binarylinearparameter static method)": [[77, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearParameter.update"]], "bitorch_engine.layers.qlinear.layer": [[78, "module-bitorch_engine.layers.qlinear.layer"]], "qlinearinf (class in bitorch_engine.layers.qlinear.layer)": [[79, "bitorch_engine.layers.qlinear.layer.QLinearInf"]], "__init__() (bitorch_engine.layers.qlinear.layer.qlinearinf method)": [[79, "bitorch_engine.layers.qlinear.layer.QLinearInf.__init__"]], "create_clone_from() (bitorch_engine.layers.qlinear.layer.qlinearinf class method)": [[79, "bitorch_engine.layers.qlinear.layer.QLinearInf.create_clone_from"]], "forward() (bitorch_engine.layers.qlinear.layer.qlinearinf method)": [[79, "bitorch_engine.layers.qlinear.layer.QLinearInf.forward"]], "generate_quantized_weight() (bitorch_engine.layers.qlinear.layer.qlinearinf method)": [[79, "bitorch_engine.layers.qlinear.layer.QLinearInf.generate_quantized_weight"]], "opt_weight (bitorch_engine.layers.qlinear.layer.qlinearinf property)": [[79, "bitorch_engine.layers.qlinear.layer.QLinearInf.opt_weight"]], "prepare_params() (bitorch_engine.layers.qlinear.layer.qlinearinf method)": [[79, "bitorch_engine.layers.qlinear.layer.QLinearInf.prepare_params"]], "set_quantized_weight_data() (bitorch_engine.layers.qlinear.layer.qlinearinf method)": [[79, "bitorch_engine.layers.qlinear.layer.QLinearInf.set_quantized_weight_data"]], "set_weight_data() (bitorch_engine.layers.qlinear.layer.qlinearinf method)": [[79, "bitorch_engine.layers.qlinear.layer.QLinearInf.set_weight_data"]], "weight (bitorch_engine.layers.qlinear.layer.qlinearinf property)": [[79, "bitorch_engine.layers.qlinear.layer.QLinearInf.weight"]], "bitorch_engine.layers.qlinear.nbit": [[80, "module-bitorch_engine.layers.qlinear.nbit"]], "bitorch_engine.layers.qlinear.nbit.cuda": [[81, "module-bitorch_engine.layers.qlinear.nbit.cuda"]], "bitorch_engine.layers.qlinear.nbit.cuda.extension": [[82, "module-bitorch_engine.layers.qlinear.nbit.cuda.extension"]], "get_ext() (in module bitorch_engine.layers.qlinear.nbit.cuda.extension)": [[83, "bitorch_engine.layers.qlinear.nbit.cuda.extension.get_ext"]], "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer": [[84, "module-bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer"]], "mbwqlinearcuda (class in bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda"]], "__init__() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda method)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.__init__"]], "check_parameters() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda method)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.check_parameters"], [85, "id0"]], "exl2fp_weight() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda method)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.exl2fp_weight"]], "exl2fp_weight() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda static method)": [[85, "id1"]], "forward() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda method)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.forward"], [85, "id2"]], "load_state_dict() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda method)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.load_state_dict"], [85, "id3"]], "prepare_params() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda method)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.prepare_params"], [85, "id4"]], "q42fp_weight() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda method)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.q42fp_weight"]], "q42fp_weight() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda static method)": [[85, "id5"]], "qweight (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda attribute)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.qweight"]], "rows (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda attribute)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.rows"]], "scales (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda attribute)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.scales"]], "set_scales() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda method)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.set_scales"], [85, "id6"]], "set_zeros() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda method)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.set_zeros"], [85, "id7"]], "use_mbw (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda attribute)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.use_mbw"]], "zeros (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda attribute)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.zeros"]], "mbwqlinearcudafunction (class in bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer)": [[86, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction"]], "backward() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcudafunction static method)": [[86, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction.backward"]], "forward() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcudafunction static method)": [[86, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction.forward"]], "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer": [[87, "module-bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer"]], "mpqlinearcuda (class in bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer)": [[88, "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda"]], "__init__() (bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.mpqlinearcuda method)": [[88, "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.__init__"]], "a_bit (bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.mpqlinearcuda attribute)": [[88, "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.a_bit"]], "check_parameters() (bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.mpqlinearcuda method)": [[88, "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.check_parameters"], [88, "id0"]], "forward() (bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.mpqlinearcuda method)": [[88, "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.forward"], [88, "id1"]], "prepare_params() (bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.mpqlinearcuda method)": [[88, "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.prepare_params"], [88, "id2"]], "qweight (bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.mpqlinearcuda attribute)": [[88, "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.qweight"]], "scales (bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.mpqlinearcuda attribute)": [[88, "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.scales"]], "w_bit (bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.mpqlinearcuda attribute)": [[88, "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.w_bit"]], "zeros (bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.mpqlinearcuda attribute)": [[88, "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.zeros"]], "mpqlinearcudafunction (class in bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer)": [[89, "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCudaFunction"]], "backward() (bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.mpqlinearcudafunction static method)": [[89, "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCudaFunction.backward"]], "forward() (bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.mpqlinearcudafunction static method)": [[89, "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCudaFunction.forward"]], "bitorch_engine.layers.qlinear.nbit.cuda.utils": [[90, "module-bitorch_engine.layers.qlinear.nbit.cuda.utils"]], "make_group_map() (in module bitorch_engine.layers.qlinear.nbit.cuda.utils)": [[91, "bitorch_engine.layers.qlinear.nbit.cuda.utils.make_group_map"]], "pack_fp_weight() (in module bitorch_engine.layers.qlinear.nbit.cuda.utils)": [[92, "bitorch_engine.layers.qlinear.nbit.cuda.utils.pack_fp_weight"]], "unpack_qweight() (in module bitorch_engine.layers.qlinear.nbit.cuda.utils)": [[93, "bitorch_engine.layers.qlinear.nbit.cuda.utils.unpack_qweight"]], "bitorch_engine.layers.qlinear.nbit.cutlass": [[94, "module-bitorch_engine.layers.qlinear.nbit.cutlass"]], "bitorch_engine.layers.qlinear.nbit.cutlass.extension": [[95, "module-bitorch_engine.layers.qlinear.nbit.cutlass.extension"]], "get_ext() (in module bitorch_engine.layers.qlinear.nbit.cutlass.extension)": [[96, "bitorch_engine.layers.qlinear.nbit.cutlass.extension.get_ext"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer": [[97, "module-bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer"]], "q4linearcutlass (class in bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer)": [[98, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass"]], "__init__() (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4linearcutlass method)": [[98, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.__init__"]], "_check_forward() (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4linearcutlass method)": [[98, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass._check_forward"]], "bias_a (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4linearcutlass attribute)": [[98, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.bias_a"]], "eps (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4linearcutlass attribute)": [[98, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.eps"]], "forward() (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4linearcutlass method)": [[98, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.forward"], [98, "id0"]], "generate_quantized_weight() (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4linearcutlass method)": [[98, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.generate_quantized_weight"], [98, "id1"]], "prepare_params() (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4linearcutlass method)": [[98, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.prepare_params"], [98, "id2"]], "scale_a (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4linearcutlass attribute)": [[98, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.scale_a"]], "scale_w (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4linearcutlass attribute)": [[98, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.scale_w"]], "set_activation() (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4linearcutlass method)": [[98, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.set_activation"], [98, "id3"]], "q4linearfunction (class in bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer)": [[99, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearFunction"]], "backward() (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4linearfunction static method)": [[99, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearFunction.backward"]], "forward() (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4linearfunction static method)": [[99, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearFunction.forward"]], "q4matmul (class in bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer)": [[100, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul"]], "__init__() (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4matmul method)": [[100, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.__init__"]], "device (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4matmul attribute)": [[100, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.device"]], "dtype (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4matmul attribute)": [[100, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.dtype"]], "eps (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4matmul attribute)": [[100, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.eps"]], "forward() (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4matmul method)": [[100, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.forward"]], "set_activation_scale() (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4matmul method)": [[100, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.set_activation_scale"]], "x_clip (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4matmul attribute)": [[100, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.x_clip"]], "y_clip (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4matmul attribute)": [[100, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.y_clip"]], "q4matmulfunction (class in bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer)": [[101, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMulFunction"]], "backward() (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4matmulfunction static method)": [[101, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMulFunction.backward"]], "forward() (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4matmulfunction static method)": [[101, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMulFunction.forward"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer": [[102, "module-bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer"]], "q8linearcutlass (class in bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer)": [[103, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass"]], "__init__() (bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.q8linearcutlass method)": [[103, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.__init__"]], "_check_forward() (bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.q8linearcutlass method)": [[103, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass._check_forward"]], "bias_a (bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.q8linearcutlass attribute)": [[103, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.bias_a"]], "eps (bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.q8linearcutlass attribute)": [[103, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.eps"]], "forward() (bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.q8linearcutlass method)": [[103, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.forward"], [103, "id0"]], "generate_quantized_weight() (bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.q8linearcutlass method)": [[103, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.generate_quantized_weight"], [103, "id1"]], "prepare_params() (bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.q8linearcutlass method)": [[103, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.prepare_params"], [103, "id2"]], "scale_a (bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.q8linearcutlass attribute)": [[103, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.scale_a"]], "scale_w (bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.q8linearcutlass attribute)": [[103, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.scale_w"]], "set_activation() (bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.q8linearcutlass method)": [[103, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.set_activation"], [103, "id3"]], "q8linearfunction (class in bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer)": [[104, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearFunction"]], "backward() (bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.q8linearfunction static method)": [[104, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearFunction.backward"]], "forward() (bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.q8linearfunction static method)": [[104, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearFunction.forward"]], "bitorch_engine.layers.qlinear.nbit.layer": [[105, "module-bitorch_engine.layers.qlinear.nbit.layer"]], "mpqlinearbase (class in bitorch_engine.layers.qlinear.nbit.layer)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase"]], "__init__() (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase method)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.__init__"]], "a_bit (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase attribute)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.a_bit"]], "asym (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase attribute)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.asym"]], "check_parameters() (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase method)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.check_parameters"], [106, "id0"]], "disable_bias (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase attribute)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.disable_bias"]], "dq_group_size (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase attribute)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.dq_group_size"]], "dq_mode (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase attribute)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.dq_mode"]], "dtype (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase attribute)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.dtype"]], "generate_quantized_weight() (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase method)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.generate_quantized_weight"], [106, "id1"]], "group_size (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase attribute)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.group_size"]], "in_channels (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase attribute)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.in_channels"]], "init_gba() (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase method)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.init_gba"], [106, "id2"]], "init_gptq() (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase method)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.init_gptq"], [106, "id3"]], "initialize() (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase method)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.initialize"], [106, "id4"]], "out_channels (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase attribute)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.out_channels"]], "prepare_params() (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase method)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.prepare_params"], [106, "id5"]], "set_qweight_data() (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase method)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.set_qweight_data"], [106, "id6"]], "use_gba_quant (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase attribute)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.use_gba_quant"]], "w_bit (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase attribute)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.w_bit"]], "mpqweightparameter (class in bitorch_engine.layers.qlinear.nbit.layer)": [[107, "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter"]], "__init__() (bitorch_engine.layers.qlinear.nbit.layer.mpqweightparameter method)": [[107, "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.__init__"]], "asym (bitorch_engine.layers.qlinear.nbit.layer.mpqweightparameter attribute)": [[107, "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.asym"]], "g_idx (bitorch_engine.layers.qlinear.nbit.layer.mpqweightparameter attribute)": [[107, "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.g_idx"]], "group_size (bitorch_engine.layers.qlinear.nbit.layer.mpqweightparameter attribute)": [[107, "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.group_size"]], "layer_type (bitorch_engine.layers.qlinear.nbit.layer.mpqweightparameter attribute)": [[107, "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.layer_type"]], "privileged_grad (bitorch_engine.layers.qlinear.nbit.layer.mpqweightparameter attribute)": [[107, "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.privileged_grad"]], "q_group_map (bitorch_engine.layers.qlinear.nbit.layer.mpqweightparameter attribute)": [[107, "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.q_group_map"]], "q_perm (bitorch_engine.layers.qlinear.nbit.layer.mpqweightparameter attribute)": [[107, "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.q_perm"]], "rows (bitorch_engine.layers.qlinear.nbit.layer.mpqweightparameter attribute)": [[107, "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.rows"]], "update() (bitorch_engine.layers.qlinear.nbit.layer.mpqweightparameter static method)": [[107, "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.update"]], "w_bit (bitorch_engine.layers.qlinear.nbit.layer.mpqweightparameter attribute)": [[107, "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.w_bit"]], "__init__() (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearbase method)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.__init__"]], "a_bit (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearbase attribute)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.a_bit"]], "device (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearbase attribute)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.device"]], "dtype (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearbase attribute)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.dtype"]], "generate_quantized_weight() (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearbase method)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.generate_quantized_weight"]], "in_channels (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearbase attribute)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.in_channels"]], "nbitlinearbase (class in bitorch_engine.layers.qlinear.nbit.layer)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase"]], "opt_weight (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearbase property)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.opt_weight"]], "out_channels (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearbase attribute)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.out_channels"]], "prepare_params() (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearbase method)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.prepare_params"]], "reset_parameters() (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearbase method)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.reset_parameters"]], "set_quantized_weight_data() (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearbase method)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.set_quantized_weight_data"]], "set_weight_data() (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearbase method)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.set_weight_data"]], "w_bit (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearbase attribute)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.w_bit"]], "nbitlinearparameter (class in bitorch_engine.layers.qlinear.nbit.layer)": [[109, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearParameter"]], "update() (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearparameter static method)": [[109, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearParameter.update"]], "bitorch_engine.layers.qlinear.nbit.mps": [[110, "module-bitorch_engine.layers.qlinear.nbit.mps"]], "bitorch_engine.layers.qlinear.nbit.mps.extension": [[111, "module-bitorch_engine.layers.qlinear.nbit.mps.extension"]], "get_ext() (in module bitorch_engine.layers.qlinear.nbit.mps.extension)": [[112, "bitorch_engine.layers.qlinear.nbit.mps.extension.get_ext"]], "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer": [[113, "module-bitorch_engine.layers.qlinear.nbit.mps.mpq_layer"]], "mpqlinearmlx (class in bitorch_engine.layers.qlinear.nbit.mps.mpq_layer)": [[114, "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx"]], "__init__() (bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.mpqlinearmlx method)": [[114, "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.__init__"]], "a_bit (bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.mpqlinearmlx attribute)": [[114, "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.a_bit"]], "check_parameters() (bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.mpqlinearmlx method)": [[114, "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.check_parameters"], [114, "id0"]], "forward() (bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.mpqlinearmlx method)": [[114, "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.forward"], [114, "id1"]], "prepare_params() (bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.mpqlinearmlx method)": [[114, "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.prepare_params"], [114, "id2"]], "qweight (bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.mpqlinearmlx attribute)": [[114, "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.qweight"]], "scales (bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.mpqlinearmlx attribute)": [[114, "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.scales"]], "w_bit (bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.mpqlinearmlx attribute)": [[114, "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.w_bit"]], "zeros (bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.mpqlinearmlx attribute)": [[114, "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.zeros"]], "mpqlinearmlxfunction (class in bitorch_engine.layers.qlinear.nbit.mps.mpq_layer)": [[115, "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlxFunction"]], "backward() (bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.mpqlinearmlxfunction static method)": [[115, "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlxFunction.backward"]], "forward() (bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.mpqlinearmlxfunction static method)": [[115, "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlxFunction.forward"]], "bitorch_engine.layers.qlinear.qlinear_implementation": [[116, "module-bitorch_engine.layers.qlinear.qlinear_implementation"]], "qlinearimplementationmixin (class in bitorch_engine.layers.qlinear.qlinear_implementation)": [[117, "bitorch_engine.layers.qlinear.qlinear_implementation.QLinearImplementationMixin"]], "can_clone() (bitorch_engine.layers.qlinear.qlinear_implementation.qlinearimplementationmixin class method)": [[117, "bitorch_engine.layers.qlinear.qlinear_implementation.QLinearImplementationMixin.can_clone"]], "bitorch_engine.layers.qmha": [[118, "module-bitorch_engine.layers.qmha"]], "bitorch_engine.layers.qmha.binary": [[119, "module-bitorch_engine.layers.qmha.binary"]], "bitorch_engine.layers.qmha.binary.layer": [[120, "module-bitorch_engine.layers.qmha.binary.layer"]], "bmha (class in bitorch_engine.layers.qmha.binary.layer)": [[121, "bitorch_engine.layers.qmha.binary.layer.BMHA"]], "__init__() (bitorch_engine.layers.qmha.binary.layer.bmha method)": [[121, "bitorch_engine.layers.qmha.binary.layer.BMHA.__init__"]], "dropout (bitorch_engine.layers.qmha.binary.layer.bmha attribute)": [[121, "bitorch_engine.layers.qmha.binary.layer.BMHA.dropout"]], "dtype (bitorch_engine.layers.qmha.binary.layer.bmha attribute)": [[121, "bitorch_engine.layers.qmha.binary.layer.BMHA.dtype"]], "forward() (bitorch_engine.layers.qmha.binary.layer.bmha method)": [[121, "bitorch_engine.layers.qmha.binary.layer.BMHA.forward"]], "head_dim (bitorch_engine.layers.qmha.binary.layer.bmha attribute)": [[121, "bitorch_engine.layers.qmha.binary.layer.BMHA.head_dim"]], "hidden_dim (bitorch_engine.layers.qmha.binary.layer.bmha attribute)": [[121, "bitorch_engine.layers.qmha.binary.layer.BMHA.hidden_dim"]], "input_dim (bitorch_engine.layers.qmha.binary.layer.bmha attribute)": [[121, "bitorch_engine.layers.qmha.binary.layer.BMHA.input_dim"]], "k_linear (bitorch_engine.layers.qmha.binary.layer.bmha attribute)": [[121, "bitorch_engine.layers.qmha.binary.layer.BMHA.k_linear"]], "num_heads (bitorch_engine.layers.qmha.binary.layer.bmha attribute)": [[121, "bitorch_engine.layers.qmha.binary.layer.BMHA.num_heads"]], "out (bitorch_engine.layers.qmha.binary.layer.bmha attribute)": [[121, "bitorch_engine.layers.qmha.binary.layer.BMHA.out"]], "q_linear (bitorch_engine.layers.qmha.binary.layer.bmha attribute)": [[121, "bitorch_engine.layers.qmha.binary.layer.BMHA.q_linear"]], "v_linear (bitorch_engine.layers.qmha.binary.layer.bmha attribute)": [[121, "bitorch_engine.layers.qmha.binary.layer.BMHA.v_linear"]], "learnablebias (class in bitorch_engine.layers.qmha.binary.layer)": [[122, "bitorch_engine.layers.qmha.binary.layer.LearnableBias"]], "__init__() (bitorch_engine.layers.qmha.binary.layer.learnablebias method)": [[122, "bitorch_engine.layers.qmha.binary.layer.LearnableBias.__init__"]], "bias (bitorch_engine.layers.qmha.binary.layer.learnablebias attribute)": [[122, "bitorch_engine.layers.qmha.binary.layer.LearnableBias.bias"]], "forward() (bitorch_engine.layers.qmha.binary.layer.learnablebias method)": [[122, "bitorch_engine.layers.qmha.binary.layer.LearnableBias.forward"]], "bitorch_engine.optim": [[123, "module-bitorch_engine.optim"]], "bitorch_engine.optim.diode_beta": [[124, "module-bitorch_engine.optim.diode_beta"]], "diodemix (class in bitorch_engine.optim.diode_beta)": [[125, "bitorch_engine.optim.diode_beta.DiodeMix"]], "__init__() (bitorch_engine.optim.diode_beta.diodemix method)": [[125, "bitorch_engine.optim.diode_beta.DiodeMix.__init__"], [125, "id0"]], "betas (bitorch_engine.optim.diode_beta.diodemix attribute)": [[125, "bitorch_engine.optim.diode_beta.DiodeMix.betas"]], "correct_bias (bitorch_engine.optim.diode_beta.diodemix attribute)": [[125, "bitorch_engine.optim.diode_beta.DiodeMix.correct_bias"]], "dtype (bitorch_engine.optim.diode_beta.diodemix attribute)": [[125, "bitorch_engine.optim.diode_beta.DiodeMix.dtype"]], "eps (bitorch_engine.optim.diode_beta.diodemix attribute)": [[125, "bitorch_engine.optim.diode_beta.DiodeMix.eps"]], "lr (bitorch_engine.optim.diode_beta.diodemix attribute)": [[125, "bitorch_engine.optim.diode_beta.DiodeMix.lr"]], "params (bitorch_engine.optim.diode_beta.diodemix attribute)": [[125, "bitorch_engine.optim.diode_beta.DiodeMix.params"]], "step() (bitorch_engine.optim.diode_beta.diodemix method)": [[125, "bitorch_engine.optim.diode_beta.DiodeMix.step"], [125, "id1"]], "weight_decay (bitorch_engine.optim.diode_beta.diodemix attribute)": [[125, "bitorch_engine.optim.diode_beta.DiodeMix.weight_decay"]], "check_pytorch_version() (in module bitorch_engine.optim.diode_beta)": [[126, "bitorch_engine.optim.diode_beta.check_pytorch_version"]], "bitorch_engine.optim.galore_projector": [[127, "module-bitorch_engine.optim.galore_projector"]], "galoreprojector (class in bitorch_engine.optim.galore_projector)": [[128, "bitorch_engine.optim.galore_projector.GaLoreProjector"]], "__init__() (bitorch_engine.optim.galore_projector.galoreprojector method)": [[128, "bitorch_engine.optim.galore_projector.GaLoreProjector.__init__"]], "bitorch_engine.utils": [[129, "module-bitorch_engine.utils"]], "bitorch_engine.utils.arch_helper": [[130, "module-bitorch_engine.utils.arch_helper"]], "arch_cpu (class in bitorch_engine.utils.arch_helper)": [[131, "bitorch_engine.utils.arch_helper.ARCH_CPU"]], "check_cpu_instruction_support() (in module bitorch_engine.utils.arch_helper)": [[132, "bitorch_engine.utils.arch_helper.check_cpu_instruction_support"]], "get_arm_model() (bitorch_engine.utils.arch_helper.linux_arch_ident static method)": [[133, "bitorch_engine.utils.arch_helper.linux_arch_ident.get_arm_model"]], "is_arm() (bitorch_engine.utils.arch_helper.linux_arch_ident static method)": [[133, "bitorch_engine.utils.arch_helper.linux_arch_ident.is_arm"]], "linux_arch_ident (class in bitorch_engine.utils.arch_helper)": [[133, "bitorch_engine.utils.arch_helper.linux_arch_ident"]], "bitorch_engine.utils.convert": [[134, "module-bitorch_engine.utils.convert"]], "collect_layers() (in module bitorch_engine.utils.convert)": [[135, "bitorch_engine.utils.convert.collect_layers"]], "get_mpq_config() (in module bitorch_engine.utils.convert)": [[136, "bitorch_engine.utils.convert.get_mpq_config"]], "quantize_linear_with_binary_linear_cuda() (in module bitorch_engine.utils.convert)": [[137, "bitorch_engine.utils.convert.quantize_linear_with_binary_linear_cuda"]], "quantize_linear_with_mpq_linear_cuda() (in module bitorch_engine.utils.convert)": [[138, "bitorch_engine.utils.convert.quantize_linear_with_mpq_linear_cuda"]], "quantize_linear_with_q4_linear_cutlass() (in module bitorch_engine.utils.convert)": [[139, "bitorch_engine.utils.convert.quantize_linear_with_q4_linear_cutlass"]], "replace_layers() (in module bitorch_engine.utils.convert)": [[140, "bitorch_engine.utils.convert.replace_layers"]], "bitorch_engine.utils.cpp_extension": [[141, "module-bitorch_engine.utils.cpp_extension"]], "get_cpp_extension() (in module bitorch_engine.utils.cpp_extension)": [[142, "bitorch_engine.utils.cpp_extension.get_cpp_extension"]], "get_kwargs() (in module bitorch_engine.utils.cpp_extension)": [[143, "bitorch_engine.utils.cpp_extension.get_kwargs"]], "bitorch_engine.utils.cuda_extension": [[144, "module-bitorch_engine.utils.cuda_extension"]], "gcc_version() (in module bitorch_engine.utils.cuda_extension)": [[145, "bitorch_engine.utils.cuda_extension.gcc_version"]], "get_cuda_arch() (in module bitorch_engine.utils.cuda_extension)": [[146, "bitorch_engine.utils.cuda_extension.get_cuda_arch"]], "get_cuda_extension() (in module bitorch_engine.utils.cuda_extension)": [[147, "bitorch_engine.utils.cuda_extension.get_cuda_extension"]], "get_kwargs() (in module bitorch_engine.utils.cuda_extension)": [[148, "bitorch_engine.utils.cuda_extension.get_kwargs"]], "bitorch_engine.utils.cutlass_path": [[149, "module-bitorch_engine.utils.cutlass_path"]], "check_path() (in module bitorch_engine.utils.cutlass_path)": [[150, "bitorch_engine.utils.cutlass_path.check_path"]], "find_cutlass() (in module bitorch_engine.utils.cutlass_path)": [[151, "bitorch_engine.utils.cutlass_path.find_cutlass"]], "get_cutlass_include_path() (in module bitorch_engine.utils.cutlass_path)": [[152, "bitorch_engine.utils.cutlass_path.get_cutlass_include_path"]], "is_cutlass_available() (in module bitorch_engine.utils.cutlass_path)": [[153, "bitorch_engine.utils.cutlass_path.is_cutlass_available"]], "bitorch_engine.utils.mlx_extension": [[154, "module-bitorch_engine.utils.mlx_extension"]], "get_mlx_extension() (in module bitorch_engine.utils.mlx_extension)": [[155, "bitorch_engine.utils.mlx_extension.get_mlx_extension"]], "bitorch_engine.utils.mlx_path": [[156, "module-bitorch_engine.utils.mlx_path"]], "get_mlx_include_path() (in module bitorch_engine.utils.mlx_path)": [[157, "bitorch_engine.utils.mlx_path.get_mlx_include_path"]], "get_mlx_lib_path() (in module bitorch_engine.utils.mlx_path)": [[158, "bitorch_engine.utils.mlx_path.get_mlx_lib_path"]], "is_mlx_available() (in module bitorch_engine.utils.mlx_path)": [[159, "bitorch_engine.utils.mlx_path.is_mlx_available"]], "bitorch_engine.utils.model_helper": [[160, "module-bitorch_engine.utils.model_helper"]], "binary_matmul_forward_post_processing() (in module bitorch_engine.utils.model_helper)": [[161, "bitorch_engine.utils.model_helper.binary_matmul_forward_post_processing"]], "flatten_x() (in module bitorch_engine.utils.model_helper)": [[162, "bitorch_engine.utils.model_helper.flatten_x"]], "init_weight() (in module bitorch_engine.utils.model_helper)": [[163, "bitorch_engine.utils.model_helper.init_weight"]], "load_checkpoint() (in module bitorch_engine.utils.model_helper)": [[164, "bitorch_engine.utils.model_helper.load_checkpoint"]], "pack_bie_layers() (in module bitorch_engine.utils.model_helper)": [[165, "bitorch_engine.utils.model_helper.pack_bie_layers"]], "pad_embedding_dim() (in module bitorch_engine.utils.model_helper)": [[166, "bitorch_engine.utils.model_helper.pad_embedding_dim"]], "pad_last_2_dims_to_multiple_of_128() (in module bitorch_engine.utils.model_helper)": [[167, "bitorch_engine.utils.model_helper.pad_last_2_dims_to_multiple_of_128"]], "prepare_bie_layers() (in module bitorch_engine.utils.model_helper)": [[168, "bitorch_engine.utils.model_helper.prepare_bie_layers"]], "qweight_update_fn() (in module bitorch_engine.utils.model_helper)": [[169, "bitorch_engine.utils.model_helper.qweight_update_fn"]], "save_checkpoint() (in module bitorch_engine.utils.model_helper)": [[170, "bitorch_engine.utils.model_helper.save_checkpoint"]], "unflatten_x() (in module bitorch_engine.utils.model_helper)": [[171, "bitorch_engine.utils.model_helper.unflatten_x"]], "update_zeros() (in module bitorch_engine.utils.model_helper)": [[172, "bitorch_engine.utils.model_helper.update_zeros"]], "bitorch_engine.utils.quant_operators": [[173, "module-bitorch_engine.utils.quant_operators"]], "bit_set() (in module bitorch_engine.utils.quant_operators)": [[174, "bitorch_engine.utils.quant_operators.bit_set"]], "get_binary_col() (in module bitorch_engine.utils.quant_operators)": [[175, "bitorch_engine.utils.quant_operators.get_binary_col"]], "get_binary_row() (in module bitorch_engine.utils.quant_operators)": [[176, "bitorch_engine.utils.quant_operators.get_binary_row"]], "gptq_style_unpacking() (in module bitorch_engine.utils.quant_operators)": [[177, "bitorch_engine.utils.quant_operators.gptq_style_unpacking"]], "gptq_style_zeros_packing() (in module bitorch_engine.utils.quant_operators)": [[178, "bitorch_engine.utils.quant_operators.gptq_style_zeros_packing"]], "nv_tensor_quant() (in module bitorch_engine.utils.quant_operators)": [[179, "bitorch_engine.utils.quant_operators.nv_tensor_quant"]], "q4_quantization() (in module bitorch_engine.utils.quant_operators)": [[180, "bitorch_engine.utils.quant_operators.q4_quantization"]], "q8_quantization() (in module bitorch_engine.utils.quant_operators)": [[181, "bitorch_engine.utils.quant_operators.q8_quantization"]], "bitorch_engine.utils.safe_import": [[182, "module-bitorch_engine.utils.safe_import"]], "extensionmoduleplaceholder (class in bitorch_engine.utils.safe_import)": [[183, "bitorch_engine.utils.safe_import.ExtensionModulePlaceholder"]], "__getattr__() (bitorch_engine.utils.safe_import.extensionmoduleplaceholder method)": [[183, "bitorch_engine.utils.safe_import.ExtensionModulePlaceholder.__getattr__"]], "__init__() (bitorch_engine.utils.safe_import.extensionmoduleplaceholder method)": [[183, "bitorch_engine.utils.safe_import.ExtensionModulePlaceholder.__init__"], [183, "id0"]], "__setattr__() (bitorch_engine.utils.safe_import.extensionmoduleplaceholder method)": [[183, "bitorch_engine.utils.safe_import.ExtensionModulePlaceholder.__setattr__"]], "_name (bitorch_engine.utils.safe_import.extensionmoduleplaceholder attribute)": [[183, "bitorch_engine.utils.safe_import.ExtensionModulePlaceholder._name"]], "import_extension() (in module bitorch_engine.utils.safe_import)": [[184, "bitorch_engine.utils.safe_import.import_extension"]]}})