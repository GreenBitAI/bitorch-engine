Search.setIndex({"docnames": ["_autosummary/bitorch_engine", "_autosummary/bitorch_engine.functions", "_autosummary/bitorch_engine.functions.cuda", "_autosummary/bitorch_engine.functions.cuda.extension", "_autosummary/bitorch_engine.functions.cuda.extension.get_ext", "_autosummary/bitorch_engine.functions.cuda.functions", "_autosummary/bitorch_engine.functions.cuda.functions.fp32toint4", "_autosummary/bitorch_engine.functions.cuda.functions.q4_pack_tensor", "_autosummary/bitorch_engine.functions.cuda.functions.q4_unpack_and_scaling_tensor", "_autosummary/bitorch_engine.functions.cuda.functions.q4_unpack_tensor", "_autosummary/bitorch_engine.functions.cuda.functions.tensor_to_packed_uint8", "_autosummary/bitorch_engine.functions.cuda.functions.unpack_uint8_tensor", "_autosummary/bitorch_engine.layers", "_autosummary/bitorch_engine.layers.qconv", "_autosummary/bitorch_engine.layers.qconv.binary", "_autosummary/bitorch_engine.layers.qconv.binary.cpp", "_autosummary/bitorch_engine.layers.qconv.binary.cpp.extension", "_autosummary/bitorch_engine.layers.qconv.binary.cpp.extension.get_ext", "_autosummary/bitorch_engine.layers.qconv.binary.cpp.layer", "_autosummary/bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP", "_autosummary/bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dForward", "_autosummary/bitorch_engine.layers.qconv.binary.cutlass", "_autosummary/bitorch_engine.layers.qconv.binary.cutlass.extension", "_autosummary/bitorch_engine.layers.qconv.binary.cutlass.extension.get_ext", "_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer", "_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass", "_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dForward", "_autosummary/bitorch_engine.layers.qconv.binary.layer", "_autosummary/bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase", "_autosummary/bitorch_engine.layers.qconv.binary.layer.BinaryConvParameter", "_autosummary/bitorch_engine.layers.qconv.nbit", "_autosummary/bitorch_engine.layers.qconv.nbit.cutlass", "_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.extension", "_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.extension.get_ext", "_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer", "_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass", "_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward", "_autosummary/bitorch_engine.layers.qconv.nbit.layer", "_autosummary/bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase", "_autosummary/bitorch_engine.layers.qconv.nbit.layer.nBitConvParameter", "_autosummary/bitorch_engine.layers.qembedding", "_autosummary/bitorch_engine.layers.qembedding.binary", "_autosummary/bitorch_engine.layers.qembedding.binary.layer", "_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag", "_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward", "_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda", "_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingForward", "_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingParameter", "_autosummary/bitorch_engine.layers.qlinear", "_autosummary/bitorch_engine.layers.qlinear.binary", "_autosummary/bitorch_engine.layers.qlinear.binary.binary_implementation", "_autosummary/bitorch_engine.layers.qlinear.binary.binary_implementation.BinaryLinearImplementationMixin", "_autosummary/bitorch_engine.layers.qlinear.binary.cpp", "_autosummary/bitorch_engine.layers.qlinear.binary.cpp.extension", "_autosummary/bitorch_engine.layers.qlinear.binary.cpp.extension.get_ext", "_autosummary/bitorch_engine.layers.qlinear.binary.cpp.layer", "_autosummary/bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP", "_autosummary/bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearForward", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.bmm", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.extension", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.extension.get_ext", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.extension", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.extension.get_ext", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMulFunction", "_autosummary/bitorch_engine.layers.qlinear.binary.get_best_binary_implementation", "_autosummary/bitorch_engine.layers.qlinear.binary.layer", "_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase", "_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearParameter", "_autosummary/bitorch_engine.layers.qlinear.layer", "_autosummary/bitorch_engine.layers.qlinear.layer.QLinearInf", "_autosummary/bitorch_engine.layers.qlinear.nbit", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.extension", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.extension.get_ext", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCudaFunction", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.utils", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.utils.make_group_map", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.utils.pack_fp_weight", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.utils.unpack_qweight", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.extension", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.extension.get_ext", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearFunction", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMulFunction", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearFunction", "_autosummary/bitorch_engine.layers.qlinear.nbit.layer", "_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase", "_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter", "_autosummary/bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase", "_autosummary/bitorch_engine.layers.qlinear.nbit.layer.nBitLinearParameter", "_autosummary/bitorch_engine.layers.qlinear.nbit.mps", "_autosummary/bitorch_engine.layers.qlinear.nbit.mps.extension", "_autosummary/bitorch_engine.layers.qlinear.nbit.mps.extension.get_ext", "_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer", "_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx", "_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlxFunction", "_autosummary/bitorch_engine.layers.qlinear.qlinear_implementation", "_autosummary/bitorch_engine.layers.qlinear.qlinear_implementation.QLinearImplementationMixin", "_autosummary/bitorch_engine.layers.qmha", "_autosummary/bitorch_engine.layers.qmha.binary", "_autosummary/bitorch_engine.layers.qmha.binary.layer", "_autosummary/bitorch_engine.layers.qmha.binary.layer.BMHA", "_autosummary/bitorch_engine.layers.qmha.binary.layer.LearnableBias", "_autosummary/bitorch_engine.optim", "_autosummary/bitorch_engine.optim.diode_beta", "_autosummary/bitorch_engine.optim.diode_beta.DiodeMix", "_autosummary/bitorch_engine.optim.diode_beta.check_pytorch_version", "_autosummary/bitorch_engine.optim.galore_projector", "_autosummary/bitorch_engine.optim.galore_projector.GaLoreProjector", "_autosummary/bitorch_engine.utils", "_autosummary/bitorch_engine.utils.arch_helper", "_autosummary/bitorch_engine.utils.arch_helper.ARCH_CPU", "_autosummary/bitorch_engine.utils.arch_helper.check_cpu_instruction_support", "_autosummary/bitorch_engine.utils.arch_helper.linux_arch_ident", "_autosummary/bitorch_engine.utils.convert", "_autosummary/bitorch_engine.utils.convert.collect_layers", "_autosummary/bitorch_engine.utils.convert.get_mpq_config", "_autosummary/bitorch_engine.utils.convert.quantize_linear_with_binary_linear_cuda", "_autosummary/bitorch_engine.utils.convert.quantize_linear_with_mpq_linear_cuda", "_autosummary/bitorch_engine.utils.convert.quantize_linear_with_q4_linear_cutlass", "_autosummary/bitorch_engine.utils.convert.replace_layers", "_autosummary/bitorch_engine.utils.cpp_extension", "_autosummary/bitorch_engine.utils.cpp_extension.get_cpp_extension", "_autosummary/bitorch_engine.utils.cpp_extension.get_kwargs", "_autosummary/bitorch_engine.utils.cuda_extension", "_autosummary/bitorch_engine.utils.cuda_extension.gcc_version", "_autosummary/bitorch_engine.utils.cuda_extension.get_cuda_extension", "_autosummary/bitorch_engine.utils.cuda_extension.get_kwargs", "_autosummary/bitorch_engine.utils.cutlass_path", "_autosummary/bitorch_engine.utils.cutlass_path.check_path", "_autosummary/bitorch_engine.utils.cutlass_path.find_cutlass", "_autosummary/bitorch_engine.utils.cutlass_path.get_cutlass_include_path", "_autosummary/bitorch_engine.utils.cutlass_path.is_cutlass_available", "_autosummary/bitorch_engine.utils.mlx_extension", "_autosummary/bitorch_engine.utils.mlx_extension.get_mlx_extension", "_autosummary/bitorch_engine.utils.mlx_path", "_autosummary/bitorch_engine.utils.mlx_path.get_mlx_include_path", "_autosummary/bitorch_engine.utils.mlx_path.get_mlx_lib_path", "_autosummary/bitorch_engine.utils.mlx_path.is_mlx_available", "_autosummary/bitorch_engine.utils.model_helper", "_autosummary/bitorch_engine.utils.model_helper.binary_matmul_forward_post_processing", "_autosummary/bitorch_engine.utils.model_helper.flatten_x", "_autosummary/bitorch_engine.utils.model_helper.init_weight", "_autosummary/bitorch_engine.utils.model_helper.load_checkpoint", "_autosummary/bitorch_engine.utils.model_helper.pack_bie_layers", "_autosummary/bitorch_engine.utils.model_helper.pad_embedding_dim", "_autosummary/bitorch_engine.utils.model_helper.pad_last_2_dims_to_multiple_of_128", "_autosummary/bitorch_engine.utils.model_helper.prepare_bie_layers", "_autosummary/bitorch_engine.utils.model_helper.qweight_update_fn", "_autosummary/bitorch_engine.utils.model_helper.save_checkpoint", "_autosummary/bitorch_engine.utils.model_helper.unflatten_x", "_autosummary/bitorch_engine.utils.quant_operators", "_autosummary/bitorch_engine.utils.quant_operators.bit_set", "_autosummary/bitorch_engine.utils.quant_operators.get_binary_col", "_autosummary/bitorch_engine.utils.quant_operators.get_binary_row", "_autosummary/bitorch_engine.utils.quant_operators.gptq_stype_unpacking", "_autosummary/bitorch_engine.utils.quant_operators.nv_tensor_quant", "_autosummary/bitorch_engine.utils.quant_operators.q4_quantization", "_autosummary/bitorch_engine.utils.quant_operators.q8_quantization", "_autosummary/bitorch_engine.utils.safe_import", "_autosummary/bitorch_engine.utils.safe_import.ExtensionModulePlaceholder", "_autosummary/bitorch_engine.utils.safe_import.import_extension", "build_options", "documentation", "index", "installation"], "filenames": ["_autosummary/bitorch_engine.rst", "_autosummary/bitorch_engine.functions.rst", "_autosummary/bitorch_engine.functions.cuda.rst", "_autosummary/bitorch_engine.functions.cuda.extension.rst", "_autosummary/bitorch_engine.functions.cuda.extension.get_ext.rst", "_autosummary/bitorch_engine.functions.cuda.functions.rst", "_autosummary/bitorch_engine.functions.cuda.functions.fp32toint4.rst", "_autosummary/bitorch_engine.functions.cuda.functions.q4_pack_tensor.rst", "_autosummary/bitorch_engine.functions.cuda.functions.q4_unpack_and_scaling_tensor.rst", "_autosummary/bitorch_engine.functions.cuda.functions.q4_unpack_tensor.rst", "_autosummary/bitorch_engine.functions.cuda.functions.tensor_to_packed_uint8.rst", "_autosummary/bitorch_engine.functions.cuda.functions.unpack_uint8_tensor.rst", "_autosummary/bitorch_engine.layers.rst", "_autosummary/bitorch_engine.layers.qconv.rst", "_autosummary/bitorch_engine.layers.qconv.binary.rst", "_autosummary/bitorch_engine.layers.qconv.binary.cpp.rst", "_autosummary/bitorch_engine.layers.qconv.binary.cpp.extension.rst", "_autosummary/bitorch_engine.layers.qconv.binary.cpp.extension.get_ext.rst", "_autosummary/bitorch_engine.layers.qconv.binary.cpp.layer.rst", "_autosummary/bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP.rst", "_autosummary/bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dForward.rst", "_autosummary/bitorch_engine.layers.qconv.binary.cutlass.rst", "_autosummary/bitorch_engine.layers.qconv.binary.cutlass.extension.rst", "_autosummary/bitorch_engine.layers.qconv.binary.cutlass.extension.get_ext.rst", "_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer.rst", "_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.rst", "_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dForward.rst", "_autosummary/bitorch_engine.layers.qconv.binary.layer.rst", "_autosummary/bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.rst", "_autosummary/bitorch_engine.layers.qconv.binary.layer.BinaryConvParameter.rst", "_autosummary/bitorch_engine.layers.qconv.nbit.rst", "_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.rst", "_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.extension.rst", "_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.extension.get_ext.rst", "_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer.rst", "_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.rst", "_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward.rst", "_autosummary/bitorch_engine.layers.qconv.nbit.layer.rst", "_autosummary/bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.rst", "_autosummary/bitorch_engine.layers.qconv.nbit.layer.nBitConvParameter.rst", "_autosummary/bitorch_engine.layers.qembedding.rst", "_autosummary/bitorch_engine.layers.qembedding.binary.rst", "_autosummary/bitorch_engine.layers.qembedding.binary.layer.rst", "_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.rst", "_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward.rst", "_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.rst", "_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingForward.rst", "_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingParameter.rst", "_autosummary/bitorch_engine.layers.qlinear.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.binary_implementation.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.binary_implementation.BinaryLinearImplementationMixin.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cpp.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cpp.extension.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cpp.extension.get_ext.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cpp.layer.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearForward.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.bmm.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.extension.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.extension.get_ext.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.extension.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.extension.get_ext.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMulFunction.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.get_best_binary_implementation.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.layer.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.rst", "_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearParameter.rst", "_autosummary/bitorch_engine.layers.qlinear.layer.rst", "_autosummary/bitorch_engine.layers.qlinear.layer.QLinearInf.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.extension.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.extension.get_ext.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCudaFunction.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.utils.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.utils.make_group_map.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.utils.pack_fp_weight.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.utils.unpack_qweight.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.extension.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.extension.get_ext.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearFunction.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMulFunction.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearFunction.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.layer.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.layer.nBitLinearParameter.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.mps.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.mps.extension.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.mps.extension.get_ext.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.rst", "_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlxFunction.rst", "_autosummary/bitorch_engine.layers.qlinear.qlinear_implementation.rst", "_autosummary/bitorch_engine.layers.qlinear.qlinear_implementation.QLinearImplementationMixin.rst", "_autosummary/bitorch_engine.layers.qmha.rst", "_autosummary/bitorch_engine.layers.qmha.binary.rst", "_autosummary/bitorch_engine.layers.qmha.binary.layer.rst", "_autosummary/bitorch_engine.layers.qmha.binary.layer.BMHA.rst", "_autosummary/bitorch_engine.layers.qmha.binary.layer.LearnableBias.rst", "_autosummary/bitorch_engine.optim.rst", "_autosummary/bitorch_engine.optim.diode_beta.rst", "_autosummary/bitorch_engine.optim.diode_beta.DiodeMix.rst", "_autosummary/bitorch_engine.optim.diode_beta.check_pytorch_version.rst", "_autosummary/bitorch_engine.optim.galore_projector.rst", "_autosummary/bitorch_engine.optim.galore_projector.GaLoreProjector.rst", "_autosummary/bitorch_engine.utils.rst", "_autosummary/bitorch_engine.utils.arch_helper.rst", "_autosummary/bitorch_engine.utils.arch_helper.ARCH_CPU.rst", "_autosummary/bitorch_engine.utils.arch_helper.check_cpu_instruction_support.rst", "_autosummary/bitorch_engine.utils.arch_helper.linux_arch_ident.rst", "_autosummary/bitorch_engine.utils.convert.rst", "_autosummary/bitorch_engine.utils.convert.collect_layers.rst", "_autosummary/bitorch_engine.utils.convert.get_mpq_config.rst", "_autosummary/bitorch_engine.utils.convert.quantize_linear_with_binary_linear_cuda.rst", "_autosummary/bitorch_engine.utils.convert.quantize_linear_with_mpq_linear_cuda.rst", "_autosummary/bitorch_engine.utils.convert.quantize_linear_with_q4_linear_cutlass.rst", "_autosummary/bitorch_engine.utils.convert.replace_layers.rst", "_autosummary/bitorch_engine.utils.cpp_extension.rst", "_autosummary/bitorch_engine.utils.cpp_extension.get_cpp_extension.rst", "_autosummary/bitorch_engine.utils.cpp_extension.get_kwargs.rst", "_autosummary/bitorch_engine.utils.cuda_extension.rst", "_autosummary/bitorch_engine.utils.cuda_extension.gcc_version.rst", "_autosummary/bitorch_engine.utils.cuda_extension.get_cuda_extension.rst", "_autosummary/bitorch_engine.utils.cuda_extension.get_kwargs.rst", "_autosummary/bitorch_engine.utils.cutlass_path.rst", "_autosummary/bitorch_engine.utils.cutlass_path.check_path.rst", "_autosummary/bitorch_engine.utils.cutlass_path.find_cutlass.rst", "_autosummary/bitorch_engine.utils.cutlass_path.get_cutlass_include_path.rst", "_autosummary/bitorch_engine.utils.cutlass_path.is_cutlass_available.rst", "_autosummary/bitorch_engine.utils.mlx_extension.rst", "_autosummary/bitorch_engine.utils.mlx_extension.get_mlx_extension.rst", "_autosummary/bitorch_engine.utils.mlx_path.rst", "_autosummary/bitorch_engine.utils.mlx_path.get_mlx_include_path.rst", "_autosummary/bitorch_engine.utils.mlx_path.get_mlx_lib_path.rst", "_autosummary/bitorch_engine.utils.mlx_path.is_mlx_available.rst", "_autosummary/bitorch_engine.utils.model_helper.rst", "_autosummary/bitorch_engine.utils.model_helper.binary_matmul_forward_post_processing.rst", "_autosummary/bitorch_engine.utils.model_helper.flatten_x.rst", "_autosummary/bitorch_engine.utils.model_helper.init_weight.rst", "_autosummary/bitorch_engine.utils.model_helper.load_checkpoint.rst", "_autosummary/bitorch_engine.utils.model_helper.pack_bie_layers.rst", "_autosummary/bitorch_engine.utils.model_helper.pad_embedding_dim.rst", "_autosummary/bitorch_engine.utils.model_helper.pad_last_2_dims_to_multiple_of_128.rst", "_autosummary/bitorch_engine.utils.model_helper.prepare_bie_layers.rst", "_autosummary/bitorch_engine.utils.model_helper.qweight_update_fn.rst", "_autosummary/bitorch_engine.utils.model_helper.save_checkpoint.rst", "_autosummary/bitorch_engine.utils.model_helper.unflatten_x.rst", "_autosummary/bitorch_engine.utils.quant_operators.rst", "_autosummary/bitorch_engine.utils.quant_operators.bit_set.rst", "_autosummary/bitorch_engine.utils.quant_operators.get_binary_col.rst", "_autosummary/bitorch_engine.utils.quant_operators.get_binary_row.rst", "_autosummary/bitorch_engine.utils.quant_operators.gptq_stype_unpacking.rst", "_autosummary/bitorch_engine.utils.quant_operators.nv_tensor_quant.rst", "_autosummary/bitorch_engine.utils.quant_operators.q4_quantization.rst", "_autosummary/bitorch_engine.utils.quant_operators.q8_quantization.rst", "_autosummary/bitorch_engine.utils.safe_import.rst", "_autosummary/bitorch_engine.utils.safe_import.ExtensionModulePlaceholder.rst", "_autosummary/bitorch_engine.utils.safe_import.import_extension.rst", "build_options.rst", "documentation.rst", "index.rst", "installation.rst"], "titles": ["bitorch_engine", "bitorch_engine.functions", "bitorch_engine.functions.cuda", "bitorch_engine.functions.cuda.extension", "bitorch_engine.functions.cuda.extension.get_ext", "bitorch_engine.functions.cuda.functions", "bitorch_engine.functions.cuda.functions.fp32toint4", "bitorch_engine.functions.cuda.functions.q4_pack_tensor", "bitorch_engine.functions.cuda.functions.q4_unpack_and_scaling_tensor", "bitorch_engine.functions.cuda.functions.q4_unpack_tensor", "bitorch_engine.functions.cuda.functions.tensor_to_packed_uint8", "bitorch_engine.functions.cuda.functions.unpack_uint8_tensor", "bitorch_engine.layers", "bitorch_engine.layers.qconv", "bitorch_engine.layers.qconv.binary", "bitorch_engine.layers.qconv.binary.cpp", "bitorch_engine.layers.qconv.binary.cpp.extension", "bitorch_engine.layers.qconv.binary.cpp.extension.get_ext", "bitorch_engine.layers.qconv.binary.cpp.layer", "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP", "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dForward", "bitorch_engine.layers.qconv.binary.cutlass", "bitorch_engine.layers.qconv.binary.cutlass.extension", "bitorch_engine.layers.qconv.binary.cutlass.extension.get_ext", "bitorch_engine.layers.qconv.binary.cutlass.layer", "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass", "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dForward", "bitorch_engine.layers.qconv.binary.layer", "bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase", "bitorch_engine.layers.qconv.binary.layer.BinaryConvParameter", "bitorch_engine.layers.qconv.nbit", "bitorch_engine.layers.qconv.nbit.cutlass", "bitorch_engine.layers.qconv.nbit.cutlass.extension", "bitorch_engine.layers.qconv.nbit.cutlass.extension.get_ext", "bitorch_engine.layers.qconv.nbit.cutlass.layer", "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass", "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward", "bitorch_engine.layers.qconv.nbit.layer", "bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase", "bitorch_engine.layers.qconv.nbit.layer.nBitConvParameter", "bitorch_engine.layers.qembedding", "bitorch_engine.layers.qembedding.binary", "bitorch_engine.layers.qembedding.binary.layer", "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag", "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward", "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda", "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingForward", "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingParameter", "bitorch_engine.layers.qlinear", "bitorch_engine.layers.qlinear.binary", "bitorch_engine.layers.qlinear.binary.binary_implementation", "bitorch_engine.layers.qlinear.binary.binary_implementation.BinaryLinearImplementationMixin", "bitorch_engine.layers.qlinear.binary.cpp", "bitorch_engine.layers.qlinear.binary.cpp.extension", "bitorch_engine.layers.qlinear.binary.cpp.extension.get_ext", "bitorch_engine.layers.qlinear.binary.cpp.layer", "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP", "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearForward", "bitorch_engine.layers.qlinear.binary.cuda", "bitorch_engine.layers.qlinear.binary.cuda.bmm", "bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM", "bitorch_engine.layers.qlinear.binary.cuda.extension", "bitorch_engine.layers.qlinear.binary.cuda.extension.get_ext", "bitorch_engine.layers.qlinear.binary.cuda.layer", "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda", "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward", "bitorch_engine.layers.qlinear.binary.cutlass", "bitorch_engine.layers.qlinear.binary.cutlass.extension", "bitorch_engine.layers.qlinear.binary.cutlass.extension.get_ext", "bitorch_engine.layers.qlinear.binary.cutlass.layer", "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass", "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward", "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul", "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMulFunction", "bitorch_engine.layers.qlinear.binary.get_best_binary_implementation", "bitorch_engine.layers.qlinear.binary.layer", "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase", "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearParameter", "bitorch_engine.layers.qlinear.layer", "bitorch_engine.layers.qlinear.layer.QLinearInf", "bitorch_engine.layers.qlinear.nbit", "bitorch_engine.layers.qlinear.nbit.cuda", "bitorch_engine.layers.qlinear.nbit.cuda.extension", "bitorch_engine.layers.qlinear.nbit.cuda.extension.get_ext", "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer", "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda", "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction", "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer", "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda", "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCudaFunction", "bitorch_engine.layers.qlinear.nbit.cuda.utils", "bitorch_engine.layers.qlinear.nbit.cuda.utils.make_group_map", "bitorch_engine.layers.qlinear.nbit.cuda.utils.pack_fp_weight", "bitorch_engine.layers.qlinear.nbit.cuda.utils.unpack_qweight", "bitorch_engine.layers.qlinear.nbit.cutlass", "bitorch_engine.layers.qlinear.nbit.cutlass.extension", "bitorch_engine.layers.qlinear.nbit.cutlass.extension.get_ext", "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer", "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass", "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearFunction", "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul", "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMulFunction", "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer", "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass", "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearFunction", "bitorch_engine.layers.qlinear.nbit.layer", "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase", "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter", "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase", "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearParameter", "bitorch_engine.layers.qlinear.nbit.mps", "bitorch_engine.layers.qlinear.nbit.mps.extension", "bitorch_engine.layers.qlinear.nbit.mps.extension.get_ext", "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer", "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx", "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlxFunction", "bitorch_engine.layers.qlinear.qlinear_implementation", "bitorch_engine.layers.qlinear.qlinear_implementation.QLinearImplementationMixin", "bitorch_engine.layers.qmha", "bitorch_engine.layers.qmha.binary", "bitorch_engine.layers.qmha.binary.layer", "bitorch_engine.layers.qmha.binary.layer.BMHA", "bitorch_engine.layers.qmha.binary.layer.LearnableBias", "bitorch_engine.optim", "bitorch_engine.optim.diode_beta", "bitorch_engine.optim.diode_beta.DiodeMix", "bitorch_engine.optim.diode_beta.check_pytorch_version", "bitorch_engine.optim.galore_projector", "bitorch_engine.optim.galore_projector.GaLoreProjector", "bitorch_engine.utils", "bitorch_engine.utils.arch_helper", "bitorch_engine.utils.arch_helper.ARCH_CPU", "bitorch_engine.utils.arch_helper.check_cpu_instruction_support", "bitorch_engine.utils.arch_helper.linux_arch_ident", "bitorch_engine.utils.convert", "bitorch_engine.utils.convert.collect_layers", "bitorch_engine.utils.convert.get_mpq_config", "bitorch_engine.utils.convert.quantize_linear_with_binary_linear_cuda", "bitorch_engine.utils.convert.quantize_linear_with_mpq_linear_cuda", "bitorch_engine.utils.convert.quantize_linear_with_q4_linear_cutlass", "bitorch_engine.utils.convert.replace_layers", "bitorch_engine.utils.cpp_extension", "bitorch_engine.utils.cpp_extension.get_cpp_extension", "bitorch_engine.utils.cpp_extension.get_kwargs", "bitorch_engine.utils.cuda_extension", "bitorch_engine.utils.cuda_extension.gcc_version", "bitorch_engine.utils.cuda_extension.get_cuda_extension", "bitorch_engine.utils.cuda_extension.get_kwargs", "bitorch_engine.utils.cutlass_path", "bitorch_engine.utils.cutlass_path.check_path", "bitorch_engine.utils.cutlass_path.find_cutlass", "bitorch_engine.utils.cutlass_path.get_cutlass_include_path", "bitorch_engine.utils.cutlass_path.is_cutlass_available", "bitorch_engine.utils.mlx_extension", "bitorch_engine.utils.mlx_extension.get_mlx_extension", "bitorch_engine.utils.mlx_path", "bitorch_engine.utils.mlx_path.get_mlx_include_path", "bitorch_engine.utils.mlx_path.get_mlx_lib_path", "bitorch_engine.utils.mlx_path.is_mlx_available", "bitorch_engine.utils.model_helper", "bitorch_engine.utils.model_helper.binary_matmul_forward_post_processing", "bitorch_engine.utils.model_helper.flatten_x", "bitorch_engine.utils.model_helper.init_weight", "bitorch_engine.utils.model_helper.load_checkpoint", "bitorch_engine.utils.model_helper.pack_bie_layers", "bitorch_engine.utils.model_helper.pad_embedding_dim", "bitorch_engine.utils.model_helper.pad_last_2_dims_to_multiple_of_128", "bitorch_engine.utils.model_helper.prepare_bie_layers", "bitorch_engine.utils.model_helper.qweight_update_fn", "bitorch_engine.utils.model_helper.save_checkpoint", "bitorch_engine.utils.model_helper.unflatten_x", "bitorch_engine.utils.quant_operators", "bitorch_engine.utils.quant_operators.bit_set", "bitorch_engine.utils.quant_operators.get_binary_col", "bitorch_engine.utils.quant_operators.get_binary_row", "bitorch_engine.utils.quant_operators.gptq_stype_unpacking", "bitorch_engine.utils.quant_operators.nv_tensor_quant", "bitorch_engine.utils.quant_operators.q4_quantization", "bitorch_engine.utils.quant_operators.q8_quantization", "bitorch_engine.utils.safe_import", "bitorch_engine.utils.safe_import.ExtensionModulePlaceholder", "bitorch_engine.utils.safe_import.import_extension", "Build options", "Full Documentation", "Welcome to Bitorch Engine\u2019s documentation!", "Installation"], "terms": {"modul": [0, 1, 2, 8, 9, 12, 13, 14, 15, 21, 30, 31, 38, 40, 41, 43, 45, 48, 49, 52, 54, 58, 62, 66, 72, 80, 81, 83, 94, 100, 108, 110, 118, 119, 121, 122, 123, 129, 135, 137, 138, 139, 140, 163, 164, 167, 169, 180, 181, 184], "path": [4, 17, 23, 33, 54, 62, 68, 83, 96, 112, 142, 146, 147, 149, 150, 154, 156, 157, 158, 163, 169, 182, 185], "sourc": [4, 6, 7, 8, 9, 10, 11, 17, 19, 20, 23, 25, 26, 28, 29, 33, 35, 36, 38, 39, 43, 44, 45, 46, 47, 51, 54, 56, 57, 60, 62, 64, 65, 68, 70, 71, 72, 73, 74, 76, 77, 79, 83, 85, 86, 88, 89, 91, 92, 93, 96, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 112, 114, 115, 117, 121, 122, 125, 126, 128, 131, 132, 133, 135, 136, 137, 138, 139, 140, 142, 143, 145, 146, 147, 149, 150, 151, 152, 154, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 172, 173, 174, 175, 176, 177, 178, 180, 181, 185], "gener": [4, 19, 25, 28, 38, 45, 56, 64, 79, 91, 106, 108, 143, 147], "specifi": [4, 33, 43, 45, 47, 51, 64, 70, 76, 79, 85, 88, 99, 114, 121, 126, 147, 150, 154, 156, 157, 160, 164, 167, 172, 174, 176, 180, 185], "paramet": [4, 6, 7, 8, 9, 10, 11, 17, 19, 20, 23, 25, 26, 28, 29, 33, 35, 36, 38, 39, 43, 44, 45, 46, 47, 51, 54, 56, 57, 62, 64, 65, 68, 70, 71, 72, 73, 76, 77, 79, 83, 85, 86, 88, 89, 91, 92, 93, 96, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 114, 115, 117, 121, 122, 125, 126, 132, 135, 136, 140, 149, 150, 154, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 172, 173, 174, 175, 176, 177, 178, 180, 181, 184], "directori": [4, 17, 23, 33, 54, 62, 83, 96, 143, 149, 150, 154, 156, 157, 182, 185], "contain": [4, 7, 8, 9, 11, 17, 23, 25, 28, 33, 44, 46, 51, 54, 56, 64, 65, 71, 76, 79, 85, 86, 89, 91, 92, 93, 96, 99, 101, 104, 115, 117, 121, 137, 138, 139, 143, 145, 147, 149, 156, 161, 162, 164, 167, 173, 175, 176], "file": [4, 23, 33, 96, 143, 149, 154, 156, 157, 163, 169, 185], "return": [4, 6, 7, 8, 9, 10, 11, 17, 19, 20, 23, 25, 26, 28, 29, 33, 35, 36, 38, 39, 43, 44, 45, 46, 47, 51, 54, 56, 57, 62, 64, 65, 68, 70, 71, 72, 73, 76, 77, 79, 83, 85, 86, 88, 89, 91, 92, 93, 96, 98, 99, 100, 101, 103, 104, 107, 108, 109, 114, 115, 117, 121, 122, 125, 132, 133, 135, 136, 137, 138, 139, 140, 143, 145, 147, 149, 150, 154, 156, 157, 158, 160, 161, 162, 165, 166, 168, 169, 170, 172, 173, 174, 175, 176, 177, 178, 181], "type": [4, 6, 7, 8, 9, 10, 11, 17, 19, 20, 23, 25, 26, 28, 29, 33, 35, 36, 38, 39, 43, 44, 45, 46, 47, 51, 54, 56, 57, 62, 64, 65, 68, 70, 71, 72, 73, 76, 77, 79, 83, 85, 86, 88, 89, 91, 92, 93, 96, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 114, 115, 117, 121, 122, 125, 132, 135, 140, 143, 145, 147, 149, 150, 154, 156, 157, 158, 161, 162, 164, 165, 166, 167, 168, 170, 172, 173, 174, 175, 176, 177, 178, 180, 181], "input": [6, 7, 8, 9, 10, 11, 19, 20, 25, 26, 28, 35, 36, 38, 43, 44, 45, 46, 51, 56, 57, 60, 64, 65, 70, 71, 72, 73, 76, 79, 85, 86, 88, 89, 93, 98, 99, 100, 101, 103, 104, 106, 108, 114, 115, 117, 121, 122, 161, 165, 166, 170, 173, 174, 175, 176, 177, 178], "tensor": [6, 7, 8, 9, 10, 11, 19, 20, 25, 26, 28, 29, 35, 36, 38, 39, 43, 44, 45, 46, 47, 56, 57, 60, 64, 65, 70, 71, 72, 73, 76, 77, 79, 85, 86, 88, 89, 91, 92, 93, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 114, 115, 121, 122, 160, 161, 162, 165, 166, 168, 170, 175, 176, 177, 178, 185], "convert": [6, 10, 11, 25, 28, 64, 70, 71, 76, 85, 103, 108, 160, 162, 174, 176, 184], "32": [6, 25, 70, 117, 136, 184], "bit": [6, 7, 8, 9, 10, 11, 19, 25, 28, 35, 36, 38, 39, 43, 45, 46, 60, 64, 70, 76, 79, 85, 86, 88, 89, 91, 92, 93, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 114, 115, 125, 136, 162, 164, 167, 169, 172, 173, 174, 176, 177, 178, 184], "float": [6, 8, 11, 25, 28, 29, 35, 38, 39, 45, 47, 64, 70, 72, 76, 77, 85, 92, 98, 100, 106, 107, 108, 109, 121, 125, 162, 168, 177, 178], "point": [6, 11, 25, 35, 45, 64, 70, 76, 85, 86, 88, 89, 92, 98, 104, 106, 107, 108, 114, 115, 125, 162, 177, 178], "4": [6, 7, 8, 9, 35, 36, 38, 85, 86, 88, 98, 99, 100, 101, 106, 108, 114, 125, 136, 177, 184, 185], "integ": [6, 10, 11, 91, 92, 145, 172, 177, 178], "represent": [6, 7, 8, 9, 10, 11, 43, 70, 85, 98, 104, 172, 173, 174, 176], "thi": [6, 7, 8, 9, 10, 11, 19, 20, 25, 26, 28, 29, 35, 36, 38, 39, 43, 44, 45, 46, 47, 51, 56, 57, 60, 64, 65, 70, 71, 72, 73, 76, 77, 79, 85, 86, 88, 89, 91, 92, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 114, 115, 117, 121, 122, 125, 127, 132, 133, 136, 140, 143, 145, 147, 149, 150, 154, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 172, 173, 174, 176, 180, 181, 184, 185], "take": [6, 7, 101, 165], "an": [6, 7, 8, 9, 10, 11, 28, 43, 44, 46, 51, 64, 65, 70, 71, 76, 79, 85, 88, 92, 103, 106, 114, 117, 121, 133, 140, 145, 149, 150, 154, 172, 173, 174, 176, 177, 178, 181, 185], "number": [6, 7, 19, 20, 28, 38, 56, 57, 70, 71, 76, 88, 91, 98, 103, 106, 108, 114, 117, 121, 122, 145, 160, 165, 166, 173, 174, 176], "compress": [6, 11, 164], "effect": [6, 43, 44, 64, 65, 99, 172], "reduc": [6, 7, 8, 9, 35, 70, 89, 98, 103, 106, 115, 169], "memori": [6, 19, 25, 28, 29, 35, 38, 39, 43, 47, 56, 64, 70, 77, 85, 89, 98, 103, 106, 109, 115, 127], "footprint": [6, 70, 89, 103, 106, 115], "factor": [6, 8, 11, 26, 36, 45, 46, 65, 70, 71, 85, 86, 88, 98, 99, 100, 103, 104, 106, 114, 176, 177, 178], "8": [6, 10, 11, 19, 43, 56, 70, 76, 88, 98, 100, 103, 104, 114, 136, 165, 176, 177, 178, 185], "The": [6, 7, 8, 9, 10, 11, 17, 19, 20, 23, 25, 26, 28, 29, 33, 35, 36, 38, 39, 43, 44, 45, 46, 47, 51, 56, 57, 60, 62, 64, 65, 68, 70, 71, 72, 73, 76, 77, 79, 83, 85, 86, 88, 89, 91, 92, 93, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 114, 115, 117, 121, 122, 125, 126, 132, 143, 145, 149, 150, 154, 156, 157, 160, 162, 163, 164, 166, 167, 168, 169, 170, 172, 173, 174, 175, 176, 177, 178, 180, 181, 185], "convers": [6, 25, 26, 64, 70, 71, 85, 160, 162], "process": [6, 7, 8, 9, 11, 29, 39, 46, 47, 65, 70, 77, 85, 86, 91, 98, 106, 107, 108, 109, 122, 160, 161, 162, 164, 168, 173, 174, 177, 178, 184], "involv": [6, 29, 39, 43, 44, 46, 47, 60, 65, 77, 98, 107, 109, 125, 160, 168], "find": [6, 150, 156, 157, 184], "minimum": [6, 29, 39, 47, 77, 107, 109, 126, 168, 176], "maximum": [6, 176], "valu": [6, 7, 8, 9, 11, 25, 26, 28, 35, 43, 44, 46, 60, 71, 72, 73, 85, 86, 91, 98, 100, 101, 103, 106, 121, 125, 131, 133, 150, 158, 172, 173, 176, 177, 178], "normal": [6, 70], "data": [6, 10, 11, 25, 28, 29, 38, 39, 45, 46, 47, 57, 64, 70, 71, 72, 76, 77, 79, 85, 86, 100, 106, 107, 108, 109, 121, 125, 160, 168, 170], "rang": [6, 26, 65, 71, 99, 101, 125, 176, 177, 178], "quantiz": [6, 7, 8, 9, 19, 25, 28, 29, 35, 36, 38, 39, 45, 47, 51, 56, 64, 70, 76, 77, 79, 83, 85, 86, 88, 89, 91, 92, 93, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 114, 115, 117, 125, 136, 163, 164, 167, 168, 169, 175, 176, 177, 178, 184], "A": [6, 7, 8, 9, 11, 20, 25, 28, 29, 35, 36, 39, 44, 46, 47, 51, 56, 57, 64, 65, 70, 71, 72, 76, 77, 79, 85, 89, 91, 98, 100, 101, 103, 106, 107, 108, 109, 115, 117, 121, 122, 125, 133, 143, 145, 147, 149, 150, 154, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 174, 177, 178, 180, 181, 185], "we": [6, 185], "want": [6, 185], "repres": [6, 7, 11, 43, 44, 56, 76, 86, 88, 91, 92, 106, 114, 145, 149, 150, 165, 174, 180, 184], "version": [6, 43, 45, 106, 121, 126, 145, 147, 173, 185], "output": [6, 19, 20, 25, 26, 35, 36, 38, 44, 46, 56, 57, 64, 65, 70, 71, 73, 76, 79, 85, 86, 88, 89, 98, 99, 100, 101, 103, 104, 106, 108, 114, 115, 121, 122, 133, 145, 160, 162, 174, 185], "us": [6, 7, 8, 9, 10, 11, 19, 20, 25, 26, 28, 29, 35, 36, 38, 39, 43, 44, 45, 46, 47, 51, 56, 57, 60, 64, 65, 70, 71, 72, 76, 77, 79, 85, 86, 88, 89, 91, 92, 98, 99, 101, 103, 104, 106, 107, 108, 109, 114, 115, 121, 125, 131, 132, 138, 143, 145, 154, 158, 160, 161, 162, 163, 164, 166, 167, 168, 169, 170, 176, 177, 178, 181, 182, 184, 185], "64": [6, 85], "store": [6, 11, 19, 43, 57, 65, 70, 71, 73, 85, 107, 108, 165, 173, 174], "each": [6, 7, 11, 29, 39, 43, 44, 45, 46, 47, 77, 85, 91, 107, 109, 121, 140, 150, 164, 167, 168, 173, 174, 177, 178], "hold": [6, 91, 106], "sixteen": 6, "i": [6, 7, 8, 9, 10, 11, 19, 20, 25, 26, 28, 29, 36, 38, 39, 43, 44, 45, 46, 47, 51, 56, 57, 64, 65, 70, 71, 72, 73, 76, 77, 79, 85, 86, 88, 89, 91, 92, 98, 99, 100, 101, 104, 106, 107, 108, 109, 114, 115, 117, 121, 122, 125, 126, 127, 132, 133, 136, 143, 145, 147, 150, 154, 156, 157, 158, 160, 161, 163, 165, 166, 167, 168, 169, 170, 172, 173, 174, 176, 177, 178, 180, 181, 182, 184, 185], "assum": [6, 71, 145, 150], "flat": 6, "1d": 6, "also": [6, 25, 29, 36, 39, 47, 57, 64, 70, 71, 77, 107, 109, 121, 145, 163, 168, 169, 184, 185], "design": [6, 8, 9, 11, 28, 29, 39, 43, 44, 46, 47, 70, 72, 76, 77, 89, 98, 100, 101, 104, 106, 108, 109, 115, 121, 125, 154, 160, 180], "execut": [6, 70, 85, 88, 106, 114, 121, 133, 145, 181], "enabl": [6, 20, 71, 85, 86, 88, 106, 114], "devic": [6, 10, 28, 38, 56, 64, 70, 76, 79, 85, 86, 88, 89, 98, 100, 108, 114, 115], "util": [6, 17, 19, 20, 25, 35, 36, 43, 45, 56, 60, 64, 70, 73, 79, 85, 88, 98, 103, 106, 114, 117, 184], "custom": [6, 20, 26, 29, 36, 39, 43, 44, 45, 46, 47, 57, 65, 71, 73, 77, 85, 86, 89, 99, 100, 101, 107, 109, 115, 125, 164, 185], "kernel": [6, 10, 20, 26, 28, 35, 36, 38, 60, 64, 65, 70, 71, 85, 88, 89, 104, 106, 114], "alloc": [6, 28, 38, 64, 70, 76, 100, 106, 173], "temporari": 6, "gpu": [6, 11, 36, 60, 64, 70, 88, 185], "intermedi": 6, "comput": [6, 10, 11, 19, 20, 25, 26, 28, 29, 35, 36, 38, 39, 43, 44, 47, 56, 57, 60, 64, 65, 70, 72, 73, 76, 77, 85, 86, 88, 89, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 114, 115, 121, 125, 131, 168, 184], "which": [6, 19, 25, 28, 38, 43, 44, 45, 46, 47, 51, 56, 64, 70, 76, 79, 86, 98, 99, 100, 104, 106, 108, 122, 131, 132, 137, 138, 139, 140, 145, 160, 163, 164, 167, 173, 185], "freed": 6, "befor": [6, 7, 25, 28, 35, 38, 46, 64, 70, 76, 85, 88, 98, 100, 103, 106, 108, 114, 160, 167, 170], "is_transpos": [7, 8, 9], "bool": [7, 8, 9, 19, 25, 26, 28, 29, 35, 36, 38, 39, 43, 44, 46, 47, 51, 56, 64, 65, 70, 71, 76, 77, 79, 85, 86, 89, 98, 99, 101, 103, 104, 106, 107, 108, 109, 115, 117, 125, 132, 133, 149, 150, 152, 158, 163, 164, 169, 176, 181], "fals": [7, 8, 9, 19, 25, 28, 35, 38, 51, 56, 64, 70, 76, 79, 98, 103, 106, 107, 108, 117, 128, 132, 133, 150, 158, 163, 169, 176, 181, 182, 185], "pack": [7, 8, 9, 10, 25, 45, 46, 64, 70, 76, 79, 92, 106, 108, 162, 163, 164, 169], "format": [7, 8, 9, 11, 25, 43, 64, 70, 76, 88, 92, 93, 103, 106, 114, 160, 162, 169, 175], "acceler": [7, 25, 36, 60, 64, 70, 73, 88, 103, 114, 185], "option": [7, 8, 9, 29, 35, 36, 38, 39, 43, 45, 47, 56, 60, 64, 70, 71, 72, 76, 77, 79, 85, 86, 98, 100, 107, 109, 121, 125, 136, 163, 167, 168, 169, 176, 181, 184, 185], "transpos": [7, 8, 9], "storag": [7, 103, 164, 169], "requir": [7, 19, 29, 39, 43, 44, 45, 46, 47, 60, 65, 77, 85, 88, 89, 91, 101, 104, 106, 107, 109, 114, 115, 126, 140, 160, 165, 166, 170, 185], "onli": [7, 44, 46, 47, 70, 76, 79, 98, 103, 106, 108, 115, 163, 164, 169, 180, 185], "particularli": [7, 25, 29, 39, 47, 64, 70, 77, 89, 109, 115, 121, 125, 161, 163, 166, 167, 181], "neural": [7, 64, 70, 72, 98, 125, 184], "network": [7, 64, 70, 72, 85, 98, 125, 140, 184], "weight": [7, 19, 20, 25, 26, 28, 29, 35, 36, 38, 39, 43, 44, 45, 46, 47, 51, 56, 57, 60, 64, 65, 70, 71, 76, 77, 79, 85, 86, 88, 89, 91, 92, 93, 98, 99, 103, 104, 106, 107, 108, 109, 114, 115, 121, 125, 136, 162, 163, 164, 165, 168, 169, 175], "other": [7, 29, 39, 47, 57, 71, 77, 89, 103, 106, 107, 108, 109, 115, 143, 154, 164, 168, 180], "scenario": [7, 11, 43, 89, 92, 115], "where": [7, 11, 19, 28, 46, 60, 71, 72, 73, 76, 89, 91, 98, 100, 104, 115, 121, 149, 150, 154, 156, 157, 161, 166, 169, 173, 174, 181, 184, 185], "precis": [7, 11, 25, 36, 64, 70, 85, 88, 89, 98, 100, 101, 106, 114, 115], "can": [7, 10, 19, 20, 25, 29, 35, 39, 44, 45, 46, 47, 51, 56, 57, 60, 64, 70, 71, 72, 76, 77, 85, 86, 88, 98, 103, 106, 107, 109, 114, 117, 121, 122, 132, 140, 163, 168, 169, 182, 184, 185], "trade": [7, 85], "effici": [7, 10, 11, 19, 20, 25, 28, 29, 35, 36, 38, 39, 43, 47, 57, 60, 64, 65, 70, 71, 73, 76, 77, 79, 85, 89, 98, 101, 103, 104, 106, 108, 109, 114, 115, 121, 125, 127, 164, 169, 184], "without": [7, 76, 79, 92, 93, 101, 103, 106, 181, 184, 185], "significantli": [7, 60, 70, 98], "affect": [7, 60, 79, 106], "applic": [7, 85, 181, 185], "": [7, 8, 9, 10, 19, 20, 25, 28, 36, 51, 64, 70, 71, 76, 79, 85, 86, 98, 103, 106, 108, 133, 154, 156, 157, 163, 169], "perform": [7, 10, 11, 20, 25, 26, 35, 36, 43, 44, 46, 47, 56, 57, 60, 65, 70, 71, 73, 79, 85, 86, 88, 89, 98, 99, 100, 101, 103, 104, 106, 114, 115, 125, 160, 164, 170, 172, 176], "actual": [7, 70, 85, 88, 98, 106, 114, 160, 164, 181], "make": 7, "suitabl": [7, 8, 9, 60, 64, 65], "larg": [7, 29, 39, 47, 77, 106, 107, 109, 168, 184], "torch": [7, 8, 9, 10, 11, 17, 19, 25, 26, 28, 29, 35, 36, 38, 39, 44, 45, 46, 47, 56, 57, 64, 65, 70, 71, 72, 73, 76, 77, 79, 85, 86, 88, 89, 91, 92, 93, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 114, 115, 121, 125, 138, 160, 161, 162, 164, 165, 166, 167, 168, 169, 170, 175, 176, 177, 178, 182, 185], "should": [7, 8, 9, 28, 29, 35, 38, 39, 43, 44, 47, 57, 64, 71, 76, 77, 85, 86, 88, 98, 106, 108, 109, 114, 122, 140, 163, 164, 169, 176, 177, 178, 185], "compat": [7, 57, 71, 76, 85, 88, 98, 103, 114], "int32": [7, 8, 9], "If": [7, 8, 9, 10, 19, 25, 26, 28, 35, 38, 51, 56, 64, 70, 72, 76, 79, 85, 92, 93, 98, 100, 103, 107, 108, 121, 125, 126, 133, 145, 150, 156, 164, 167, 176, 181, 182], "true": [7, 19, 25, 28, 29, 35, 38, 39, 47, 51, 56, 64, 70, 76, 77, 79, 85, 98, 103, 106, 107, 108, 109, 117, 125, 132, 133, 150, 158, 163, 164, 169, 176, 181, 182], "need": [7, 11, 20, 86, 106, 125, 136, 154, 161, 182, 184, 185], "specif": [7, 19, 20, 25, 29, 38, 39, 43, 46, 47, 60, 64, 70, 77, 79, 86, 88, 89, 98, 99, 100, 103, 106, 107, 108, 109, 114, 115, 117, 125, 132, 133, 143, 160, 167, 168, 172, 174, 181, 184], "orient": 7, "subsequ": [7, 65, 70], "oper": [7, 10, 11, 19, 20, 23, 25, 26, 28, 29, 35, 36, 39, 43, 44, 46, 47, 60, 62, 64, 65, 70, 71, 72, 73, 76, 77, 79, 83, 86, 88, 89, 99, 101, 104, 106, 107, 108, 109, 114, 115, 121, 143, 160, 161, 166, 167, 168, 170, 172, 173, 180, 184], "have": [7, 8, 9, 88, 91, 100, 106, 114, 167, 182], "dtype": [7, 8, 9, 28, 29, 38, 39, 45, 47, 64, 70, 71, 72, 76, 77, 100, 106, 107, 108, 109, 121, 125, 138, 168], "int8": [7, 8, 9, 10, 25, 64, 65, 70, 71, 103, 162], "potenti": [7, 60, 79, 106, 143, 149, 150, 169], "half": [7, 10, 106], "element": [7, 20, 26, 28, 36, 38, 46, 85, 106, 160, 166, 173, 174, 177, 178], "last": [7, 160, 166], "dimens": [7, 19, 20, 46, 60, 64, 70, 72, 76, 79, 91, 98, 100, 103, 108, 121, 122, 160, 161, 165, 166, 173], "transposit": [7, 8, 9], "chang": [7, 43, 44, 86, 184], "shape": [7, 11, 19, 25, 35, 43, 46, 70, 71, 88, 98, 103, 114, 121, 160, 161, 170, 176], "adjust": [7, 25, 29, 39, 47, 77, 79, 86, 99, 100, 103, 106, 107, 109, 143, 147, 160, 167, 168, 176, 177, 178], "accordingli": [7, 143], "scale": [8, 11, 25, 26, 35, 36, 45, 46, 64, 65, 70, 71, 85, 86, 88, 89, 98, 99, 100, 103, 104, 106, 107, 114, 115, 128, 162, 176, 177, 178, 184], "unpack": [8, 9, 11, 46, 106, 163, 169], "ha": [8, 9, 29, 39, 47, 70, 77, 106, 107, 109, 168, 176, 184], "been": [8, 9, 29, 39, 47, 70, 77, 106, 107, 109, 168, 184], "previous": [8, 9, 70, 85], "its": [8, 9, 51, 71, 91, 125, 160, 165, 166, 167], "origin": [8, 9, 11, 19, 25, 28, 38, 45, 46, 56, 64, 70, 79, 98, 127, 160, 161, 162, 169, 170, 172, 184], "work": [8, 9, 11, 44, 45, 46, 98, 101, 121, 185], "from": [8, 9, 19, 20, 25, 26, 28, 35, 36, 43, 44, 45, 51, 56, 64, 65, 70, 71, 73, 76, 79, 85, 88, 89, 93, 98, 99, 101, 103, 104, 106, 107, 114, 115, 121, 125, 127, 133, 160, 162, 163, 167, 172, 175, 176, 184, 185], "standard": [8, 9, 43, 47, 65, 86, 107, 125], "down": [8, 9], "two": [8, 9, 57, 71, 100, 106, 158, 160, 161, 166], "singl": [8, 9, 125, 172], "revers": [8, 9, 170], "reconstruct": [8, 9, 85, 93, 170, 175], "new": [8, 9, 25, 28, 38, 56, 64, 70, 76, 106, 108, 138, 172], "It": [8, 9, 10, 11, 19, 25, 28, 29, 35, 36, 39, 43, 45, 46, 47, 51, 57, 64, 70, 71, 72, 73, 76, 77, 79, 85, 86, 88, 89, 91, 98, 101, 103, 106, 107, 108, 109, 114, 115, 121, 125, 140, 143, 147, 150, 157, 158, 162, 165, 168, 173, 177, 178, 180, 182, 184], "must": [8, 9, 10, 25, 28, 35, 38, 43, 44, 45, 57, 64, 70, 71, 76, 79, 88, 98, 103, 108, 114, 121, 158], "multipli": 8, "indic": [8, 9, 26, 28, 29, 36, 39, 43, 44, 45, 46, 47, 51, 64, 65, 71, 76, 77, 79, 85, 86, 89, 91, 99, 101, 104, 106, 107, 108, 109, 117, 131, 132, 149, 150, 158, 163, 164, 168, 169, 176, 181], "whether": [8, 9, 28, 29, 39, 46, 47, 51, 71, 77, 85, 86, 104, 106, 107, 109, 117, 125, 149, 150, 163, 164, 168, 169, 181], "default": [8, 9, 19, 28, 29, 38, 39, 47, 64, 70, 72, 76, 77, 79, 85, 100, 103, 106, 107, 108, 109, 121, 125, 136, 143, 145, 156, 163, 164, 167, 169, 176, 181, 185], "mean": [8, 9, 72, 98, 100, 106, 108, 163], "occur": [8, 9, 145], "depend": [8, 9, 150, 154, 169, 182], "implement": [8, 9, 11, 19, 20, 25, 26, 28, 29, 35, 36, 38, 39, 43, 44, 47, 51, 56, 60, 64, 65, 71, 73, 76, 77, 85, 86, 88, 92, 98, 99, 101, 103, 104, 106, 107, 108, 109, 114, 115, 117, 121, 125, 127, 167, 168, 173, 181], "q4_unpack": [8, 9], "functions_cuda": [8, 9], "typic": [8, 9, 28, 43, 44, 70, 106, 121, 157, 173], "further": [8, 9, 11, 70, 106, 143, 163], "analysi": [8, 9, 11], "rais": [8, 9, 29, 39, 47, 77, 79, 88, 92, 93, 100, 106, 107, 109, 114, 121, 125, 126, 133, 168, 176, 180, 181], "assertionerror": [8, 9, 79, 100], "assert": [8, 9, 88, 114], "error": [8, 9, 10, 43, 44, 86, 88, 106, 114, 121, 125, 133, 145, 180], "ensur": [8, 9, 10, 20, 25, 28, 35, 38, 46, 64, 65, 70, 72, 76, 85, 88, 98, 99, 103, 106, 108, 114, 117, 121, 125, 143, 164, 166, 167, 177, 178, 180, 184], "appli": [8, 9, 11, 29, 39, 43, 44, 46, 47, 56, 57, 64, 65, 70, 72, 77, 79, 85, 98, 99, 103, 107, 109, 125, 160, 161, 163, 168, 177, 178], "correctli": [8, 9, 85, 88, 106, 114, 167], "given": [10, 19, 43, 51, 56, 64, 70, 79, 88, 91, 114, 117, 125, 132, 136, 137, 138, 139, 140, 163, 164, 167, 172, 176], "unsign": [10, 11, 176], "variou": [10, 76, 106, 156, 157], "float32": [10, 28, 38, 45, 72, 76, 100, 108, 121, 125], "bfloat16": [10, 138], "correct": [10, 29, 39, 46, 47, 77, 106, 107, 109, 125, 168, 185], "emploi": [10, 43, 44, 184], "guard": 10, "base": [10, 11, 19, 23, 25, 28, 29, 35, 36, 38, 39, 43, 44, 47, 51, 56, 60, 64, 65, 70, 71, 72, 76, 77, 79, 85, 86, 91, 98, 99, 100, 101, 104, 106, 107, 108, 109, 117, 125, 133, 143, 147, 149, 164, 168, 169, 173, 174, 176], "support": [10, 25, 29, 35, 39, 43, 44, 45, 46, 47, 51, 56, 60, 64, 65, 70, 71, 76, 77, 79, 85, 86, 88, 89, 93, 98, 99, 106, 108, 109, 114, 115, 125, 132, 143, 154, 164, 176, 184, 185], "termin": 10, "program": [10, 181], "messag": [10, 51, 117, 125, 181], "provid": [11, 35, 38, 46, 51, 56, 71, 76, 99, 106, 108, 117, 133, 149, 162, 163, 164, 167, 181, 185], "python": [11, 156, 157, 173, 181, 185], "interfac": 11, "backend": [11, 20, 57], "them": [11, 103], "higher": 11, "compact": 11, "expand": 11, "batch_siz": [11, 46, 121, 161, 170], "sequence_length": [11, 121], "packed_embedding_dimens": 11, "embed": [11, 43, 44, 45, 46, 47, 165, 167], "1": [11, 28, 38, 43, 57, 71, 79, 101, 106, 107, 128, 149, 156, 165, 172, 174, 185], "sequenc": [11, 161, 170], "batch": [11, 19, 57, 70, 88, 98, 103, 114], "These": [11, 154, 160], "ar": [11, 19, 25, 26, 28, 35, 38, 43, 44, 45, 46, 47, 51, 57, 60, 64, 70, 71, 72, 73, 76, 79, 88, 89, 93, 98, 99, 101, 103, 104, 106, 107, 108, 114, 115, 117, 121, 125, 136, 140, 143, 154, 157, 158, 163, 164, 166, 167, 173, 176, 180, 181, 184, 185], "0": [11, 28, 29, 38, 39, 47, 64, 70, 76, 77, 103, 107, 109, 125, 127, 128, 145, 168, 172, 173, 174, 185], "directli": [11, 43, 44, 57, 71, 99, 101, 125, 135, 137, 138, 139, 140, 149, 184], "offer": [11, 60, 72, 106], "signific": [11, 25, 64, 70, 172, 184], "speedup": [11, 169], "compar": [11, 184], "cpu": [11, 56, 131, 132, 133, 143], "function": [16, 19, 20, 22, 25, 29, 32, 35, 36, 39, 44, 45, 46, 47, 49, 51, 53, 56, 57, 61, 64, 65, 67, 70, 71, 72, 73, 77, 79, 82, 85, 86, 88, 89, 90, 91, 92, 95, 98, 99, 101, 103, 104, 106, 107, 109, 111, 114, 115, 117, 124, 130, 132, 134, 136, 140, 141, 143, 144, 145, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 173, 174, 176, 177, 178, 179, 181, 184], "retriev": [17, 46, 54, 57, 71, 73, 133], "c": [17, 19, 20, 35, 54, 56, 57, 127, 147, 154, 173, 174, 185], "convolut": [17, 19, 20, 23, 25, 26, 28, 35, 36, 38, 76, 164, 167], "code": [17, 143, 185], "cpp_extens": [17, 184], "cppextens": [17, 154], "class": [18, 19, 20, 24, 25, 26, 27, 28, 29, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 50, 51, 55, 56, 57, 59, 60, 63, 64, 65, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 84, 85, 86, 87, 88, 89, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 113, 114, 115, 116, 117, 120, 121, 122, 124, 125, 127, 128, 130, 131, 133, 140, 162, 164, 167, 179, 180], "arg": [19, 20, 25, 26, 35, 36, 43, 44, 45, 46, 51, 57, 64, 65, 70, 71, 72, 73, 85, 86, 88, 89, 98, 99, 100, 101, 103, 104, 114, 115, 117, 121, 136, 160], "kwarg": [19, 20, 25, 26, 35, 36, 43, 44, 45, 46, 51, 57, 64, 65, 70, 71, 72, 73, 85, 86, 88, 89, 98, 99, 100, 101, 103, 104, 114, 115, 117, 121], "pytorch": [19, 20, 26, 36, 43, 44, 47, 72, 100, 126, 165, 166, 169, 176, 184, 185], "optim": [19, 28, 29, 35, 38, 39, 43, 44, 45, 46, 47, 60, 64, 65, 70, 73, 76, 77, 79, 85, 86, 88, 89, 106, 107, 108, 109, 114, 115, 122, 143, 168, 169, 184], "extens": [19, 70, 154, 169, 180, 181, 184], "inherit": [19, 25, 51, 56, 79, 88, 98, 103, 114], "binaryconv2dbas": [19, 25], "leverag": [19, 25, 51, 60, 64, 70, 104, 125], "common": [19, 56, 88, 106, 114, 117], "ad": [19, 20, 26, 28, 36, 38, 122, 125, 160, 165, 166], "bits_binary_word": [19, 25, 64, 70, 76], "defin": [19, 20, 25, 26, 29, 35, 39, 47, 56, 57, 64, 70, 71, 77, 85, 92, 98, 101, 103, 106, 107, 109, 117, 168, 177, 178, 181], "size": [19, 20, 28, 29, 35, 36, 38, 39, 43, 45, 47, 57, 70, 77, 85, 86, 88, 91, 98, 103, 106, 107, 109, 114, 115, 121, 136, 162, 166, 168, 169, 173, 174, 184], "word": [19, 64, 70, 76, 173, 174], "int": [19, 20, 26, 28, 36, 38, 43, 45, 46, 56, 57, 64, 70, 71, 76, 79, 85, 86, 88, 89, 91, 106, 107, 108, 114, 115, 121, 122, 160, 166, 172, 173, 174, 176, 185], "method": [19, 20, 25, 26, 28, 29, 35, 36, 38, 39, 43, 44, 45, 46, 47, 51, 56, 57, 64, 65, 70, 71, 72, 73, 76, 77, 79, 85, 86, 88, 89, 92, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 114, 115, 117, 121, 122, 125, 128, 133, 164, 167, 168, 172, 176, 180], "attribut": [19, 20, 25, 26, 28, 29, 35, 36, 38, 39, 43, 44, 45, 46, 47, 56, 57, 60, 64, 65, 70, 71, 72, 73, 76, 77, 79, 85, 86, 88, 89, 92, 93, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 114, 115, 121, 122, 125, 131, 180], "__init__": [19, 25, 28, 35, 38, 43, 45, 56, 64, 70, 72, 76, 79, 85, 88, 98, 100, 103, 106, 107, 108, 114, 121, 122, 125, 128, 180], "initi": [19, 25, 28, 29, 35, 38, 39, 43, 45, 47, 56, 64, 70, 72, 76, 77, 79, 85, 88, 98, 100, 103, 106, 108, 109, 114, 121, 122, 125, 162, 167, 174, 180, 185], "argument": [19, 25, 26, 35, 44, 57, 64, 71, 72, 85, 88, 89, 100, 114, 115, 121, 143, 147], "forward": [19, 20, 25, 26, 35, 36, 38, 43, 44, 45, 46, 56, 57, 64, 65, 70, 71, 72, 73, 76, 79, 85, 86, 88, 89, 98, 99, 100, 101, 103, 104, 106, 114, 115, 121, 122], "addition": [19, 70, 86, 147], "set": [19, 25, 28, 38, 57, 64, 70, 71, 72, 76, 79, 85, 88, 98, 100, 103, 106, 108, 114, 121, 132, 136, 143, 147, 154, 163, 167, 172, 173, 174, 180, 182, 185], "up": [19, 28, 57, 71, 79, 88, 98, 103, 106, 114, 121, 154, 166, 167, 185], "variabl": [19, 25, 26, 35, 64, 85, 86, 99, 100, 104, 121, 150, 156, 157, 172, 182, 185], "length": [19, 25, 35, 64, 85, 100, 121, 174], "list": [19, 25, 35, 64, 85, 86, 100, 107, 121, 135, 137, 138, 139, 140, 143, 150, 154, 157, 160, 161, 164, 167, 170], "pass": [19, 20, 25, 26, 29, 35, 36, 38, 39, 44, 45, 46, 47, 56, 57, 64, 65, 70, 71, 72, 73, 76, 77, 79, 85, 86, 88, 89, 98, 99, 100, 101, 103, 104, 106, 109, 114, 115, 121, 122, 143], "arbitrari": [19, 20, 25, 35, 57, 64, 71, 85, 100, 121], "keyword": [19, 25, 35, 64, 85, 88, 100, 114, 121, 143, 147], "x": [19, 25, 26, 28, 35, 36, 38, 56, 64, 70, 72, 73, 76, 79, 85, 86, 88, 89, 98, 99, 100, 101, 103, 104, 108, 114, 115, 122, 161, 170, 173, 185], "n": [19, 20, 25, 35, 38, 39, 57, 79, 108, 109, 125, 164, 167, 173], "c_in": [19, 25], "h": [19, 25, 35, 149, 156], "w": [19, 25, 35], "channel": [19, 20, 28, 38, 122], "height": 19, "width": [19, 38, 64, 70, 79, 85, 88, 89, 106, 107, 108, 114, 115], "determin": [19, 29, 39, 43, 44, 47, 51, 70, 77, 107, 109, 117, 132, 133, 145, 150, 157, 158, 168, 173, 174], "generate_quantized_weight": [19, 25, 28, 35, 38, 56, 64, 70, 76, 79, 98, 103, 106, 108, 164], "qweight_onli": [19, 25, 28, 35, 38, 56, 64, 70, 76, 79, 98, 103, 106, 108, 163, 164, 169], "none": [19, 25, 26, 28, 29, 35, 36, 38, 39, 43, 44, 45, 46, 47, 51, 56, 57, 64, 65, 70, 71, 72, 76, 77, 79, 85, 86, 88, 89, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 114, 115, 121, 125, 135, 136, 138, 156, 157, 158, 163, 164, 167, 168, 169, 176, 177, 178, 180, 185], "current": [19, 28, 29, 38, 39, 44, 45, 47, 57, 64, 71, 76, 77, 79, 92, 106, 107, 108, 109, 115, 117, 126, 133, 136, 157, 165, 168, 185], "nn": [19, 25, 28, 29, 35, 38, 39, 43, 45, 47, 64, 70, 72, 76, 77, 88, 98, 100, 103, 107, 108, 109, 114, 121, 122, 125, 162, 167, 168, 169], "gradient": [19, 20, 26, 29, 36, 39, 43, 44, 46, 47, 65, 71, 73, 76, 77, 86, 89, 99, 101, 104, 106, 107, 109, 115, 125, 127, 168, 185], "discard": [19, 25, 28, 38, 64, 70, 98], "save": [19, 25, 26, 28, 35, 36, 38, 44, 46, 56, 57, 64, 65, 70, 71, 73, 86, 89, 98, 99, 101, 104, 106, 115, 164, 169, 185], "prepare_param": [19, 25, 28, 35, 38, 45, 56, 64, 70, 76, 79, 85, 88, 98, 103, 106, 108, 114, 167], "prepar": [19, 25, 28, 35, 38, 45, 56, 64, 70, 76, 79, 85, 88, 98, 103, 106, 108, 114, 162, 164, 166, 167, 185], "model": [19, 25, 28, 29, 35, 36, 38, 39, 43, 44, 45, 47, 56, 60, 64, 65, 70, 76, 77, 85, 91, 98, 99, 101, 103, 106, 107, 108, 109, 121, 125, 133, 135, 143, 161, 163, 164, 167, 168, 169, 184], "train": [19, 25, 26, 28, 35, 36, 38, 43, 44, 45, 46, 47, 56, 64, 65, 70, 71, 76, 86, 89, 98, 99, 101, 103, 104, 106, 108, 115, 122, 125, 127, 162, 163, 164, 167, 169, 184, 185], "One": [19, 25, 35, 45, 56, 64, 70, 85, 88, 98, 103, 106, 114], "prepare_bie_lay": [19, 25, 35, 45, 56, 64, 70, 85, 88, 98, 103, 106, 114], "project_root": [19, 25, 35, 45, 56, 64, 70, 85, 88, 98, 103, 106, 114], "model_help": [19, 25, 35, 45, 56, 64, 70, 85, 88, 98, 103, 106, 114, 184], "call": [19, 25, 28, 35, 38, 45, 56, 64, 70, 76, 79, 85, 88, 98, 103, 106, 108, 114, 125, 135, 137, 138, 139, 140, 158, 164, 167], "autograd": [20, 36, 44, 46, 57, 65, 71, 73, 86, 89, 101, 115], "2d": [20, 161, 170], "static": [20, 26, 29, 36, 39, 44, 46, 47, 57, 64, 65, 71, 73, 77, 85, 86, 89, 99, 101, 104, 107, 109, 115, 133], "carri": 20, "out": [20, 43, 121, 125, 132, 143], "activ": [20, 25, 35, 38, 47, 64, 65, 70, 71, 79, 88, 89, 98, 99, 100, 103, 104, 106, 108, 114, 115, 185], "No": 20, "level": [20, 60, 85], "ctx": [20, 26, 36, 44, 46, 57, 65, 71, 73, 86, 89, 99, 101, 104, 115], "m": [20, 57], "k": [20, 57, 160, 173], "kernel_s": [20, 26, 28, 36, 38], "stride": [20, 26, 28, 36, 38], "pad": [20, 26, 28, 36, 38, 43, 45, 73, 160, 165, 166], "dilat": [20, 26, 28, 36, 38], "output_edg": 20, "binary_conv_cpp": 20, "automat": [20, 60, 154], "integr": [20, 26, 71, 72, 184], "mechan": [20, 36, 43, 44, 108, 121, 181], "context": [20, 26, 36, 44, 46, 47, 57, 65, 71, 73, 86, 89, 98, 99, 101, 104, 115], "object": [20, 26, 33, 36, 46, 51, 57, 64, 65, 71, 73, 79, 89, 92, 93, 99, 101, 104, 115, 117, 140, 175, 181], "stash": [20, 26], "inform": [20, 26, 36, 57, 65, 73, 85, 86, 89, 91, 93, 107, 115, 132, 133, 175, 181, 184, 185], "backward": [20, 26, 29, 36, 39, 44, 46, 47, 57, 65, 71, 73, 77, 86, 89, 99, 101, 104, 109, 115], "you": [20, 57, 71, 161, 172, 182, 184, 185], "cach": 20, "save_for_backward": [20, 57, 71], "featur": [20, 56, 57, 64, 70, 76, 79, 88, 98, 103, 106, 108, 114, 117, 132, 143], "map": [20, 85, 86, 91, 107, 133], "spatial": 20, "conv": [20, 29, 39], "zero": [20, 28, 35, 43, 45, 46, 85, 86, 88, 89, 98, 99, 100, 101, 103, 104, 106, 107, 114, 115, 122, 166, 177, 178], "both": [20, 28, 35, 36, 43, 44, 45, 51, 64, 70, 71, 76, 86, 89, 98, 99, 100, 101, 104, 108, 115, 147, 158, 163, 167, 176], "side": [20, 26, 28, 36, 38], "space": [20, 26, 28, 36, 38, 106], "between": [20, 26, 28, 36, 38, 46, 85, 98, 143, 176, 184], "edg": [20, 89, 98, 115, 184], "match": [20, 103, 122, 164, 167], "expect": [20, 29, 39, 45, 46, 47, 65, 71, 77, 85, 91, 107, 109, 125, 149, 161, 168], "result": [20, 36, 43, 44, 45, 46, 65, 72, 73, 85, 88, 89, 100, 101, 114, 115, 160, 173, 177, 178], "part": [20, 47, 85], "pair": [20, 91], "correspond": [20, 79, 133, 173, 174, 177, 178, 185], "obtain": 23, "cuda": [23, 33, 68, 96, 147, 184], "necessari": [23, 26, 28, 45, 46, 85, 93, 98, 106, 108, 117, 154, 166, 167, 175], "special": [25, 29, 35, 39, 43, 44, 46, 47, 51, 64, 70, 73, 77, 85, 106, 109, 176, 184], "librari": [25, 71, 98, 114, 132, 143, 147, 150, 154, 156, 157, 158, 182, 184, 185], "add": [25, 70, 98, 103, 122, 143], "possibli": [25, 85], "uint8_t": 25, "bias_a": [25, 35, 64, 70, 98, 103], "bia": [25, 29, 35, 39, 47, 64, 65, 70, 77, 79, 88, 98, 103, 106, 107, 109, 114, 117, 122, 125, 168], "scale_a": [25, 26, 35, 36, 64, 65, 70, 71, 98, 99, 103, 104, 177, 178], "scale_w": [25, 26, 35, 36, 45, 64, 65, 70, 71, 98, 99, 103, 104], "addit": [25, 73, 88, 106, 107, 114, 143, 160, 184], "param": [25, 125, 136, 137, 138, 139], "init_weight": [25, 45, 64, 70], "achiev": [25, 64, 70, 162], "reduct": [25, 43, 64, 70, 162], "usag": [25, 29, 39, 47, 57, 64, 70, 71, 77, 85, 86, 98, 109], "essenti": [25, 46, 64, 70, 93, 167], "maintain": [25, 35, 64, 70, 71, 100, 101, 103, 108, 184], "numer": [25, 29, 39, 47, 64, 70, 77, 103, 107, 109, 125, 168, 173], "fidel": [25, 64, 70], "lower": [25, 64, 70, 106, 177, 178], "benefici": [25, 64, 70], "infer": [25, 35, 64, 70, 76, 79, 85, 86, 88, 104, 106, 108, 114, 162, 163, 167, 169, 184], "hardwar": [25, 60, 64, 70, 73, 76, 85, 88, 98, 103, 106, 114], "arithmet": [25, 43, 44, 64, 70, 98, 101], "after": [25, 28, 35, 38, 43, 44, 45, 46, 56, 57, 64, 70, 71, 76, 79, 86, 98, 99, 103, 106, 108, 122, 165, 170, 185], "start": [25, 28, 35, 38, 64, 70, 76, 91, 98, 103, 108, 172], "properli": [25, 28, 35, 38, 64, 70, 76, 98, 103, 108, 121, 164], "set_activ": [25, 35, 64, 70, 98, 103], "set_weight_data": [25, 28, 38, 64, 70, 76, 79, 108], "re": [25, 173, 182], "pre": [25, 98, 162, 173], "avail": [25, 38, 60, 70, 89, 115, 158, 162, 167, 181], "includ": [26, 43, 45, 65, 72, 76, 79, 85, 106, 117, 125, 140, 143, 147, 149, 150, 154, 156, 158, 160, 167, 169, 185], "dure": [26, 45, 46, 47, 57, 60, 70, 71, 76, 85, 88, 99, 101, 106, 108, 114, 122, 145, 160, 180, 181, 185], "backwardcfunct": [26, 36, 44, 46, 65, 71, 73, 86, 89, 99, 101, 104, 115], "output_gradi": [26, 36, 44, 46, 65, 71, 73, 86, 89, 99, 101, 104, 115], "tupl": [26, 36, 44, 46, 51, 57, 65, 71, 73, 86, 89, 99, 101, 104, 115, 117, 121, 125, 145, 149, 150, 161, 162, 176], "loss": [26, 29, 36, 39, 44, 46, 47, 65, 71, 73, 77, 89, 99, 101, 104, 106, 107, 109, 115, 125, 168, 184], "respect": [26, 36, 44, 46, 65, 71, 73, 86, 89, 99, 100, 101, 104, 115, 147], "non": [26, 36, 46, 85, 173, 174], "is_train": [26, 36, 44, 46, 65, 71, 86, 89, 99, 101, 104, 115], "filter": 26, "flag": [26, 29, 36, 39, 44, 46, 47, 71, 77, 85, 86, 89, 99, 101, 104, 106, 107, 109, 115, 132, 143, 147, 163, 164, 169, 176, 181], "all": [26, 38, 57, 71, 93, 106, 135, 137, 138, 139, 140, 164, 167, 175, 184, 185], "four": 26, "in_channel": [28, 38, 106, 108], "out_channel": [28, 38, 106, 108], "symmetr": [28, 64, 70, 76, 106, 115], "serv": [28, 106, 180], "configur": [28, 51, 64, 70, 76, 79, 85, 106, 117, 143, 154, 185], "imag": [28, 185], "produc": [28, 108], "convolv": 28, "desir": [28, 38, 60, 100, 135, 169], "logic": [28, 38, 43, 44, 85, 173, 174], "form": [28, 181], "abstract": [28, 117], "subclass": [28, 38, 57, 71, 106, 108, 117], "properti": [28, 38, 64, 70, 76, 79, 108], "opt_weight": [28, 38, 76, 79, 108], "check": [28, 51, 98, 106, 117, 125, 126, 132, 133, 143, 145, 149, 150, 156, 158, 164, 185], "mode": [28, 36, 38, 46, 56, 71, 76, 85, 86, 89, 99, 101, 106, 108, 115, 176], "appropri": [28, 70, 72, 106, 143, 181], "reset_paramet": [28, 38, 43, 45, 76, 108], "reset": [28, 38, 43, 45, 76, 108], "reiniti": 28, "random": 28, "set_bits_binary_word": [28, 76], "num_bit": [28, 76, 176], "set_quantized_weight_data": [28, 38, 76, 79, 108], "requires_grad": [29, 39, 47, 77, 106, 107, 109, 185], "extend": [29, 35, 39, 47, 51, 57, 64, 70, 71, 77, 85, 98, 107, 109, 117], "techniqu": [29, 39, 47, 77, 106, 109], "updat": [29, 39, 43, 44, 46, 47, 65, 76, 77, 85, 89, 106, 107, 109, 115, 125, 168], "qweight": [29, 39, 44, 45, 46, 47, 70, 76, 77, 85, 86, 88, 89, 92, 93, 106, 107, 109, 114, 115, 125, 168, 175], "exp_avg_": [29, 39, 47, 77, 107, 109, 168], "exp_avg_l": [29, 39, 47, 77, 107, 109, 168], "step": [29, 39, 43, 44, 47, 73, 77, 88, 106, 107, 109, 114, 125, 160, 167, 168, 185], "lr": [29, 39, 47, 77, 107, 109, 125, 168], "0001": [29, 39, 47, 77, 107, 109, 125, 168], "weight_decai": [29, 39, 47, 77, 107, 109, 125, 168], "beta1": [29, 39, 47, 77, 107, 109, 168], "99": [29, 39, 47, 77, 107, 109, 125, 168], "beta2": [29, 39, 47, 77, 107, 109, 168], "9999": [29, 39, 47, 77, 107, 109, 125, 168], "ep": [29, 35, 39, 47, 77, 98, 99, 100, 101, 103, 104, 107, 109, 125, 168, 177, 178], "1e": [29, 39, 47, 77, 107, 109, 125, 168], "06": [29, 39, 47, 77, 107, 109, 125, 168], "float16": [29, 39, 47, 77, 106, 107, 109, 168], "correct_bia": [29, 39, 47, 77, 107, 109, 125, 168], "how": [29, 39, 46, 47, 70, 77, 85, 106, 107, 109, 143, 168, 184, 185], "mai": [29, 39, 44, 45, 46, 47, 65, 70, 77, 79, 86, 107, 109, 168, 169, 185], "momentum": [29, 39, 47, 77, 107, 109, 125, 168], "some": [29, 39, 47, 77, 107, 109, 168], "algorithm": [29, 39, 47, 77, 107, 109, 168], "exponenti": [29, 39, 47, 77, 107, 109, 168], "move": [29, 39, 47, 77, 107, 109, 168], "averag": [29, 39, 47, 77, 107, 109, 125, 162, 168], "squar": [29, 39, 47, 77, 107, 109, 125, 168], "like": [29, 39, 43, 44, 47, 77, 92, 106, 107, 109, 125, 157, 161, 164, 168, 173, 174, 182, 185], "adam": [29, 39, 47, 77, 107, 109, 125, 168], "iter": [29, 39, 47, 77, 107, 109, 125, 137, 138, 139, 140, 150, 154, 164, 167, 168, 173, 174], "learn": [29, 39, 47, 60, 65, 77, 88, 107, 109, 114, 125, 168], "rate": [29, 39, 47, 77, 107, 109, 125, 168], "condit": [29, 39, 47, 77, 88, 107, 109, 114, 168], "hyperparamet": [29, 39, 47, 77, 107, 109, 168], "while": [29, 35, 39, 43, 44, 47, 73, 77, 85, 89, 101, 107, 109, 115, 168, 182], "toward": [29, 39, 47, 77, 107, 109, 125, 168], "decai": [29, 39, 47, 77, 107, 109, 125, 168], "l2": [29, 39, 47, 77, 107, 109, 125, 168], "penalti": [29, 39, 47, 77, 107, 109, 125, 168], "regular": [29, 39, 47, 77, 107, 109, 168], "term": [29, 39, 47, 65, 77, 106, 107, 109, 122, 125, 132, 168], "help": [29, 39, 47, 77, 100, 107, 109, 168], "prevent": [29, 35, 39, 47, 77, 100, 103, 107, 109, 121, 168, 177, 178], "overfit": [29, 39, 47, 77, 107, 109, 121, 168], "penal": [29, 39, 47, 77, 107, 109, 168], "first": [29, 39, 47, 57, 71, 72, 73, 77, 100, 107, 109, 161, 163, 168, 169, 177, 178], "moment": [29, 39, 47, 77, 107, 109, 168], "estim": [29, 39, 47, 77, 107, 109, 168], "second": [29, 39, 47, 72, 73, 77, 100, 107, 109, 160, 166, 168, 173], "anoth": [29, 39, 47, 77, 107, 109, 168], "small": [29, 35, 39, 47, 77, 98, 100, 103, 107, 109, 168, 177, 178], "constant": [29, 39, 47, 77, 107, 109, 160, 168], "stabil": [29, 39, 47, 64, 77, 103, 107, 109, 125, 168], "certain": [29, 39, 43, 44, 47, 77, 98, 107, 109, 117, 121, 135, 166, 168, 185], "bert": [29, 39, 47, 77, 107, 109, 161, 168], "place": [29, 39, 47, 77, 107, 109, 168], "doe": [29, 39, 47, 77, 107, 109, 158, 165, 168], "anyth": [29, 39, 47, 77, 107, 109, 168], "notimplementederror": [29, 39, 47, 77, 92, 93, 106, 107, 109, 168], "yet": [29, 39, 47, 77, 93, 106, 107, 108, 109, 168, 181, 185], "get": [33, 62, 68, 83], "nbitconv2dbas": 35, "aim": [35, 60, 100, 103, 106, 133, 162], "improv": [35, 101, 121, 125], "accuraci": [35, 70, 85, 101, 103, 184], "epsilon": [35, 98, 99, 100, 101, 103, 104, 125], "divis": [35, 98, 99, 100, 101, 103, 104, 117, 121, 177, 178], "calcul": [35, 36, 44, 65, 71, 86, 88, 91, 100, 101, 106, 107, 114, 162, 165, 176], "releas": 35, "especi": [35, 60, 76, 98, 106], "runtim": [35, 56, 154, 180], "shift": [35, 172, 184], "learnabl": [35, 98, 103, 122], "intend": [36, 57, 70, 71, 169], "low": [36, 70, 89, 98, 100, 101, 108, 115, 127, 184], "primit": 36, "placehold": [36, 44, 65, 71, 89, 99, 101, 104, 106, 115, 180, 181], "differenti": 36, "functionctx": [36, 57], "a_bit": [38, 79, 88, 89, 106, 108, 114], "w_bit": [38, 79, 88, 89, 106, 107, 108, 114, 115], "creat": [38, 46, 56, 64, 79, 91, 140, 154, 185], "overridden": [38, 57, 71], "proper": [38, 99], "evalu": [38, 43, 70], "otherwis": [38, 79, 117, 132, 133, 157, 158, 174, 185], "kaim": [38, 76, 108], "uniform": [38, 76, 108, 177, 178], "num_embed": [43, 45], "embedding_dim": [43, 45], "padding_idx": [43, 45], "bag": [43, 44], "binar": [43, 44, 45, 65, 71, 173, 174], "boolean": [43, 44, 51, 117, 149, 150, 163, 164], "experiment": [43, 44, 45, 46, 86, 121], "guarante": [43, 86], "free": [43, 44, 86], "alwai": [43, 44, 45, 46], "due": [43, 44, 46, 51, 91], "natur": [43, 44, 46, 71], "note": [43, 44, 45, 46, 99, 121, 160], "char": 43, "occupi": 43, "per": [43, 85, 174], "thu": [43, 65], "despit": 43, "being": [43, 86, 106, 154], "truli": 43, "import": [43, 167, 181], "consid": [43, 47, 60, 73, 98, 99, 106, 132, 158, 163, 164], "when": [43, 44, 76, 85, 86, 135, 137, 138, 139, 140, 185], "same": [43, 185], "4x": [43, 162], "tradit": [43, 44, 184], "descent": [43, 44, 125], "cannot": [43, 44, 51, 117, 133, 156, 157, 181], "sinc": [43, 44, 65], "do": [43, 44, 64, 89, 99, 100, 101, 104, 115], "instead": [43, 44, 57, 71, 125, 181], "decid": [43, 44], "state": [43, 44, 45, 64, 70, 76, 79, 85, 100, 106, 108, 163, 169, 180], "criteria": [43, 44, 117], "rule": [43, 44], "deriv": [43, 44, 56], "might": [43, 44, 91, 150, 156, 161, 185], "strategi": [43, 44, 106, 136, 138], "flip": [43, 44], "presenc": [43, 44, 150], "absenc": [43, 44, 181], "vote": [43, 44], "system": [43, 44, 133, 143, 145, 156, 157], "across": [43, 44, 85], "multipl": [43, 44, 60, 64, 65, 72, 73, 85, 89, 100, 101, 106, 114, 115, 121, 160, 165, 166], "develop": [43, 44, 180, 182], "care": [43, 44, 46], "consider": [43, 44], "adher": [43, 44, 88, 114], "limit": [43, 44, 117, 169], "characterist": [43, 44, 60], "algebra": [43, 44], "dictionari": [43, 45, 85, 143, 147, 169], "vector": [43, 45, 121], "index": [43, 45, 46, 64, 91, 92, 107, 174, 184, 185], "intern": [43, 45, 70, 100, 108], "share": [43, 45, 100, 108, 176], "scriptmodul": [43, 45, 100, 108], "fetch": [43, 132, 133], "lookup": [44, 46], "major": [44, 145], "ones": 44, "slice": [44, 173], "simpli": 44, "unchang": 44, "futur": [44, 88, 106, 114, 185], "sparse_update_embedding_qweight": [44, 46], "ani": [44, 51, 54, 56, 57, 62, 64, 71, 79, 83, 86, 117, 125, 142, 143, 146, 147, 150, 156, 157, 160, 164, 167, 180, 181, 184], "stage": [45, 121], "uint8": [45, 46, 162], "row": [45, 85, 86, 91, 107, 173, 174], "wise": [45, 64, 70, 86, 173], "setup": [45, 46, 88, 114], "checkpoint": [45, 98, 106, 163, 169], "load": [45, 85, 98, 106, 163, 169, 180], "fill": [45, 165], "seq_length": [46, 161, 170], "matrix": [46, 56, 60, 64, 65, 72, 73, 85, 89, 100, 101, 106, 107, 114, 115, 160, 165], "embed_scal": 46, "ori_embedding_dim": 46, "handl": [46, 57, 64, 65, 71, 73, 79, 85, 91, 92, 103, 125, 176, 181], "flow": [46, 99], "behavior": [46, 86, 150, 180], "conjunct": [46, 89, 115], "most": [46, 70, 106], "suggest": 46, "approach": [46, 106, 184], "here": [46, 100, 150], "exampl": [46, 91, 132, 172, 173, 174, 181, 185], "xor": 46, "grad_weight": [46, 65], "mask": [46, 121], "identifi": [46, 70, 71, 133, 145, 180], "posit": [46, 121, 172, 173, 174, 177, 178], "keep": [46, 98, 185], "elsewher": 46, "manipul": 46, "dynam": [46, 70, 86, 100, 147, 180, 181], "original_embedding_dim": 46, "active_indic": 47, "allow": [47, 56, 60, 85, 89, 101, 106, 115, 163, 164, 167, 169, 172, 180, 181, 184, 185], "spars": [47, 125], "enhanc": [47, 70, 184], "focus": [47, 79, 167], "mixin": [51, 117], "linear": [51, 54, 56, 57, 62, 64, 65, 68, 70, 71, 76, 77, 79, 83, 85, 86, 88, 89, 96, 98, 99, 103, 104, 106, 108, 109, 114, 115, 117, 121, 137, 138, 139, 164, 167], "qlinearimplementationmixin": [51, 79], "clone": [51, 56, 64, 79, 117, 185], "sign": [51, 65, 71, 125, 173, 174, 176], "swishsign": 51, "can_clon": [51, 117], "accord": 51, "recip": [51, 56, 64, 79, 117], "explicitli": 51, "abc": [51, 117], "classmethod": [51, 56, 64, 79, 117], "layerrecip": [51, 56, 64, 79, 117], "str": [51, 117, 126, 132, 136, 137, 138, 139, 140, 142, 143, 146, 147, 149, 150, 151, 154, 156, 157, 163, 169, 180, 181], "among": 51, "either": [51, 57, 71, 106, 150, 162, 167, 172, 184, 185], "along": [51, 121, 122], "string": [51, 117, 136, 145, 149, 150, 157], "empti": [51, 135, 137, 138, 139, 140, 149, 150], "unsupport": 51, "detail": [54, 57, 71, 86, 132, 185], "input_featur": [56, 64, 70, 76, 79], "out_featur": [56, 64, 70, 76, 79], "binarylinearbas": [56, 64, 70, 79], "mix": [56, 64, 85, 86, 88, 89, 92, 93, 106, 114, 115], "binarylinearimplementationmixin": [56, 64], "itself": 56, "easi": 56, "replic": 56, "modif": [56, 180], "divid": [56, 165], "create_clone_from": [56, 64, 79], "instanc": [56, 64, 79, 140, 154, 167, 181, 184], "transform": [56, 57, 65, 79, 85, 88, 98, 114, 121, 161, 167, 173], "clear": 56, "There": [57, 71], "wai": [57, 71], "combin": [57, 60, 71, 161], "staticmethod": [57, 71], "def": [57, 71], "accept": [57, 71], "follow": [57, 71, 91, 156, 157, 185], "see": [57, 71, 138, 150, 185], "more": [57, 60, 71, 85, 100, 106, 185], "2": [57, 71, 85, 88, 100, 101, 106, 107, 114, 127, 136, 143, 149, 156, 160, 184, 185], "separ": [57, 71, 150, 157], "setup_context": [57, 71], "longer": [57, 71], "overrid": [57, 71], "though": [57, 71], "enforc": [57, 71, 85], "thei": [57, 71, 72, 88, 106, 114, 176], "equival": [57, 71, 172, 173, 174], "vjp": [57, 71], "save_for_forward": [57, 71], "jvp": [57, 71], "enumer": [60, 65], "select": [60, 70, 106, 185], "choic": 60, "differ": [60, 79, 85, 89, 91, 106, 115, 125, 176, 182], "underli": [60, 79], "constraint": [60, 65, 85, 98, 117], "bstc32": 60, "softwar": 60, "core": 60, "simul": 60, "flexibl": [60, 85], "cost": [60, 70, 98, 106], "raw": 60, "btc32": 60, "nvidia": [60, 176, 185], "high": [60, 98, 100, 106], "adapt": [60, 64, 85, 106, 125, 185], "best": 60, "capabl": [60, 65, 98, 184], "deep": [60, 65, 88, 114, 125], "preval": 60, "bmm_type": [64, 65], "bmm": [64, 65], "cutlass": [64, 149, 150], "manag": [64, 85, 98, 185], "enum": [64, 133], "hidden": [64, 70, 76, 79, 106, 121], "around": [64, 70, 76], "deploi": [64, 184], "copi": 64, "device_id": 64, "bias": [64, 70, 164], "job": 64, "w_pack": 64, "eval": 65, "receiv": [65, 99], "grad_input": 65, "doesn": 65, "t": [65, 185], "grad_scale_a": 65, "account": [65, 101], "clip": [65, 71, 72, 73, 101], "remain": [65, 174], "within": [65, 70, 71, 91, 98, 106, 125, 132, 135, 137, 138, 139, 140, 149, 156, 157, 167, 172, 177, 178, 185], "reflect": [65, 106], "direct": 65, "incorpor": [70, 169], "gemm": [70, 71], "gemm_kernel_id": [70, 71], "aid": 70, "select_gemm_kernel": 70, "readi": [70, 106], "full": [70, 85, 154, 181, 184], "facilit": [70, 76, 108], "leav": 70, "choos": 70, "one": [70, 98, 106, 182, 184, 185], "id": 70, "warmup": 70, "phase": 70, "begin": [70, 149], "preprocess": 70, "statist": [70, 106], "influenc": 70, "backpropag": [71, 107], "flatten": [71, 161, 170], "back": [71, 85, 121, 160, 170], "reli": 71, "three": [71, 92, 145, 149], "through": [71, 76, 79, 150, 164], "wrap": 72, "binarymatmulfunct": 72, "benefit": 72, "x_clip": [72, 73, 100, 101], "y_clip": [72, 73, 100, 101], "y": [72, 73, 100, 101, 173, 185], "set_activation_scal": [72, 100], "alreadi": [72, 164], "absolut": [72, 98, 156, 176, 185], "e": [73, 107, 132, 158, 182, 185], "g": [73, 107, 132, 182, 185], "128": [73, 136, 166, 178], "better": 73, "threshold": [73, 177, 178], "creation": 76, "foundat": [76, 184], "fulli": [76, 98, 99, 162, 184, 185], "connect": [76, 98, 99], "output_featur": 76, "extern": 76, "_check_forward": [76, 98, 103], "valid": [76, 85, 88, 100, 106, 114, 121, 125], "modifi": [76, 172, 173, 180], "purpos": 76, "disabl": [76, 106], "binari": [79, 86, 125, 160, 162, 164, 167, 172, 173, 174, 182], "access": [79, 91, 180], "use_mbw": [85, 86], "group": [85, 86, 89, 91, 92, 106, 107, 115, 136], "rows_pack": 85, "bitwidth": [85, 86, 100, 108], "mbwq": [85, 86], "mpqlinearbas": [85, 88, 114], "scheme": [85, 104], "run": [85, 125, 133, 145, 181, 185], "fine": [85, 106, 184], "grain": 85, "control": [85, 106], "over": [85, 106, 167, 173], "off": 85, "7": [85, 177], "about": [85, 91, 184], "distribut": [85, 86], "permut": [85, 86, 107], "check_paramet": [85, 88, 106, 114], "chosen": 85, "load_state_dict": 85, "set_scal": 85, "set_zero": 85, "q42fp_weight": 85, "fp": 85, "q4": 85, "exl2fp_weight": 85, "exl2": 85, "against": [85, 143], "qscale": [88, 106, 114], "qscales_zero": 107, "qscales_scal": 107, "qzero": [88, 106, 114], "qzeros_zero": 107, "qzeros_scal": 107, "q_perm": [85, 86, 107], "q_group_map": [85, 86, 107], "were": [85, 137, 138, 139], "de": 85, "complex": 85, "perhap": 85, "translat": 85, "order": [85, 156, 157], "state_dict": 85, "strict": 85, "case": [85, 86, 145, 181], "dict": [85, 143, 147, 163], "kei": [85, 121, 147, 184], "group_siz": [85, 86, 106, 107, 115], "accur": [85, 106], "associ": [85, 106, 156], "togeth": 85, "crucial": [85, 106, 108, 121], "reshap": [85, 160], "action": 85, "taken": 85, "consist": [86, 91], "reorder": 86, "prioriti": 86, "subject": 86, "advanc": 86, "mpq": [88, 89, 106, 114, 115, 136, 138], "fix": [88, 104, 114], "16": [88, 106, 114, 184, 185], "task": [88, 114, 125], "asymmetr": [88, 89, 106, 107, 114, 115], "meet": [88, 114, 117, 126], "decompress": [88, 106, 114], "met": [88, 98, 114], "mainli": [88, 106, 114], "could": [88, 106, 114], "simplifi": [88, 106, 114, 154], "elimin": [88, 106, 114], "power": [89, 115], "constrain": [89, 115, 121, 184], "environ": [89, 98, 115, 121, 150, 156, 157, 182, 184, 185], "privileg": [89, 107, 115], "mpq_adamw": [89, 115], "g_idx": [89, 107], "asym": [89, 106, 107], "q_group": 91, "num_qrow": 91, "irregular": 91, "organ": 91, "assign": 91, "total": 91, "overal": 91, "short": 91, "invers": [91, 177, 178], "mpqweightparamet": [92, 93, 115], "fp16": [92, 93, 175, 176], "qweightparamet": 92, "main": [92, 106], "gptq": [92, 93, 106, 175], "style": [92, 93, 175, 184], "g_index": [92, 93], "valueerror": [92, 93, 121, 125, 176], "layer_typ": [92, 107, 135], "invalid": 92, "present": [92, 150], "For": [92, 93, 125, 143, 158, 164, 174, 184, 185], "unimpl": 92, "miss": 93, "q": [96, 107], "avoid": [98, 99, 101, 104, 176, 177, 178], "regist": 98, "buffer": [98, 106], "nbitlinearbas": [98, 103, 106], "introduc": [98, 103, 106, 122, 184], "speed": 98, "critic": 98, "remov": [98, 160, 185], "everi": 98, "retain": 98, "q4linear": 99, "parent": [100, 117, 121, 135, 137, 138, 139, 140], "than": [100, 147, 165, 176, 180], "alpha": 100, "ab": 100, "math": 100, "sqrt": 100, "qp": 100, "127": [100, 178], "matmul": 101, "dequant": 101, "reason": [101, 106], "instanti": 101, "q_linear_cutlass": 101, "magnitud": [103, 162], "00001": 103, "verifi": [103, 158], "alter": 103, "use_gba_qu": 106, "dq_group_siz": 106, "dq_mode": 106, "disable_bia": 106, "languag": [106, 184], "llm": [106, 127, 184], "bitwis": [106, 172], "tailor": [106, 143], "platform": [106, 181], "name": [106, 133, 135, 137, 138, 139, 140, 154, 169, 180, 181, 185], "correspondingli": 106, "dimension": [106, 121], "entir": [106, 132], "treat": 106, "gba": 106, "compliant": 106, "doubl": [106, 136], "granular": 106, "cater": 106, "llama": 106, "altern": [106, 185], "init_gptq": 106, "init_gba": 106, "accommod": 106, "asymmetri": 106, "set_qweight_data": 106, "dim": 106, "facter": 106, "symmetri": 106, "relev": 106, "tune": [106, 184], "minim": 106, "infrastructur": 106, "recent": 106, "privileged_grad": [86, 89, 107], "affin": 107, "mpqlinear": 107, "mbwqlinear": 107, "rest": 107, "awar": 108, "qat": 108, "framework": 108, "trigger": 108, "mlx": [114, 115, 154, 156, 157, 158, 184], "appl": 114, "accel": 115, "customimplementationmixin": 117, "relat": 117, "describ": 117, "explain": 117, "why": 117, "input_dim": 121, "hidden_dim": 121, "num_head": 121, "multi": 121, "head": 121, "attent": 121, "mha": 121, "deploy": [121, 167], "resourc": [121, 184], "head_dim": 121, "q_linear": 121, "queri": 121, "binarylinearcutlass": 121, "v_linear": 121, "k_linear": 121, "dropout": 121, "final": [121, 165], "project": [121, 127, 184, 185], "still": [121, 182], "evenli": 121, "align": 121, "alert": 121, "user": [121, 125, 181, 185], "hidden_st": 121, "exclud": [121, 164], "score": 121, "out_chn": 122, "beta": 125, "suit": 125, "diod": 125, "reinvent": 125, "guo": 125, "nianhui": 125, "et": 125, "al": 125, "2024": [125, 127], "coeffici": 125, "denomin": 125, "6": [125, 172], "closur": 125, "guid": 125, "sparseadam": 125, "callabl": [125, 140], "reevalu": 125, "architectur": [131, 133, 143, 147, 164, 184], "search_term": 132, "instruct": [132, 143, 185], "cpuinfo": 132, "search": [132, 149, 150, 156, 157, 184], "sse4_2": 132, "avx2": [132, 143], "found": [132, 145, 149, 150, 156, 157, 181], "print": [132, 181], "get_cpu_info": 132, "quit": 132, "verbos": [128, 132], "comment": [132, 143], "statement": 132, "product": 132, "linux": [133, 143, 184], "arm": [133, 143, 185], "get_arm_model": 133, "arch_cpu": 133, "predefin": [133, 150, 154, 164, 167, 181], "attempt": [133, 149, 156, 157, 180, 181], "lscpu": 133, "command": [133, 145], "pars": [133, 145], "except": [126, 133], "recogn": 133, "is_arm": 133, "parent_nam": [135, 137, 138, 139, 140], "collect": [135, 145], "layer": [135, 136, 137, 138, 139, 140, 163, 164, 167, 169, 182, 184, 185], "recurs": [135, 140, 185], "usual": [135, 137, 138, 139, 140, 169], "quantized_lay": [], "names_to_replac": [137, 138, 139, 140], "double_group_s": [], "root_path": [142, 146, 154], "relative_nam": [142, 146, 154], "relative_sourc": [142, 146, 154], "compil": [143, 145, 147, 154, 185], "maco": [143, 184], "include_dir": 143, "look": [143, 156, 157], "header": [143, 149, 156], "link": [143, 154], "vari": 143, "omp": 143, "gomp": 143, "extra_compile_arg": [143, 147], "warn": [143, 147, 181], "openmp": [143, 147, 185], "armv8": 143, "detect": [143, 147], "a55": 143, "a76": 143, "snippet": 143, "show": 143, "condition": [143, 147, 181], "gcc": [145, 147, 185], "gnu": 145, "instal": [145, 156, 157, 182, 184], "subprocess": 145, "extract": 145, "clang": [145, 185], "masquerad": 145, "minor": 145, "patch": 145, "construct": [140, 147], "extra": 147, "nvcc": 147, "suppress": 147, "deprec": 147, "declar": 147, "host": 147, "11": [147, 185], "greater": [147, 165], "nest": 147, "cxx": [147, 185], "p": [149, 150, 185], "exist": [149, 150, 180], "locat": [149, 150, 154, 156, 157], "rel": [149, 154, 182], "insid": 149, "3": [149, 156, 185], "structur": [149, 170], "wa": [149, 150], "check_onli": 150, "usr": 150, "local": 150, "cpath": [150, 156], "upon": 150, "union": 150, "check_path": 150, "shown": 150, "success": [150, 181], "root": 154, "resolv": 154, "prefix": [154, 156, 157, 181, 185], "constitut": 154, "possibl": 156, "packag": [156, 157, 167, 185], "submodul": [156, 157], "under": [156, 157, 185], "scan": 156, "libmlx": 157, "dylib": 157, "hypothet": 157, "lib": [157, 185], "In": [157, 184, 185], "library_path": 157, "colon": 157, "unix": 157, "get_mlx_include_path": 158, "get_mlx_lib_path": 158, "shape_pr": 160, "x_pad_sec_last": 160, "y_pad_sec_last": 160, "post": 160, "sever": 160, "truncat": 160, "domain": 160, "replac": [137, 138, 139, 140, 160], "formula": 160, "revert": 160, "3d": [161, 170], "hidden_s": 161, "later": [161, 185], "unflatten": [161, 170], "cl": 162, "32x": 162, "preserv": 162, "checkpoint_path": 163, "resum": [163, 169], "invok": 164, "prior": 164, "whose": [140, 164, 172], "sub": [140, 164], "smallest": 165, "equal": 165, "so": [165, 182], "remaind": 165, "column": [165, 173], "nearest": [166, 177, 178], "round": [166, 177, 178], "those": 167, "well": [167, 185], "comprehens": 167, "statu": 169, "inclus": 169, "filenam": 169, "pth": 169, "abil": 169, "flatten_x": 170, "output_s": 170, "var": 172, "po": 172, "val": 172, "OR": 172, "least": 172, "lsb": 172, "0b0010": 172, "0b0110": 172, "nd_col": 173, "binary_col": 173, "dim_n": 173, "dim_k": 173, "bits_per_binary_word": [173, 174], "arrai": [173, 174], "columnar": 173, "encod": 173, "segment": [173, 174], "neg": [173, 174, 176], "v": [173, 182, 185], "proce": 173, "block": 173, "binary_word": [173, 174], "rvalu": [173, 174], "b": 173, "col": 173, "bit_set": [173, 174], "b_col": 173, "nd_row": 174, "binary_row": 174, "nd_size": 174, "ndarrai": 174, "j": 174, "b_row": 174, "amax": 176, "narrow_rang": 176, "narrow": 176, "tensorquantfunct": 176, "faketensorquantfunct": 176, "author": [127, 176], "nv_pytorch_quant": 176, "http": [176, 185], "github": [176, 185], "com": [176, 185], "tensorrt": 176, "blob": 176, "master": 176, "tool": 176, "pytorch_quant": 176, "tensor_qu": 176, "py": 176, "l315": 176, "typeerror": 176, "encount": 176, "fp32": 176, "overflow": 176, "bf16": 176, "smaller": 176, "too": [177, 178], "close": [177, 178], "clamp": [177, 178], "ideal": [177, 178], "fit": [177, 178, 185], "intercept": 180, "misus": 180, "suppos": 180, "promptli": 180, "_name": 180, "__getattr__": 180, "runtimeerror": 180, "__setattr__": 180, "module_nam": 181, "not_yet_impl": 181, "safe": 181, "mark": 181, "importerror": 181, "continu": 181, "gracefulli": 181, "extension_prefix": 181, "known": [136, 181], "immedi": 181, "extensionmoduleplacehold": 181, "binary_linear_cuda": 181, "consol": 181, "issu": 181, "interrupt": 181, "bitorch_engin": [182, 184], "sphinx": [], "To": [182, 185], "cd": 185, "repositori": 185, "html": [], "put": [], "bie": 184, "cut": 184, "build": [184, 185], "strength": 184, "technologi": 184, "pioneer": 184, "push": 184, "boundari": 184, "green": 184, "showcas": 184, "adept": 184, "fast": [], "qllm": [], "trainer": 184, "track": 184, "changelog": 184, "docker": [182, 184], "qconv": 184, "qembed": 184, "qlinear": [182, 184], "qmha": 184, "diode_beta": 184, "arch_help": 184, "cuda_extens": 184, "cutlass_path": 184, "mlx_extens": 184, "mlx_path": 184, "quant_oper": 184, "safe_import": 184, "doc": [], "page": 184, "enjoi": 184, "explor": 184, "our": [184, 185], "toolkit": 185, "your": 185, "bitorch": 185, "engin": 185, "pip": [182, 185], "hide": 185, "cpp": [182, 185], "bie_build_onli": 182, "arch": 182, "bie_cuda_arch": 182, "sm_75": 182, "sm_80": 182, "sm_86": 182, "homebrew": 185, "brew": 185, "libomp": 185, "export": 185, "ld_library_path": [], "someth": 185, "ldflag": 185, "l": 185, "opt": 185, "cppflag": 185, "projector": [29, 39, 47, 77, 107, 109, 168], "grad": [29, 39, 47, 77, 107, 109, 168], "optin": [29, 39, 47, 77, 107, 109, 168], "q_weight": 86, "required_vers": 126, "below": 126, "galor": 127, "jiaweizzhao": [], "tree": [], "galore_torch": [], "licens": 127, "apach": 127, "tab": 185, "ov": 185, "misc": 127, "zhao2024galor": 127, "titl": 127, "rank": [127, 128], "jiawei": 127, "zhao": 127, "zhenyu": 127, "zhang": 127, "beidi": 127, "chen": 127, "zhangyang": 127, "wang": 127, "anima": 127, "anandkumar": 127, "yuandong": 127, "tian": 127, "year": 127, "eprint": 127, "2403": 127, "03507": 127, "archiveprefix": 127, "arxiv": 127, "primaryclass": 127, "lg": 127, "update_proj_gap": 128, "200": 128, "proj_typ": 128, "std": 128, "mpq_strategi": [136, 138], "256": 136, "binarylinearcuda": 137, "mpqlinearcuda": 138, "get_mpq_config": 138, "q4linearcutlass": 139, "class_": 140, "replace_fn": 140, "done": 140, "collect_lay": 140, "is_avail": 182, "hpc": 182, "bie_force_cuda": 182, "conda": 184, "forc": 184, "galore_projector": 184, "9": 185, "12": 185, "built": 185, "recommend": 185, "cuda_hom": 185, "everyth": 185, "etc": 185, "wish": 185, "label": 185, "download": 185, "cp39": 185, "linux_x86_64": 185, "whl": 185, "torchvis": 185, "vision": 185, "readm": 185, "url": 185, "org": 185, "cu118": 185, "workspac": 185, "dir": 185, "bitorch_workspac": 185, "home": 185, "mkdir": 185, "env": 185, "previou": 185, "git": 185, "greenbitai": 185, "cc": 185, "conda_prefix": 185, "dockerfil": 185, "rm": 185, "volum": 185, "latest": 185, "virtual": 185, "virtualenv": 185, "macosx_11_0_arm64": 185, "17": 185, "remind": 185, "mpqlinearlay": 185, "forg": 185, "test": 185, "howev": 185, "newer": 185, "abov": 185, "5": 185, "now": 185, "abl": 185, "leap": 184, "field": 184, "unlik": 184, "few": 184, "trainabl": 184, "lora": 184, "innov": 184, "paradigm": 184, "tightli": 184, "schema": 184, "outset": 184, "stand": 184, "testament": 184, "delic": 184, "balanc": 184, "address": 184, "challeng": 184, "sophist": 184, "repo": 127, "10": 185}, "objects": {"": [[0, 0, 0, "-", "bitorch_engine"]], "bitorch_engine": [[1, 0, 0, "-", "functions"], [12, 0, 0, "-", "layers"], [123, 0, 0, "-", "optim"], [129, 0, 0, "-", "utils"]], "bitorch_engine.functions": [[2, 0, 0, "-", "cuda"]], "bitorch_engine.functions.cuda": [[3, 0, 0, "-", "extension"], [5, 0, 0, "-", "functions"]], "bitorch_engine.functions.cuda.extension": [[4, 1, 1, "", "get_ext"]], "bitorch_engine.functions.cuda.functions": [[6, 1, 1, "", "fp32toint4"], [7, 1, 1, "", "q4_pack_tensor"], [8, 1, 1, "", "q4_unpack_and_scaling_tensor"], [9, 1, 1, "", "q4_unpack_tensor"], [10, 1, 1, "", "tensor_to_packed_uint8"], [11, 1, 1, "", "unpack_uint8_tensor"]], "bitorch_engine.layers": [[13, 0, 0, "-", "qconv"], [40, 0, 0, "-", "qembedding"], [48, 0, 0, "-", "qlinear"], [118, 0, 0, "-", "qmha"]], "bitorch_engine.layers.qconv": [[14, 0, 0, "-", "binary"], [30, 0, 0, "-", "nbit"]], "bitorch_engine.layers.qconv.binary": [[15, 0, 0, "-", "cpp"], [21, 0, 0, "-", "cutlass"], [27, 0, 0, "-", "layer"]], "bitorch_engine.layers.qconv.binary.cpp": [[16, 0, 0, "-", "extension"], [18, 0, 0, "-", "layer"]], "bitorch_engine.layers.qconv.binary.cpp.extension": [[17, 1, 1, "", "get_ext"]], "bitorch_engine.layers.qconv.binary.cpp.layer": [[19, 2, 1, "", "BinaryConv2dCPP"], [20, 2, 1, "", "BinaryConv2dForward"]], "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP": [[19, 3, 1, "", "__init__"], [19, 4, 1, "", "bits_binary_word"], [19, 3, 1, "", "forward"], [19, 3, 1, "", "generate_quantized_weight"], [19, 3, 1, "", "prepare_params"]], "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dForward": [[20, 3, 1, "", "forward"]], "bitorch_engine.layers.qconv.binary.cutlass": [[22, 0, 0, "-", "extension"], [24, 0, 0, "-", "layer"]], "bitorch_engine.layers.qconv.binary.cutlass.extension": [[23, 1, 1, "", "get_ext"]], "bitorch_engine.layers.qconv.binary.cutlass.layer": [[25, 2, 1, "", "BinaryConv2dCutlass"], [26, 2, 1, "", "BinaryConv2dForward"]], "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass": [[25, 3, 1, "", "__init__"], [25, 4, 1, "", "bias_a"], [25, 4, 1, "", "bits_binary_word"], [25, 3, 1, "", "forward"], [25, 3, 1, "", "generate_quantized_weight"], [25, 3, 1, "", "prepare_params"], [25, 4, 1, "", "scale_a"], [25, 4, 1, "", "scale_w"], [25, 3, 1, "", "set_activation"], [25, 3, 1, "", "set_weight_data"]], "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dForward": [[26, 3, 1, "", "backward"], [26, 3, 1, "", "forward"]], "bitorch_engine.layers.qconv.binary.layer": [[28, 2, 1, "", "BinaryConv2dBase"], [29, 2, 1, "", "BinaryConvParameter"]], "bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase": [[28, 3, 1, "", "__init__"], [28, 3, 1, "", "generate_quantized_weight"], [28, 5, 1, "", "opt_weight"], [28, 3, 1, "", "prepare_params"], [28, 3, 1, "", "reset_parameters"], [28, 3, 1, "", "set_bits_binary_word"], [28, 3, 1, "", "set_quantized_weight_data"], [28, 3, 1, "", "set_weight_data"]], "bitorch_engine.layers.qconv.binary.layer.BinaryConvParameter": [[29, 3, 1, "", "update"]], "bitorch_engine.layers.qconv.nbit": [[31, 0, 0, "-", "cutlass"], [37, 0, 0, "-", "layer"]], "bitorch_engine.layers.qconv.nbit.cutlass": [[32, 0, 0, "-", "extension"], [34, 0, 0, "-", "layer"]], "bitorch_engine.layers.qconv.nbit.cutlass.extension": [[33, 1, 1, "", "get_ext"]], "bitorch_engine.layers.qconv.nbit.cutlass.layer": [[35, 2, 1, "", "Q4Conv2dCutlass"], [36, 2, 1, "", "Q4Conv2dCutlassForward"]], "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass": [[35, 3, 1, "", "__init__"], [35, 4, 1, "", "bias_a"], [35, 4, 1, "", "eps"], [35, 3, 1, "", "forward"], [35, 3, 1, "", "generate_quantized_weight"], [35, 3, 1, "", "prepare_params"], [35, 4, 1, "", "scale_a"], [35, 4, 1, "", "scale_w"], [35, 3, 1, "", "set_activation"]], "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward": [[36, 3, 1, "id0", "backward"], [36, 3, 1, "id1", "forward"]], "bitorch_engine.layers.qconv.nbit.layer": [[38, 2, 1, "", "nBitConv2dBase"], [39, 2, 1, "", "nBitConvParameter"]], "bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase": [[38, 3, 1, "", "__init__"], [38, 3, 1, "", "generate_quantized_weight"], [38, 5, 1, "", "opt_weight"], [38, 3, 1, "", "prepare_params"], [38, 3, 1, "", "reset_parameters"], [38, 3, 1, "", "set_quantized_weight_data"], [38, 3, 1, "", "set_weight_data"]], "bitorch_engine.layers.qconv.nbit.layer.nBitConvParameter": [[39, 3, 1, "", "update"]], "bitorch_engine.layers.qembedding": [[41, 0, 0, "-", "binary"]], "bitorch_engine.layers.qembedding.binary": [[42, 0, 0, "-", "layer"]], "bitorch_engine.layers.qembedding.binary.layer": [[43, 2, 1, "", "BinaryEmbeddingBag"], [44, 2, 1, "", "BinaryEmbeddingBagForward"], [45, 2, 1, "", "BinaryEmbeddingCuda"], [46, 2, 1, "", "BinaryEmbeddingForward"], [47, 2, 1, "", "BinaryEmbeddingParameter"]], "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag": [[43, 3, 1, "", "__init__"], [43, 3, 1, "", "forward"], [43, 3, 1, "", "reset_parameters"]], "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward": [[44, 3, 1, "", "backward"], [44, 3, 1, "", "forward"]], "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda": [[45, 3, 1, "", "__init__"], [45, 3, 1, "", "forward"], [45, 3, 1, "", "init_weight"], [45, 3, 1, "", "prepare_params"], [45, 4, 1, "", "qweight"], [45, 3, 1, "", "reset_parameters"], [45, 4, 1, "", "scale_w"], [45, 4, 1, "", "weight"]], "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingForward": [[46, 3, 1, "", "backward"], [46, 3, 1, "", "forward"]], "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingParameter": [[47, 4, 1, "", "active_indices"], [47, 3, 1, "", "update"]], "bitorch_engine.layers.qlinear": [[49, 0, 0, "-", "binary"], [78, 0, 0, "-", "layer"], [80, 0, 0, "-", "nbit"], [116, 0, 0, "-", "qlinear_implementation"]], "bitorch_engine.layers.qlinear.binary": [[50, 0, 0, "-", "binary_implementation"], [52, 0, 0, "-", "cpp"], [58, 0, 0, "-", "cuda"], [66, 0, 0, "-", "cutlass"], [74, 1, 1, "", "get_best_binary_implementation"], [75, 0, 0, "-", "layer"]], "bitorch_engine.layers.qlinear.binary.binary_implementation": [[51, 2, 1, "", "BinaryLinearImplementationMixin"]], "bitorch_engine.layers.qlinear.binary.binary_implementation.BinaryLinearImplementationMixin": [[51, 3, 1, "id0", "can_clone"]], "bitorch_engine.layers.qlinear.binary.cpp": [[53, 0, 0, "-", "extension"], [55, 0, 0, "-", "layer"]], "bitorch_engine.layers.qlinear.binary.cpp.extension": [[54, 1, 1, "", "get_ext"]], "bitorch_engine.layers.qlinear.binary.cpp.layer": [[56, 2, 1, "", "BinaryLinearCPP"], [57, 2, 1, "", "BinaryLinearForward"]], "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP": [[56, 3, 1, "", "__init__"], [56, 3, 1, "", "create_clone_from"], [56, 3, 1, "", "forward"], [56, 3, 1, "", "generate_quantized_weight"], [56, 3, 1, "", "prepare_params"]], "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearForward": [[57, 3, 1, "", "forward"]], "bitorch_engine.layers.qlinear.binary.cuda": [[59, 0, 0, "-", "bmm"], [61, 0, 0, "-", "extension"], [63, 0, 0, "-", "layer"]], "bitorch_engine.layers.qlinear.binary.cuda.bmm": [[60, 2, 1, "", "BMM"]], "bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM": [[60, 4, 1, "", "ADAPTIVE"], [60, 4, 1, "", "BSTC32"], [60, 4, 1, "", "BTC32"]], "bitorch_engine.layers.qlinear.binary.cuda.extension": [[62, 1, 1, "", "get_ext"]], "bitorch_engine.layers.qlinear.binary.cuda.layer": [[64, 2, 1, "", "BinaryLinearCuda"], [65, 2, 1, "", "BinaryLinearForward"]], "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda": [[64, 3, 1, "", "__init__"], [64, 4, 1, "", "bias_a"], [64, 4, 1, "", "bits_binary_word"], [64, 4, 1, "", "bmm_type"], [64, 3, 1, "", "create_clone_from"], [64, 5, 1, "", "device_id"], [64, 3, 1, "", "forward"], [64, 3, 1, "", "generate_quantized_weight"], [64, 3, 1, "", "prepare_params"], [64, 4, 1, "", "scale_a"], [64, 4, 1, "", "scale_w"], [64, 3, 1, "", "set_activation"], [64, 3, 1, "", "set_weight_data"], [64, 3, 1, "", "w_pack"]], "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward": [[65, 3, 1, "", "backward"], [65, 4, 1, "", "bmm_type"], [65, 4, 1, "", "ctx"], [65, 3, 1, "", "forward"], [65, 4, 1, "", "input"], [65, 4, 1, "", "is_train"], [65, 4, 1, "", "scale_a"], [65, 4, 1, "", "scale_w"], [65, 4, 1, "", "weight"]], "bitorch_engine.layers.qlinear.binary.cutlass": [[67, 0, 0, "-", "extension"], [69, 0, 0, "-", "layer"]], "bitorch_engine.layers.qlinear.binary.cutlass.extension": [[68, 1, 1, "", "get_ext"]], "bitorch_engine.layers.qlinear.binary.cutlass.layer": [[70, 2, 1, "", "BinaryLinearCutlass"], [71, 2, 1, "", "BinaryLinearForward"], [72, 2, 1, "", "BinaryMatMul"], [73, 2, 1, "", "BinaryMatMulFunction"]], "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass": [[70, 3, 1, "", "__init__"], [70, 4, 1, "", "bias_a"], [70, 4, 1, "", "bits_binary_word"], [70, 3, 1, "id0", "forward"], [70, 4, 1, "", "gemm_kernel_id"], [70, 3, 1, "id1", "generate_quantized_weight"], [70, 3, 1, "id2", "prepare_params"], [70, 4, 1, "", "scale_a"], [70, 4, 1, "", "scale_w"], [70, 3, 1, "id3", "select_gemm_kernel"], [70, 3, 1, "id4", "set_activation"], [70, 3, 1, "id5", "set_weight_data"]], "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward": [[71, 3, 1, "", "backward"], [71, 3, 1, "", "forward"]], "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul": [[72, 3, 1, "", "__init__"], [72, 4, 1, "", "dtype"], [72, 3, 1, "", "forward"], [72, 3, 1, "", "set_activation_scale"], [72, 4, 1, "", "x_clip"], [72, 4, 1, "", "y_clip"]], "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMulFunction": [[73, 3, 1, "", "backward"], [73, 3, 1, "", "forward"]], "bitorch_engine.layers.qlinear.binary.layer": [[76, 2, 1, "", "BinaryLinearBase"], [77, 2, 1, "", "BinaryLinearParameter"]], "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase": [[76, 3, 1, "", "__init__"], [76, 3, 1, "", "_check_forward"], [76, 4, 1, "", "bits_binary_word"], [76, 4, 1, "", "device"], [76, 4, 1, "", "dtype"], [76, 3, 1, "id0", "generate_quantized_weight"], [76, 4, 1, "", "input_features"], [76, 5, 1, "id1", "opt_weight"], [76, 4, 1, "", "output_features"], [76, 3, 1, "", "prepare_params"], [76, 4, 1, "", "qweight"], [76, 3, 1, "id2", "reset_parameters"], [76, 3, 1, "id3", "set_bits_binary_word"], [76, 3, 1, "id4", "set_quantized_weight_data"], [76, 3, 1, "id5", "set_weight_data"], [76, 4, 1, "", "symmetric"], [76, 4, 1, "", "weight"]], "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearParameter": [[77, 3, 1, "", "update"]], "bitorch_engine.layers.qlinear.layer": [[79, 2, 1, "", "QLinearInf"]], "bitorch_engine.layers.qlinear.layer.QLinearInf": [[79, 3, 1, "", "__init__"], [79, 3, 1, "", "create_clone_from"], [79, 3, 1, "", "forward"], [79, 3, 1, "", "generate_quantized_weight"], [79, 5, 1, "", "opt_weight"], [79, 3, 1, "", "prepare_params"], [79, 3, 1, "", "set_quantized_weight_data"], [79, 3, 1, "", "set_weight_data"], [79, 5, 1, "", "weight"]], "bitorch_engine.layers.qlinear.nbit": [[81, 0, 0, "-", "cuda"], [94, 0, 0, "-", "cutlass"], [105, 0, 0, "-", "layer"], [110, 0, 0, "-", "mps"]], "bitorch_engine.layers.qlinear.nbit.cuda": [[82, 0, 0, "-", "extension"], [84, 0, 0, "-", "mbwq_layer"], [87, 0, 0, "-", "mpq_layer"], [90, 0, 0, "-", "utils"]], "bitorch_engine.layers.qlinear.nbit.cuda.extension": [[83, 1, 1, "", "get_ext"]], "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer": [[85, 2, 1, "", "MBWQLinearCuda"], [86, 2, 1, "", "MBWQLinearCudaFunction"]], "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda": [[85, 3, 1, "", "__init__"], [85, 3, 1, "id0", "check_parameters"], [85, 3, 1, "id1", "exl2fp_weight"], [85, 3, 1, "id2", "forward"], [85, 3, 1, "id3", "load_state_dict"], [85, 3, 1, "id4", "prepare_params"], [85, 3, 1, "id5", "q42fp_weight"], [85, 4, 1, "", "qweight"], [85, 4, 1, "", "rows"], [85, 4, 1, "", "scales"], [85, 3, 1, "id6", "set_scales"], [85, 3, 1, "id7", "set_zeros"], [85, 4, 1, "", "use_mbw"], [85, 4, 1, "", "zeros"]], "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction": [[86, 3, 1, "", "backward"], [86, 3, 1, "", "forward"]], "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer": [[88, 2, 1, "", "MPQLinearCuda"], [89, 2, 1, "", "MPQLinearCudaFunction"]], "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda": [[88, 3, 1, "", "__init__"], [88, 4, 1, "", "a_bit"], [88, 3, 1, "id0", "check_parameters"], [88, 3, 1, "id1", "forward"], [88, 3, 1, "id2", "prepare_params"], [88, 4, 1, "", "qweight"], [88, 4, 1, "", "scales"], [88, 4, 1, "", "w_bit"], [88, 4, 1, "", "zeros"]], "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCudaFunction": [[89, 3, 1, "", "backward"], [89, 3, 1, "", "forward"]], "bitorch_engine.layers.qlinear.nbit.cuda.utils": [[91, 1, 1, "", "make_group_map"], [92, 1, 1, "", "pack_fp_weight"], [93, 1, 1, "", "unpack_qweight"]], "bitorch_engine.layers.qlinear.nbit.cutlass": [[95, 0, 0, "-", "extension"], [97, 0, 0, "-", "q4_layer"], [102, 0, 0, "-", "q8_layer"]], "bitorch_engine.layers.qlinear.nbit.cutlass.extension": [[96, 1, 1, "", "get_ext"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer": [[98, 2, 1, "", "Q4LinearCutlass"], [99, 2, 1, "", "Q4LinearFunction"], [100, 2, 1, "", "Q4MatMul"], [101, 2, 1, "", "Q4MatMulFunction"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass": [[98, 3, 1, "", "__init__"], [98, 3, 1, "", "_check_forward"], [98, 4, 1, "", "bias_a"], [98, 4, 1, "", "eps"], [98, 3, 1, "id0", "forward"], [98, 3, 1, "id1", "generate_quantized_weight"], [98, 3, 1, "id2", "prepare_params"], [98, 4, 1, "", "scale_a"], [98, 4, 1, "", "scale_w"], [98, 3, 1, "id3", "set_activation"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearFunction": [[99, 3, 1, "", "backward"], [99, 3, 1, "", "forward"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul": [[100, 3, 1, "", "__init__"], [100, 4, 1, "", "device"], [100, 4, 1, "", "dtype"], [100, 4, 1, "", "eps"], [100, 3, 1, "", "forward"], [100, 3, 1, "", "set_activation_scale"], [100, 4, 1, "", "x_clip"], [100, 4, 1, "", "y_clip"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMulFunction": [[101, 3, 1, "", "backward"], [101, 3, 1, "", "forward"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer": [[103, 2, 1, "", "Q8LinearCutlass"], [104, 2, 1, "", "Q8LinearFunction"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass": [[103, 3, 1, "", "__init__"], [103, 3, 1, "", "_check_forward"], [103, 4, 1, "", "bias_a"], [103, 4, 1, "", "eps"], [103, 3, 1, "id0", "forward"], [103, 3, 1, "id1", "generate_quantized_weight"], [103, 3, 1, "id2", "prepare_params"], [103, 4, 1, "", "scale_a"], [103, 4, 1, "", "scale_w"], [103, 3, 1, "id3", "set_activation"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearFunction": [[104, 3, 1, "", "backward"], [104, 3, 1, "", "forward"]], "bitorch_engine.layers.qlinear.nbit.layer": [[106, 2, 1, "", "MPQLinearBase"], [107, 2, 1, "", "MPQWeightParameter"], [108, 2, 1, "", "nBitLinearBase"], [109, 2, 1, "", "nBitLinearParameter"]], "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase": [[106, 3, 1, "", "__init__"], [106, 4, 1, "", "a_bit"], [106, 4, 1, "", "asym"], [106, 3, 1, "id0", "check_parameters"], [106, 4, 1, "", "disable_bias"], [106, 4, 1, "", "dq_group_size"], [106, 4, 1, "", "dq_mode"], [106, 4, 1, "", "dtype"], [106, 3, 1, "id1", "generate_quantized_weight"], [106, 4, 1, "", "group_size"], [106, 4, 1, "", "in_channels"], [106, 3, 1, "id2", "init_gba"], [106, 3, 1, "id3", "init_gptq"], [106, 3, 1, "id4", "initialize"], [106, 4, 1, "", "out_channels"], [106, 3, 1, "id5", "prepare_params"], [106, 3, 1, "id6", "set_qweight_data"], [106, 4, 1, "", "use_gba_quant"], [106, 4, 1, "", "w_bit"]], "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter": [[107, 3, 1, "", "__init__"], [107, 4, 1, "", "asym"], [107, 4, 1, "", "g_idx"], [107, 4, 1, "", "group_size"], [107, 4, 1, "", "layer_type"], [107, 4, 1, "", "privileged_grad"], [107, 4, 1, "", "q_group_map"], [107, 4, 1, "", "q_perm"], [107, 4, 1, "", "rows"], [107, 3, 1, "", "update"], [107, 4, 1, "", "w_bit"]], "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase": [[108, 3, 1, "", "__init__"], [108, 4, 1, "", "a_bit"], [108, 4, 1, "", "device"], [108, 4, 1, "", "dtype"], [108, 3, 1, "", "generate_quantized_weight"], [108, 4, 1, "", "in_channels"], [108, 5, 1, "", "opt_weight"], [108, 4, 1, "", "out_channels"], [108, 3, 1, "", "prepare_params"], [108, 3, 1, "", "reset_parameters"], [108, 3, 1, "", "set_quantized_weight_data"], [108, 3, 1, "", "set_weight_data"], [108, 4, 1, "", "w_bit"]], "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearParameter": [[109, 3, 1, "", "update"]], "bitorch_engine.layers.qlinear.nbit.mps": [[111, 0, 0, "-", "extension"], [113, 0, 0, "-", "mpq_layer"]], "bitorch_engine.layers.qlinear.nbit.mps.extension": [[112, 1, 1, "", "get_ext"]], "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer": [[114, 2, 1, "", "MPQLinearMlx"], [115, 2, 1, "", "MPQLinearMlxFunction"]], "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx": [[114, 3, 1, "", "__init__"], [114, 4, 1, "", "a_bit"], [114, 3, 1, "id0", "check_parameters"], [114, 3, 1, "id1", "forward"], [114, 3, 1, "id2", "prepare_params"], [114, 4, 1, "", "qweight"], [114, 4, 1, "", "scales"], [114, 4, 1, "", "w_bit"], [114, 4, 1, "", "zeros"]], "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlxFunction": [[115, 3, 1, "", "backward"], [115, 3, 1, "", "forward"]], "bitorch_engine.layers.qlinear.qlinear_implementation": [[117, 2, 1, "", "QLinearImplementationMixin"]], "bitorch_engine.layers.qlinear.qlinear_implementation.QLinearImplementationMixin": [[117, 3, 1, "", "can_clone"]], "bitorch_engine.layers.qmha": [[119, 0, 0, "-", "binary"]], "bitorch_engine.layers.qmha.binary": [[120, 0, 0, "-", "layer"]], "bitorch_engine.layers.qmha.binary.layer": [[121, 2, 1, "", "BMHA"], [122, 2, 1, "", "LearnableBias"]], "bitorch_engine.layers.qmha.binary.layer.BMHA": [[121, 3, 1, "", "__init__"], [121, 4, 1, "", "dropout"], [121, 4, 1, "", "dtype"], [121, 3, 1, "", "forward"], [121, 4, 1, "", "head_dim"], [121, 4, 1, "", "hidden_dim"], [121, 4, 1, "", "input_dim"], [121, 4, 1, "", "k_linear"], [121, 4, 1, "", "num_heads"], [121, 4, 1, "", "out"], [121, 4, 1, "", "q_linear"], [121, 4, 1, "", "v_linear"]], "bitorch_engine.layers.qmha.binary.layer.LearnableBias": [[122, 3, 1, "", "__init__"], [122, 4, 1, "", "bias"], [122, 3, 1, "", "forward"]], "bitorch_engine.optim": [[124, 0, 0, "-", "diode_beta"], [127, 0, 0, "-", "galore_projector"]], "bitorch_engine.optim.diode_beta": [[125, 2, 1, "", "DiodeMix"], [126, 1, 1, "", "check_pytorch_version"]], "bitorch_engine.optim.diode_beta.DiodeMix": [[125, 3, 1, "id0", "__init__"], [125, 4, 1, "", "betas"], [125, 4, 1, "", "correct_bias"], [125, 4, 1, "", "dtype"], [125, 4, 1, "", "eps"], [125, 4, 1, "", "lr"], [125, 4, 1, "", "params"], [125, 3, 1, "id1", "step"], [125, 4, 1, "", "weight_decay"]], "bitorch_engine.optim.galore_projector": [[128, 2, 1, "", "GaLoreProjector"]], "bitorch_engine.optim.galore_projector.GaLoreProjector": [[128, 3, 1, "", "__init__"]], "bitorch_engine.utils": [[130, 0, 0, "-", "arch_helper"], [134, 0, 0, "-", "convert"], [141, 0, 0, "-", "cpp_extension"], [144, 0, 0, "-", "cuda_extension"], [148, 0, 0, "-", "cutlass_path"], [153, 0, 0, "-", "mlx_extension"], [155, 0, 0, "-", "mlx_path"], [159, 0, 0, "-", "model_helper"], [171, 0, 0, "-", "quant_operators"], [179, 0, 0, "-", "safe_import"]], "bitorch_engine.utils.arch_helper": [[131, 2, 1, "", "ARCH_CPU"], [132, 1, 1, "", "check_cpu_instruction_support"], [133, 2, 1, "", "linux_arch_ident"]], "bitorch_engine.utils.arch_helper.linux_arch_ident": [[133, 3, 1, "", "get_arm_model"], [133, 3, 1, "", "is_arm"]], "bitorch_engine.utils.convert": [[135, 1, 1, "", "collect_layers"], [136, 1, 1, "", "get_mpq_config"], [137, 1, 1, "", "quantize_linear_with_binary_linear_cuda"], [138, 1, 1, "", "quantize_linear_with_mpq_linear_cuda"], [139, 1, 1, "", "quantize_linear_with_q4_linear_cutlass"], [140, 1, 1, "", "replace_layers"]], "bitorch_engine.utils.cpp_extension": [[142, 1, 1, "", "get_cpp_extension"], [143, 1, 1, "", "get_kwargs"]], "bitorch_engine.utils.cuda_extension": [[145, 1, 1, "", "gcc_version"], [146, 1, 1, "", "get_cuda_extension"], [147, 1, 1, "", "get_kwargs"]], "bitorch_engine.utils.cutlass_path": [[149, 1, 1, "", "check_path"], [150, 1, 1, "", "find_cutlass"], [151, 1, 1, "", "get_cutlass_include_path"], [152, 1, 1, "", "is_cutlass_available"]], "bitorch_engine.utils.mlx_extension": [[154, 1, 1, "", "get_mlx_extension"]], "bitorch_engine.utils.mlx_path": [[156, 1, 1, "", "get_mlx_include_path"], [157, 1, 1, "", "get_mlx_lib_path"], [158, 1, 1, "", "is_mlx_available"]], "bitorch_engine.utils.model_helper": [[160, 1, 1, "", "binary_matmul_forward_post_processing"], [161, 1, 1, "", "flatten_x"], [162, 1, 1, "", "init_weight"], [163, 1, 1, "", "load_checkpoint"], [164, 1, 1, "", "pack_bie_layers"], [165, 1, 1, "", "pad_embedding_dim"], [166, 1, 1, "", "pad_last_2_dims_to_multiple_of_128"], [167, 1, 1, "", "prepare_bie_layers"], [168, 1, 1, "", "qweight_update_fn"], [169, 1, 1, "", "save_checkpoint"], [170, 1, 1, "", "unflatten_x"]], "bitorch_engine.utils.quant_operators": [[172, 1, 1, "", "bit_set"], [173, 1, 1, "", "get_binary_col"], [174, 1, 1, "", "get_binary_row"], [175, 1, 1, "", "gptq_stype_unpacking"], [176, 1, 1, "", "nv_tensor_quant"], [177, 1, 1, "", "q4_quantization"], [178, 1, 1, "", "q8_quantization"]], "bitorch_engine.utils.safe_import": [[180, 2, 1, "", "ExtensionModulePlaceholder"], [181, 1, 1, "", "import_extension"]], "bitorch_engine.utils.safe_import.ExtensionModulePlaceholder": [[180, 3, 1, "", "__getattr__"], [180, 3, 1, "id0", "__init__"], [180, 3, 1, "", "__setattr__"], [180, 4, 1, "", "_name"]]}, "objtypes": {"0": "py:module", "1": "py:function", "2": "py:class", "3": "py:method", "4": "py:attribute", "5": "py:property"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "function", "Python function"], "2": ["py", "class", "Python class"], "3": ["py", "method", "Python method"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "property", "Python property"]}, "titleterms": {"bitorch_engin": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181], "extens": [3, 4, 16, 17, 22, 23, 32, 33, 53, 54, 61, 62, 67, 68, 82, 83, 95, 96, 111, 112, 182], "function": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "cuda": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 58, 59, 60, 61, 62, 63, 64, 65, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 182, 185], "get_ext": [4, 17, 23, 33, 54, 62, 68, 83, 96, 112], "fp32toint4": 6, "q4_pack_tensor": 7, "q4_unpack_and_scaling_tensor": 8, "q4_unpack_tensor": 9, "tensor_to_packed_uint8": 10, "unpack_uint8_tensor": 11, "layer": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122], "qconv": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39], "binari": [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 119, 120, 121, 122], "cpp": [15, 16, 17, 18, 19, 20, 52, 53, 54, 55, 56, 57], "binaryconv2dcpp": 19, "binaryconv2dforward": [20, 26], "cutlass": [21, 22, 23, 24, 25, 26, 31, 32, 33, 34, 35, 36, 66, 67, 68, 69, 70, 71, 72, 73, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104], "binaryconv2dcutlass": 25, "binaryconv2dbas": 28, "binaryconvparamet": 29, "nbit": [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], "q4conv2dcutlass": 35, "q4conv2dcutlassforward": 36, "nbitconv2dbas": 38, "nbitconvparamet": 39, "qembed": [40, 41, 42, 43, 44, 45, 46, 47], "binaryembeddingbag": 43, "binaryembeddingbagforward": 44, "binaryembeddingcuda": 45, "binaryembeddingforward": 46, "binaryembeddingparamet": 47, "qlinear": [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "binary_implement": [50, 51], "binarylinearimplementationmixin": 51, "binarylinearcpp": 56, "binarylinearforward": [57, 65, 71], "bmm": [59, 60], "binarylinearcuda": 64, "binarylinearcutlass": 70, "binarymatmul": 72, "binarymatmulfunct": 73, "get_best_binary_implement": 74, "binarylinearbas": 76, "binarylinearparamet": 77, "qlinearinf": 79, "mbwq_layer": [84, 85, 86], "mbwqlinearcuda": 85, "mbwqlinearcudafunct": 86, "mpq_layer": [87, 88, 89, 113, 114, 115], "mpqlinearcuda": 88, "mpqlinearcudafunct": 89, "util": [90, 91, 92, 93, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181], "make_group_map": 91, "pack_fp_weight": 92, "unpack_qweight": 93, "q4_layer": [97, 98, 99, 100, 101], "q4linearcutlass": 98, "q4linearfunct": 99, "q4matmul": 100, "q4matmulfunct": 101, "q8_layer": [102, 103, 104], "q8linearcutlass": 103, "q8linearfunct": 104, "mpqlinearbas": 106, "mpqweightparamet": 107, "nbitlinearbas": 108, "nbitlinearparamet": 109, "mp": [110, 111, 112, 113, 114, 115], "mpqlinearmlx": 114, "mpqlinearmlxfunct": 115, "qlinear_implement": [116, 117], "qlinearimplementationmixin": 117, "qmha": [118, 119, 120, 121, 122], "bmha": 121, "learnablebia": 122, "optim": [123, 124, 125, 126, 127, 128], "diode_beta": [124, 125, 126], "diodemix": 125, "arch_help": [130, 131, 132, 133], "arch_cpu": 131, "check_cpu_instruction_support": 132, "linux_arch_id": 133, "convert": [134, 135, 136, 137, 138, 139, 140], "collect_lay": 135, "finalize_quantized_lay": [], "quantize_linear_with_mpq_linear_cuda": 138, "cpp_extens": [141, 142, 143], "get_cpp_extens": 142, "get_kwarg": [143, 147], "cuda_extens": [144, 145, 146, 147], "gcc_version": 145, "get_cuda_extens": 146, "cutlass_path": [148, 149, 150, 151, 152], "check_path": 149, "find_cutlass": 150, "get_cutlass_include_path": 151, "is_cutlass_avail": 152, "mlx_extens": [153, 154], "get_mlx_extens": 154, "mlx_path": [155, 156, 157, 158], "get_mlx_include_path": 156, "get_mlx_lib_path": 157, "is_mlx_avail": 158, "model_help": [159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170], "binary_matmul_forward_post_process": 160, "flatten_x": 161, "init_weight": 162, "load_checkpoint": 163, "pack_bie_lay": 164, "pad_embedding_dim": 165, "pad_last_2_dims_to_multiple_of_128": 166, "prepare_bie_lay": 167, "qweight_update_fn": 168, "save_checkpoint": 169, "unflatten_x": 170, "quant_oper": [171, 172, 173, 174, 175, 176, 177, 178], "bit_set": 172, "get_binary_col": 173, "get_binary_row": 174, "nv_tensor_qu": 176, "q4_quantiz": 177, "q8_quantiz": 178, "safe_import": [179, 180, 181], "extensionmoduleplacehold": 180, "import_extens": 181, "build": 182, "doc": [], "full": 183, "document": [183, 184], "welcom": 184, "bitorch": 184, "engin": 184, "": 184, "content": 184, "indic": 184, "tabl": 184, "instal": 185, "from": [], "sourc": [], "docker": 185, "imag": [], "specif": 182, "architectur": 182, "maco": 185, "instruct": [], "check_pytorch_vers": 126, "galore_projector": [127, 128], "galoreprojector": 128, "get_mpq_config": 136, "quantize_linear_with_binary_linear_cuda": 137, "quantize_linear_with_q4_linear_cutlass": 139, "replace_lay": 140, "gptq_stype_unpack": 175, "option": 182, "forc": 182, "modul": 182, "conda": 185, "linux": 185, "mlx": 185}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx.ext.intersphinx": 1, "sphinx": 60}, "alltitles": {"bitorch_engine": [[0, "module-bitorch_engine"]], "bitorch_engine.functions": [[1, "module-bitorch_engine.functions"]], "bitorch_engine.functions.cuda": [[2, "module-bitorch_engine.functions.cuda"]], "bitorch_engine.functions.cuda.extension": [[3, "module-bitorch_engine.functions.cuda.extension"]], "bitorch_engine.functions.cuda.extension.get_ext": [[4, "bitorch-engine-functions-cuda-extension-get-ext"]], "bitorch_engine.functions.cuda.functions": [[5, "module-bitorch_engine.functions.cuda.functions"]], "bitorch_engine.functions.cuda.functions.fp32toint4": [[6, "bitorch-engine-functions-cuda-functions-fp32toint4"]], "bitorch_engine.functions.cuda.functions.q4_pack_tensor": [[7, "bitorch-engine-functions-cuda-functions-q4-pack-tensor"]], "bitorch_engine.functions.cuda.functions.q4_unpack_and_scaling_tensor": [[8, "bitorch-engine-functions-cuda-functions-q4-unpack-and-scaling-tensor"]], "bitorch_engine.functions.cuda.functions.q4_unpack_tensor": [[9, "bitorch-engine-functions-cuda-functions-q4-unpack-tensor"]], "bitorch_engine.functions.cuda.functions.tensor_to_packed_uint8": [[10, "bitorch-engine-functions-cuda-functions-tensor-to-packed-uint8"]], "bitorch_engine.functions.cuda.functions.unpack_uint8_tensor": [[11, "bitorch-engine-functions-cuda-functions-unpack-uint8-tensor"]], "bitorch_engine.layers": [[12, "module-bitorch_engine.layers"]], "bitorch_engine.layers.qconv": [[13, "module-bitorch_engine.layers.qconv"]], "bitorch_engine.layers.qconv.binary": [[14, "module-bitorch_engine.layers.qconv.binary"]], "bitorch_engine.layers.qconv.binary.cpp": [[15, "module-bitorch_engine.layers.qconv.binary.cpp"]], "bitorch_engine.layers.qconv.binary.cpp.extension": [[16, "module-bitorch_engine.layers.qconv.binary.cpp.extension"]], "bitorch_engine.layers.qconv.binary.cpp.extension.get_ext": [[17, "bitorch-engine-layers-qconv-binary-cpp-extension-get-ext"]], "bitorch_engine.layers.qconv.binary.cpp.layer": [[18, "module-bitorch_engine.layers.qconv.binary.cpp.layer"]], "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP": [[19, "bitorch-engine-layers-qconv-binary-cpp-layer-binaryconv2dcpp"]], "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dForward": [[20, "bitorch-engine-layers-qconv-binary-cpp-layer-binaryconv2dforward"]], "bitorch_engine.layers.qconv.binary.cutlass": [[21, "module-bitorch_engine.layers.qconv.binary.cutlass"]], "bitorch_engine.layers.qconv.binary.cutlass.extension": [[22, "module-bitorch_engine.layers.qconv.binary.cutlass.extension"]], "bitorch_engine.layers.qconv.binary.cutlass.extension.get_ext": [[23, "bitorch-engine-layers-qconv-binary-cutlass-extension-get-ext"]], "bitorch_engine.layers.qconv.binary.cutlass.layer": [[24, "module-bitorch_engine.layers.qconv.binary.cutlass.layer"]], "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass": [[25, "bitorch-engine-layers-qconv-binary-cutlass-layer-binaryconv2dcutlass"]], "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dForward": [[26, "bitorch-engine-layers-qconv-binary-cutlass-layer-binaryconv2dforward"]], "bitorch_engine.layers.qconv.binary.layer": [[27, "module-bitorch_engine.layers.qconv.binary.layer"]], "bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase": [[28, "bitorch-engine-layers-qconv-binary-layer-binaryconv2dbase"]], "bitorch_engine.layers.qconv.binary.layer.BinaryConvParameter": [[29, "bitorch-engine-layers-qconv-binary-layer-binaryconvparameter"]], "bitorch_engine.layers.qconv.nbit": [[30, "module-bitorch_engine.layers.qconv.nbit"]], "bitorch_engine.layers.qconv.nbit.cutlass": [[31, "module-bitorch_engine.layers.qconv.nbit.cutlass"]], "bitorch_engine.layers.qconv.nbit.cutlass.extension": [[32, "module-bitorch_engine.layers.qconv.nbit.cutlass.extension"]], "bitorch_engine.layers.qconv.nbit.cutlass.extension.get_ext": [[33, "bitorch-engine-layers-qconv-nbit-cutlass-extension-get-ext"]], "bitorch_engine.layers.qconv.nbit.cutlass.layer": [[34, "module-bitorch_engine.layers.qconv.nbit.cutlass.layer"]], "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass": [[35, "bitorch-engine-layers-qconv-nbit-cutlass-layer-q4conv2dcutlass"]], "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward": [[36, "bitorch-engine-layers-qconv-nbit-cutlass-layer-q4conv2dcutlassforward"]], "bitorch_engine.layers.qconv.nbit.layer": [[37, "module-bitorch_engine.layers.qconv.nbit.layer"]], "bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase": [[38, "bitorch-engine-layers-qconv-nbit-layer-nbitconv2dbase"]], "bitorch_engine.layers.qconv.nbit.layer.nBitConvParameter": [[39, "bitorch-engine-layers-qconv-nbit-layer-nbitconvparameter"]], "bitorch_engine.layers.qembedding": [[40, "module-bitorch_engine.layers.qembedding"]], "bitorch_engine.layers.qembedding.binary": [[41, "module-bitorch_engine.layers.qembedding.binary"]], "bitorch_engine.layers.qembedding.binary.layer": [[42, "module-bitorch_engine.layers.qembedding.binary.layer"]], "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag": [[43, "bitorch-engine-layers-qembedding-binary-layer-binaryembeddingbag"]], "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward": [[44, "bitorch-engine-layers-qembedding-binary-layer-binaryembeddingbagforward"]], "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda": [[45, "bitorch-engine-layers-qembedding-binary-layer-binaryembeddingcuda"]], "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingForward": [[46, "bitorch-engine-layers-qembedding-binary-layer-binaryembeddingforward"]], "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingParameter": [[47, "bitorch-engine-layers-qembedding-binary-layer-binaryembeddingparameter"]], "bitorch_engine.layers.qlinear": [[48, "module-bitorch_engine.layers.qlinear"]], "bitorch_engine.layers.qlinear.binary": [[49, "module-bitorch_engine.layers.qlinear.binary"]], "bitorch_engine.layers.qlinear.binary.binary_implementation": [[50, "module-bitorch_engine.layers.qlinear.binary.binary_implementation"]], "bitorch_engine.layers.qlinear.binary.binary_implementation.BinaryLinearImplementationMixin": [[51, "bitorch-engine-layers-qlinear-binary-binary-implementation-binarylinearimplementationmixin"]], "bitorch_engine.layers.qlinear.binary.cpp": [[52, "module-bitorch_engine.layers.qlinear.binary.cpp"]], "bitorch_engine.layers.qlinear.binary.cpp.extension": [[53, "module-bitorch_engine.layers.qlinear.binary.cpp.extension"]], "bitorch_engine.layers.qlinear.binary.cpp.extension.get_ext": [[54, "bitorch-engine-layers-qlinear-binary-cpp-extension-get-ext"]], "bitorch_engine.layers.qlinear.binary.cpp.layer": [[55, "module-bitorch_engine.layers.qlinear.binary.cpp.layer"]], "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP": [[56, "bitorch-engine-layers-qlinear-binary-cpp-layer-binarylinearcpp"]], "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearForward": [[57, "bitorch-engine-layers-qlinear-binary-cpp-layer-binarylinearforward"]], "bitorch_engine.layers.qlinear.binary.cuda": [[58, "module-bitorch_engine.layers.qlinear.binary.cuda"]], "bitorch_engine.layers.qlinear.binary.cuda.bmm": [[59, "module-bitorch_engine.layers.qlinear.binary.cuda.bmm"]], "bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM": [[60, "bitorch-engine-layers-qlinear-binary-cuda-bmm-bmm"]], "bitorch_engine.layers.qlinear.binary.cuda.extension": [[61, "module-bitorch_engine.layers.qlinear.binary.cuda.extension"]], "bitorch_engine.layers.qlinear.binary.cuda.extension.get_ext": [[62, "bitorch-engine-layers-qlinear-binary-cuda-extension-get-ext"]], "bitorch_engine.layers.qlinear.binary.cuda.layer": [[63, "module-bitorch_engine.layers.qlinear.binary.cuda.layer"]], "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda": [[64, "bitorch-engine-layers-qlinear-binary-cuda-layer-binarylinearcuda"]], "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward": [[65, "bitorch-engine-layers-qlinear-binary-cuda-layer-binarylinearforward"]], "bitorch_engine.layers.qlinear.binary.cutlass": [[66, "module-bitorch_engine.layers.qlinear.binary.cutlass"]], "bitorch_engine.layers.qlinear.binary.cutlass.extension": [[67, "module-bitorch_engine.layers.qlinear.binary.cutlass.extension"]], "bitorch_engine.layers.qlinear.binary.cutlass.extension.get_ext": [[68, "bitorch-engine-layers-qlinear-binary-cutlass-extension-get-ext"]], "bitorch_engine.layers.qlinear.binary.cutlass.layer": [[69, "module-bitorch_engine.layers.qlinear.binary.cutlass.layer"]], "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass": [[70, "bitorch-engine-layers-qlinear-binary-cutlass-layer-binarylinearcutlass"]], "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward": [[71, "bitorch-engine-layers-qlinear-binary-cutlass-layer-binarylinearforward"]], "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul": [[72, "bitorch-engine-layers-qlinear-binary-cutlass-layer-binarymatmul"]], "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMulFunction": [[73, "bitorch-engine-layers-qlinear-binary-cutlass-layer-binarymatmulfunction"]], "bitorch_engine.layers.qlinear.binary.get_best_binary_implementation": [[74, "bitorch-engine-layers-qlinear-binary-get-best-binary-implementation"]], "bitorch_engine.layers.qlinear.binary.layer": [[75, "module-bitorch_engine.layers.qlinear.binary.layer"]], "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase": [[76, "bitorch-engine-layers-qlinear-binary-layer-binarylinearbase"]], "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearParameter": [[77, "bitorch-engine-layers-qlinear-binary-layer-binarylinearparameter"]], "bitorch_engine.layers.qlinear.layer": [[78, "module-bitorch_engine.layers.qlinear.layer"]], "bitorch_engine.layers.qlinear.layer.QLinearInf": [[79, "bitorch-engine-layers-qlinear-layer-qlinearinf"]], "bitorch_engine.layers.qlinear.nbit": [[80, "module-bitorch_engine.layers.qlinear.nbit"]], "bitorch_engine.layers.qlinear.nbit.cuda": [[81, "module-bitorch_engine.layers.qlinear.nbit.cuda"]], "bitorch_engine.layers.qlinear.nbit.cuda.extension": [[82, "module-bitorch_engine.layers.qlinear.nbit.cuda.extension"]], "bitorch_engine.layers.qlinear.nbit.cuda.extension.get_ext": [[83, "bitorch-engine-layers-qlinear-nbit-cuda-extension-get-ext"]], "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer": [[84, "module-bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer"]], "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda": [[85, "bitorch-engine-layers-qlinear-nbit-cuda-mbwq-layer-mbwqlinearcuda"]], "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction": [[86, "bitorch-engine-layers-qlinear-nbit-cuda-mbwq-layer-mbwqlinearcudafunction"]], "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer": [[87, "module-bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer"]], "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda": [[88, "bitorch-engine-layers-qlinear-nbit-cuda-mpq-layer-mpqlinearcuda"]], "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCudaFunction": [[89, "bitorch-engine-layers-qlinear-nbit-cuda-mpq-layer-mpqlinearcudafunction"]], "bitorch_engine.layers.qlinear.nbit.cuda.utils": [[90, "module-bitorch_engine.layers.qlinear.nbit.cuda.utils"]], "bitorch_engine.layers.qlinear.nbit.cuda.utils.make_group_map": [[91, "bitorch-engine-layers-qlinear-nbit-cuda-utils-make-group-map"]], "bitorch_engine.layers.qlinear.nbit.cuda.utils.pack_fp_weight": [[92, "bitorch-engine-layers-qlinear-nbit-cuda-utils-pack-fp-weight"]], "bitorch_engine.layers.qlinear.nbit.cuda.utils.unpack_qweight": [[93, "bitorch-engine-layers-qlinear-nbit-cuda-utils-unpack-qweight"]], "bitorch_engine.layers.qlinear.nbit.cutlass": [[94, "module-bitorch_engine.layers.qlinear.nbit.cutlass"]], "bitorch_engine.layers.qlinear.nbit.cutlass.extension": [[95, "module-bitorch_engine.layers.qlinear.nbit.cutlass.extension"]], "bitorch_engine.layers.qlinear.nbit.cutlass.extension.get_ext": [[96, "bitorch-engine-layers-qlinear-nbit-cutlass-extension-get-ext"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer": [[97, "module-bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass": [[98, "bitorch-engine-layers-qlinear-nbit-cutlass-q4-layer-q4linearcutlass"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearFunction": [[99, "bitorch-engine-layers-qlinear-nbit-cutlass-q4-layer-q4linearfunction"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul": [[100, "bitorch-engine-layers-qlinear-nbit-cutlass-q4-layer-q4matmul"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMulFunction": [[101, "bitorch-engine-layers-qlinear-nbit-cutlass-q4-layer-q4matmulfunction"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer": [[102, "module-bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass": [[103, "bitorch-engine-layers-qlinear-nbit-cutlass-q8-layer-q8linearcutlass"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearFunction": [[104, "bitorch-engine-layers-qlinear-nbit-cutlass-q8-layer-q8linearfunction"]], "bitorch_engine.layers.qlinear.nbit.layer": [[105, "module-bitorch_engine.layers.qlinear.nbit.layer"]], "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase": [[106, "bitorch-engine-layers-qlinear-nbit-layer-mpqlinearbase"]], "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter": [[107, "bitorch-engine-layers-qlinear-nbit-layer-mpqweightparameter"]], "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase": [[108, "bitorch-engine-layers-qlinear-nbit-layer-nbitlinearbase"]], "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearParameter": [[109, "bitorch-engine-layers-qlinear-nbit-layer-nbitlinearparameter"]], "bitorch_engine.layers.qlinear.nbit.mps": [[110, "module-bitorch_engine.layers.qlinear.nbit.mps"]], "bitorch_engine.layers.qlinear.nbit.mps.extension": [[111, "module-bitorch_engine.layers.qlinear.nbit.mps.extension"]], "bitorch_engine.layers.qlinear.nbit.mps.extension.get_ext": [[112, "bitorch-engine-layers-qlinear-nbit-mps-extension-get-ext"]], "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer": [[113, "module-bitorch_engine.layers.qlinear.nbit.mps.mpq_layer"]], "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx": [[114, "bitorch-engine-layers-qlinear-nbit-mps-mpq-layer-mpqlinearmlx"]], "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlxFunction": [[115, "bitorch-engine-layers-qlinear-nbit-mps-mpq-layer-mpqlinearmlxfunction"]], "bitorch_engine.layers.qlinear.qlinear_implementation": [[116, "module-bitorch_engine.layers.qlinear.qlinear_implementation"]], "bitorch_engine.layers.qlinear.qlinear_implementation.QLinearImplementationMixin": [[117, "bitorch-engine-layers-qlinear-qlinear-implementation-qlinearimplementationmixin"]], "bitorch_engine.layers.qmha": [[118, "module-bitorch_engine.layers.qmha"]], "bitorch_engine.layers.qmha.binary": [[119, "module-bitorch_engine.layers.qmha.binary"]], "bitorch_engine.layers.qmha.binary.layer": [[120, "module-bitorch_engine.layers.qmha.binary.layer"]], "bitorch_engine.layers.qmha.binary.layer.BMHA": [[121, "bitorch-engine-layers-qmha-binary-layer-bmha"]], "bitorch_engine.layers.qmha.binary.layer.LearnableBias": [[122, "bitorch-engine-layers-qmha-binary-layer-learnablebias"]], "bitorch_engine.optim": [[123, "module-bitorch_engine.optim"]], "bitorch_engine.optim.diode_beta": [[124, "module-bitorch_engine.optim.diode_beta"]], "bitorch_engine.optim.diode_beta.DiodeMix": [[125, "bitorch-engine-optim-diode-beta-diodemix"]], "bitorch_engine.optim.diode_beta.check_pytorch_version": [[126, "bitorch-engine-optim-diode-beta-check-pytorch-version"]], "bitorch_engine.utils": [[129, "module-bitorch_engine.utils"]], "bitorch_engine.utils.arch_helper": [[130, "module-bitorch_engine.utils.arch_helper"]], "bitorch_engine.utils.arch_helper.ARCH_CPU": [[131, "bitorch-engine-utils-arch-helper-arch-cpu"]], "bitorch_engine.utils.arch_helper.check_cpu_instruction_support": [[132, "bitorch-engine-utils-arch-helper-check-cpu-instruction-support"]], "bitorch_engine.utils.arch_helper.linux_arch_ident": [[133, "bitorch-engine-utils-arch-helper-linux-arch-ident"]], "bitorch_engine.utils.convert": [[134, "module-bitorch_engine.utils.convert"]], "bitorch_engine.utils.convert.collect_layers": [[135, "bitorch-engine-utils-convert-collect-layers"]], "bitorch_engine.utils.convert.get_mpq_config": [[136, "bitorch-engine-utils-convert-get-mpq-config"]], "bitorch_engine.utils.convert.quantize_linear_with_binary_linear_cuda": [[137, "bitorch-engine-utils-convert-quantize-linear-with-binary-linear-cuda"]], "bitorch_engine.utils.convert.quantize_linear_with_mpq_linear_cuda": [[138, "bitorch-engine-utils-convert-quantize-linear-with-mpq-linear-cuda"]], "bitorch_engine.utils.convert.quantize_linear_with_q4_linear_cutlass": [[139, "bitorch-engine-utils-convert-quantize-linear-with-q4-linear-cutlass"]], "bitorch_engine.utils.convert.replace_layers": [[140, "bitorch-engine-utils-convert-replace-layers"]], "bitorch_engine.utils.cpp_extension": [[141, "module-bitorch_engine.utils.cpp_extension"]], "bitorch_engine.utils.cpp_extension.get_cpp_extension": [[142, "bitorch-engine-utils-cpp-extension-get-cpp-extension"]], "bitorch_engine.utils.cpp_extension.get_kwargs": [[143, "bitorch-engine-utils-cpp-extension-get-kwargs"]], "bitorch_engine.utils.cuda_extension": [[144, "module-bitorch_engine.utils.cuda_extension"]], "bitorch_engine.utils.cuda_extension.gcc_version": [[145, "bitorch-engine-utils-cuda-extension-gcc-version"]], "bitorch_engine.utils.cuda_extension.get_cuda_extension": [[146, "bitorch-engine-utils-cuda-extension-get-cuda-extension"]], "bitorch_engine.utils.cuda_extension.get_kwargs": [[147, "bitorch-engine-utils-cuda-extension-get-kwargs"]], "bitorch_engine.utils.cutlass_path": [[148, "module-bitorch_engine.utils.cutlass_path"]], "bitorch_engine.utils.cutlass_path.check_path": [[149, "bitorch-engine-utils-cutlass-path-check-path"]], "bitorch_engine.utils.cutlass_path.find_cutlass": [[150, "bitorch-engine-utils-cutlass-path-find-cutlass"]], "bitorch_engine.utils.cutlass_path.get_cutlass_include_path": [[151, "bitorch-engine-utils-cutlass-path-get-cutlass-include-path"]], "bitorch_engine.utils.cutlass_path.is_cutlass_available": [[152, "bitorch-engine-utils-cutlass-path-is-cutlass-available"]], "bitorch_engine.utils.mlx_extension": [[153, "module-bitorch_engine.utils.mlx_extension"]], "bitorch_engine.utils.mlx_extension.get_mlx_extension": [[154, "bitorch-engine-utils-mlx-extension-get-mlx-extension"]], "bitorch_engine.utils.mlx_path": [[155, "module-bitorch_engine.utils.mlx_path"]], "bitorch_engine.utils.mlx_path.get_mlx_include_path": [[156, "bitorch-engine-utils-mlx-path-get-mlx-include-path"]], "bitorch_engine.utils.mlx_path.get_mlx_lib_path": [[157, "bitorch-engine-utils-mlx-path-get-mlx-lib-path"]], "bitorch_engine.utils.mlx_path.is_mlx_available": [[158, "bitorch-engine-utils-mlx-path-is-mlx-available"]], "bitorch_engine.utils.model_helper": [[159, "module-bitorch_engine.utils.model_helper"]], "bitorch_engine.utils.model_helper.binary_matmul_forward_post_processing": [[160, "bitorch-engine-utils-model-helper-binary-matmul-forward-post-processing"]], "bitorch_engine.utils.model_helper.flatten_x": [[161, "bitorch-engine-utils-model-helper-flatten-x"]], "bitorch_engine.utils.model_helper.init_weight": [[162, "bitorch-engine-utils-model-helper-init-weight"]], "bitorch_engine.utils.model_helper.load_checkpoint": [[163, "bitorch-engine-utils-model-helper-load-checkpoint"]], "bitorch_engine.utils.model_helper.pack_bie_layers": [[164, "bitorch-engine-utils-model-helper-pack-bie-layers"]], "bitorch_engine.utils.model_helper.pad_embedding_dim": [[165, "bitorch-engine-utils-model-helper-pad-embedding-dim"]], "bitorch_engine.utils.model_helper.pad_last_2_dims_to_multiple_of_128": [[166, "bitorch-engine-utils-model-helper-pad-last-2-dims-to-multiple-of-128"]], "bitorch_engine.utils.model_helper.prepare_bie_layers": [[167, "bitorch-engine-utils-model-helper-prepare-bie-layers"]], "bitorch_engine.utils.model_helper.qweight_update_fn": [[168, "bitorch-engine-utils-model-helper-qweight-update-fn"]], "bitorch_engine.utils.model_helper.save_checkpoint": [[169, "bitorch-engine-utils-model-helper-save-checkpoint"]], "bitorch_engine.utils.model_helper.unflatten_x": [[170, "bitorch-engine-utils-model-helper-unflatten-x"]], "bitorch_engine.utils.quant_operators": [[171, "module-bitorch_engine.utils.quant_operators"]], "bitorch_engine.utils.quant_operators.bit_set": [[172, "bitorch-engine-utils-quant-operators-bit-set"]], "bitorch_engine.utils.quant_operators.get_binary_col": [[173, "bitorch-engine-utils-quant-operators-get-binary-col"]], "bitorch_engine.utils.quant_operators.get_binary_row": [[174, "bitorch-engine-utils-quant-operators-get-binary-row"]], "bitorch_engine.utils.quant_operators.gptq_stype_unpacking": [[175, "bitorch-engine-utils-quant-operators-gptq-stype-unpacking"]], "bitorch_engine.utils.quant_operators.nv_tensor_quant": [[176, "bitorch-engine-utils-quant-operators-nv-tensor-quant"]], "bitorch_engine.utils.quant_operators.q4_quantization": [[177, "bitorch-engine-utils-quant-operators-q4-quantization"]], "bitorch_engine.utils.quant_operators.q8_quantization": [[178, "bitorch-engine-utils-quant-operators-q8-quantization"]], "bitorch_engine.utils.safe_import": [[179, "module-bitorch_engine.utils.safe_import"]], "bitorch_engine.utils.safe_import.ExtensionModulePlaceholder": [[180, "bitorch-engine-utils-safe-import-extensionmoduleplaceholder"]], "bitorch_engine.utils.safe_import.import_extension": [[181, "bitorch-engine-utils-safe-import-import-extension"]], "Full Documentation": [[183, "full-documentation"]], "Welcome to Bitorch Engine\u2019s documentation!": [[184, "welcome-to-bitorch-engine-s-documentation"]], "Contents:": [[184, null]], "Indices and tables": [[184, "indices-and-tables"]], "bitorch_engine.optim.galore_projector": [[127, "module-bitorch_engine.optim.galore_projector"]], "bitorch_engine.optim.galore_projector.GaLoreProjector": [[128, "bitorch-engine-optim-galore-projector-galoreprojector"]], "Build options": [[182, "build-options"]], "Building Specific Extensions": [[182, "building-specific-extensions"]], "Building for a Specific CUDA Architecture": [[182, "building-for-a-specific-cuda-architecture"]], "Force Building CUDA Modules": [[182, "force-building-cuda-modules"]], "Installation": [[185, "installation"]], "Conda on Linux (with CUDA)": [[185, "conda-on-linux-with-cuda"]], "Docker (with CUDA)": [[185, "docker-with-cuda"]], "Conda on MacOS (with MLX)": [[185, "conda-on-macos-with-mlx"]]}, "indexentries": {"bitorch_engine": [[0, "module-bitorch_engine"]], "module": [[0, "module-bitorch_engine"], [1, "module-bitorch_engine.functions"], [2, "module-bitorch_engine.functions.cuda"], [3, "module-bitorch_engine.functions.cuda.extension"], [5, "module-bitorch_engine.functions.cuda.functions"], [12, "module-bitorch_engine.layers"], [13, "module-bitorch_engine.layers.qconv"], [14, "module-bitorch_engine.layers.qconv.binary"], [15, "module-bitorch_engine.layers.qconv.binary.cpp"], [16, "module-bitorch_engine.layers.qconv.binary.cpp.extension"], [18, "module-bitorch_engine.layers.qconv.binary.cpp.layer"], [21, "module-bitorch_engine.layers.qconv.binary.cutlass"], [22, "module-bitorch_engine.layers.qconv.binary.cutlass.extension"], [24, "module-bitorch_engine.layers.qconv.binary.cutlass.layer"], [27, "module-bitorch_engine.layers.qconv.binary.layer"], [30, "module-bitorch_engine.layers.qconv.nbit"], [31, "module-bitorch_engine.layers.qconv.nbit.cutlass"], [32, "module-bitorch_engine.layers.qconv.nbit.cutlass.extension"], [34, "module-bitorch_engine.layers.qconv.nbit.cutlass.layer"], [37, "module-bitorch_engine.layers.qconv.nbit.layer"], [40, "module-bitorch_engine.layers.qembedding"], [41, "module-bitorch_engine.layers.qembedding.binary"], [42, "module-bitorch_engine.layers.qembedding.binary.layer"], [48, "module-bitorch_engine.layers.qlinear"], [49, "module-bitorch_engine.layers.qlinear.binary"], [50, "module-bitorch_engine.layers.qlinear.binary.binary_implementation"], [52, "module-bitorch_engine.layers.qlinear.binary.cpp"], [53, "module-bitorch_engine.layers.qlinear.binary.cpp.extension"], [55, "module-bitorch_engine.layers.qlinear.binary.cpp.layer"], [58, "module-bitorch_engine.layers.qlinear.binary.cuda"], [59, "module-bitorch_engine.layers.qlinear.binary.cuda.bmm"], [61, "module-bitorch_engine.layers.qlinear.binary.cuda.extension"], [63, "module-bitorch_engine.layers.qlinear.binary.cuda.layer"], [66, "module-bitorch_engine.layers.qlinear.binary.cutlass"], [67, "module-bitorch_engine.layers.qlinear.binary.cutlass.extension"], [69, "module-bitorch_engine.layers.qlinear.binary.cutlass.layer"], [75, "module-bitorch_engine.layers.qlinear.binary.layer"], [78, "module-bitorch_engine.layers.qlinear.layer"], [80, "module-bitorch_engine.layers.qlinear.nbit"], [81, "module-bitorch_engine.layers.qlinear.nbit.cuda"], [82, "module-bitorch_engine.layers.qlinear.nbit.cuda.extension"], [84, "module-bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer"], [87, "module-bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer"], [90, "module-bitorch_engine.layers.qlinear.nbit.cuda.utils"], [94, "module-bitorch_engine.layers.qlinear.nbit.cutlass"], [95, "module-bitorch_engine.layers.qlinear.nbit.cutlass.extension"], [97, "module-bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer"], [102, "module-bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer"], [105, "module-bitorch_engine.layers.qlinear.nbit.layer"], [110, "module-bitorch_engine.layers.qlinear.nbit.mps"], [111, "module-bitorch_engine.layers.qlinear.nbit.mps.extension"], [113, "module-bitorch_engine.layers.qlinear.nbit.mps.mpq_layer"], [116, "module-bitorch_engine.layers.qlinear.qlinear_implementation"], [118, "module-bitorch_engine.layers.qmha"], [119, "module-bitorch_engine.layers.qmha.binary"], [120, "module-bitorch_engine.layers.qmha.binary.layer"], [123, "module-bitorch_engine.optim"], [124, "module-bitorch_engine.optim.diode_beta"], [127, "module-bitorch_engine.optim.galore_projector"], [129, "module-bitorch_engine.utils"], [130, "module-bitorch_engine.utils.arch_helper"], [134, "module-bitorch_engine.utils.convert"], [141, "module-bitorch_engine.utils.cpp_extension"], [144, "module-bitorch_engine.utils.cuda_extension"], [148, "module-bitorch_engine.utils.cutlass_path"], [153, "module-bitorch_engine.utils.mlx_extension"], [155, "module-bitorch_engine.utils.mlx_path"], [159, "module-bitorch_engine.utils.model_helper"], [171, "module-bitorch_engine.utils.quant_operators"], [179, "module-bitorch_engine.utils.safe_import"]], "bitorch_engine.functions": [[1, "module-bitorch_engine.functions"]], "bitorch_engine.functions.cuda": [[2, "module-bitorch_engine.functions.cuda"]], "bitorch_engine.functions.cuda.extension": [[3, "module-bitorch_engine.functions.cuda.extension"]], "get_ext() (in module bitorch_engine.functions.cuda.extension)": [[4, "bitorch_engine.functions.cuda.extension.get_ext"]], "bitorch_engine.functions.cuda.functions": [[5, "module-bitorch_engine.functions.cuda.functions"]], "fp32toint4() (in module bitorch_engine.functions.cuda.functions)": [[6, "bitorch_engine.functions.cuda.functions.fp32toint4"]], "q4_pack_tensor() (in module bitorch_engine.functions.cuda.functions)": [[7, "bitorch_engine.functions.cuda.functions.q4_pack_tensor"]], "q4_unpack_and_scaling_tensor() (in module bitorch_engine.functions.cuda.functions)": [[8, "bitorch_engine.functions.cuda.functions.q4_unpack_and_scaling_tensor"]], "q4_unpack_tensor() (in module bitorch_engine.functions.cuda.functions)": [[9, "bitorch_engine.functions.cuda.functions.q4_unpack_tensor"]], "tensor_to_packed_uint8() (in module bitorch_engine.functions.cuda.functions)": [[10, "bitorch_engine.functions.cuda.functions.tensor_to_packed_uint8"]], "unpack_uint8_tensor() (in module bitorch_engine.functions.cuda.functions)": [[11, "bitorch_engine.functions.cuda.functions.unpack_uint8_tensor"]], "bitorch_engine.layers": [[12, "module-bitorch_engine.layers"]], "bitorch_engine.layers.qconv": [[13, "module-bitorch_engine.layers.qconv"]], "bitorch_engine.layers.qconv.binary": [[14, "module-bitorch_engine.layers.qconv.binary"]], "bitorch_engine.layers.qconv.binary.cpp": [[15, "module-bitorch_engine.layers.qconv.binary.cpp"]], "bitorch_engine.layers.qconv.binary.cpp.extension": [[16, "module-bitorch_engine.layers.qconv.binary.cpp.extension"]], "get_ext() (in module bitorch_engine.layers.qconv.binary.cpp.extension)": [[17, "bitorch_engine.layers.qconv.binary.cpp.extension.get_ext"]], "bitorch_engine.layers.qconv.binary.cpp.layer": [[18, "module-bitorch_engine.layers.qconv.binary.cpp.layer"]], "binaryconv2dcpp (class in bitorch_engine.layers.qconv.binary.cpp.layer)": [[19, "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP"]], "__init__() (bitorch_engine.layers.qconv.binary.cpp.layer.binaryconv2dcpp method)": [[19, "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP.__init__"]], "bits_binary_word (bitorch_engine.layers.qconv.binary.cpp.layer.binaryconv2dcpp attribute)": [[19, "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP.bits_binary_word"]], "forward() (bitorch_engine.layers.qconv.binary.cpp.layer.binaryconv2dcpp method)": [[19, "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP.forward"]], "generate_quantized_weight() (bitorch_engine.layers.qconv.binary.cpp.layer.binaryconv2dcpp method)": [[19, "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP.generate_quantized_weight"]], "prepare_params() (bitorch_engine.layers.qconv.binary.cpp.layer.binaryconv2dcpp method)": [[19, "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP.prepare_params"]], "binaryconv2dforward (class in bitorch_engine.layers.qconv.binary.cpp.layer)": [[20, "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dForward"]], "forward() (bitorch_engine.layers.qconv.binary.cpp.layer.binaryconv2dforward static method)": [[20, "bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dForward.forward"]], "bitorch_engine.layers.qconv.binary.cutlass": [[21, "module-bitorch_engine.layers.qconv.binary.cutlass"]], "bitorch_engine.layers.qconv.binary.cutlass.extension": [[22, "module-bitorch_engine.layers.qconv.binary.cutlass.extension"]], "get_ext() (in module bitorch_engine.layers.qconv.binary.cutlass.extension)": [[23, "bitorch_engine.layers.qconv.binary.cutlass.extension.get_ext"]], "bitorch_engine.layers.qconv.binary.cutlass.layer": [[24, "module-bitorch_engine.layers.qconv.binary.cutlass.layer"]], "binaryconv2dcutlass (class in bitorch_engine.layers.qconv.binary.cutlass.layer)": [[25, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass"]], "__init__() (bitorch_engine.layers.qconv.binary.cutlass.layer.binaryconv2dcutlass method)": [[25, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.__init__"]], "bias_a (bitorch_engine.layers.qconv.binary.cutlass.layer.binaryconv2dcutlass attribute)": [[25, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.bias_a"]], "bits_binary_word (bitorch_engine.layers.qconv.binary.cutlass.layer.binaryconv2dcutlass attribute)": [[25, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.bits_binary_word"]], "forward() (bitorch_engine.layers.qconv.binary.cutlass.layer.binaryconv2dcutlass method)": [[25, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.forward"]], "generate_quantized_weight() (bitorch_engine.layers.qconv.binary.cutlass.layer.binaryconv2dcutlass method)": [[25, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.generate_quantized_weight"]], "prepare_params() (bitorch_engine.layers.qconv.binary.cutlass.layer.binaryconv2dcutlass method)": [[25, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.prepare_params"]], "scale_a (bitorch_engine.layers.qconv.binary.cutlass.layer.binaryconv2dcutlass attribute)": [[25, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.scale_a"]], "scale_w (bitorch_engine.layers.qconv.binary.cutlass.layer.binaryconv2dcutlass attribute)": [[25, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.scale_w"]], "set_activation() (bitorch_engine.layers.qconv.binary.cutlass.layer.binaryconv2dcutlass method)": [[25, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.set_activation"]], "set_weight_data() (bitorch_engine.layers.qconv.binary.cutlass.layer.binaryconv2dcutlass method)": [[25, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.set_weight_data"]], "binaryconv2dforward (class in bitorch_engine.layers.qconv.binary.cutlass.layer)": [[26, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dForward"]], "backward() (bitorch_engine.layers.qconv.binary.cutlass.layer.binaryconv2dforward static method)": [[26, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dForward.backward"]], "forward() (bitorch_engine.layers.qconv.binary.cutlass.layer.binaryconv2dforward static method)": [[26, "bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dForward.forward"]], "bitorch_engine.layers.qconv.binary.layer": [[27, "module-bitorch_engine.layers.qconv.binary.layer"]], "binaryconv2dbase (class in bitorch_engine.layers.qconv.binary.layer)": [[28, "bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase"]], "__init__() (bitorch_engine.layers.qconv.binary.layer.binaryconv2dbase method)": [[28, "bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.__init__"]], "generate_quantized_weight() (bitorch_engine.layers.qconv.binary.layer.binaryconv2dbase method)": [[28, "bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.generate_quantized_weight"]], "opt_weight (bitorch_engine.layers.qconv.binary.layer.binaryconv2dbase property)": [[28, "bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.opt_weight"]], "prepare_params() (bitorch_engine.layers.qconv.binary.layer.binaryconv2dbase method)": [[28, "bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.prepare_params"]], "reset_parameters() (bitorch_engine.layers.qconv.binary.layer.binaryconv2dbase method)": [[28, "bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.reset_parameters"]], "set_bits_binary_word() (bitorch_engine.layers.qconv.binary.layer.binaryconv2dbase method)": [[28, "bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.set_bits_binary_word"]], "set_quantized_weight_data() (bitorch_engine.layers.qconv.binary.layer.binaryconv2dbase method)": [[28, "bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.set_quantized_weight_data"]], "set_weight_data() (bitorch_engine.layers.qconv.binary.layer.binaryconv2dbase method)": [[28, "bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.set_weight_data"]], "binaryconvparameter (class in bitorch_engine.layers.qconv.binary.layer)": [[29, "bitorch_engine.layers.qconv.binary.layer.BinaryConvParameter"]], "update() (bitorch_engine.layers.qconv.binary.layer.binaryconvparameter static method)": [[29, "bitorch_engine.layers.qconv.binary.layer.BinaryConvParameter.update"]], "bitorch_engine.layers.qconv.nbit": [[30, "module-bitorch_engine.layers.qconv.nbit"]], "bitorch_engine.layers.qconv.nbit.cutlass": [[31, "module-bitorch_engine.layers.qconv.nbit.cutlass"]], "bitorch_engine.layers.qconv.nbit.cutlass.extension": [[32, "module-bitorch_engine.layers.qconv.nbit.cutlass.extension"]], "get_ext() (in module bitorch_engine.layers.qconv.nbit.cutlass.extension)": [[33, "bitorch_engine.layers.qconv.nbit.cutlass.extension.get_ext"]], "bitorch_engine.layers.qconv.nbit.cutlass.layer": [[34, "module-bitorch_engine.layers.qconv.nbit.cutlass.layer"]], "q4conv2dcutlass (class in bitorch_engine.layers.qconv.nbit.cutlass.layer)": [[35, "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass"]], "__init__() (bitorch_engine.layers.qconv.nbit.cutlass.layer.q4conv2dcutlass method)": [[35, "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.__init__"]], "bias_a (bitorch_engine.layers.qconv.nbit.cutlass.layer.q4conv2dcutlass attribute)": [[35, "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.bias_a"]], "eps (bitorch_engine.layers.qconv.nbit.cutlass.layer.q4conv2dcutlass attribute)": [[35, "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.eps"]], "forward() (bitorch_engine.layers.qconv.nbit.cutlass.layer.q4conv2dcutlass method)": [[35, "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.forward"]], "generate_quantized_weight() (bitorch_engine.layers.qconv.nbit.cutlass.layer.q4conv2dcutlass method)": [[35, "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.generate_quantized_weight"]], "prepare_params() (bitorch_engine.layers.qconv.nbit.cutlass.layer.q4conv2dcutlass method)": [[35, "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.prepare_params"]], "scale_a (bitorch_engine.layers.qconv.nbit.cutlass.layer.q4conv2dcutlass attribute)": [[35, "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.scale_a"]], "scale_w (bitorch_engine.layers.qconv.nbit.cutlass.layer.q4conv2dcutlass attribute)": [[35, "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.scale_w"]], "set_activation() (bitorch_engine.layers.qconv.nbit.cutlass.layer.q4conv2dcutlass method)": [[35, "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.set_activation"]], "q4conv2dcutlassforward (class in bitorch_engine.layers.qconv.nbit.cutlass.layer)": [[36, "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward"]], "backward (bitorch_engine.layers.qconv.nbit.cutlass.layer.q4conv2dcutlassforward attribute)": [[36, "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward.backward"]], "backward() (bitorch_engine.layers.qconv.nbit.cutlass.layer.q4conv2dcutlassforward static method)": [[36, "id0"]], "forward (bitorch_engine.layers.qconv.nbit.cutlass.layer.q4conv2dcutlassforward attribute)": [[36, "bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward.forward"]], "forward() (bitorch_engine.layers.qconv.nbit.cutlass.layer.q4conv2dcutlassforward static method)": [[36, "id1"]], "bitorch_engine.layers.qconv.nbit.layer": [[37, "module-bitorch_engine.layers.qconv.nbit.layer"]], "__init__() (bitorch_engine.layers.qconv.nbit.layer.nbitconv2dbase method)": [[38, "bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.__init__"]], "generate_quantized_weight() (bitorch_engine.layers.qconv.nbit.layer.nbitconv2dbase method)": [[38, "bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.generate_quantized_weight"]], "nbitconv2dbase (class in bitorch_engine.layers.qconv.nbit.layer)": [[38, "bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase"]], "opt_weight (bitorch_engine.layers.qconv.nbit.layer.nbitconv2dbase property)": [[38, "bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.opt_weight"]], "prepare_params() (bitorch_engine.layers.qconv.nbit.layer.nbitconv2dbase method)": [[38, "bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.prepare_params"]], "reset_parameters() (bitorch_engine.layers.qconv.nbit.layer.nbitconv2dbase method)": [[38, "bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.reset_parameters"]], "set_quantized_weight_data() (bitorch_engine.layers.qconv.nbit.layer.nbitconv2dbase method)": [[38, "bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.set_quantized_weight_data"]], "set_weight_data() (bitorch_engine.layers.qconv.nbit.layer.nbitconv2dbase method)": [[38, "bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.set_weight_data"]], "nbitconvparameter (class in bitorch_engine.layers.qconv.nbit.layer)": [[39, "bitorch_engine.layers.qconv.nbit.layer.nBitConvParameter"]], "update() (bitorch_engine.layers.qconv.nbit.layer.nbitconvparameter static method)": [[39, "bitorch_engine.layers.qconv.nbit.layer.nBitConvParameter.update"]], "bitorch_engine.layers.qembedding": [[40, "module-bitorch_engine.layers.qembedding"]], "bitorch_engine.layers.qembedding.binary": [[41, "module-bitorch_engine.layers.qembedding.binary"]], "bitorch_engine.layers.qembedding.binary.layer": [[42, "module-bitorch_engine.layers.qembedding.binary.layer"]], "binaryembeddingbag (class in bitorch_engine.layers.qembedding.binary.layer)": [[43, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag"]], "__init__() (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingbag method)": [[43, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.__init__"]], "forward() (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingbag method)": [[43, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.forward"]], "reset_parameters() (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingbag method)": [[43, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.reset_parameters"]], "binaryembeddingbagforward (class in bitorch_engine.layers.qembedding.binary.layer)": [[44, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward"]], "backward() (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingbagforward static method)": [[44, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward.backward"]], "forward() (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingbagforward static method)": [[44, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward.forward"]], "binaryembeddingcuda (class in bitorch_engine.layers.qembedding.binary.layer)": [[45, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda"]], "__init__() (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingcuda method)": [[45, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.__init__"]], "forward() (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingcuda method)": [[45, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.forward"]], "init_weight() (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingcuda method)": [[45, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.init_weight"]], "prepare_params() (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingcuda method)": [[45, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.prepare_params"]], "qweight (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingcuda attribute)": [[45, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.qweight"]], "reset_parameters() (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingcuda method)": [[45, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.reset_parameters"]], "scale_w (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingcuda attribute)": [[45, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.scale_w"]], "weight (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingcuda attribute)": [[45, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.weight"]], "binaryembeddingforward (class in bitorch_engine.layers.qembedding.binary.layer)": [[46, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingForward"]], "backward() (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingforward static method)": [[46, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingForward.backward"]], "forward() (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingforward static method)": [[46, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingForward.forward"]], "binaryembeddingparameter (class in bitorch_engine.layers.qembedding.binary.layer)": [[47, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingParameter"]], "active_indices (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingparameter attribute)": [[47, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingParameter.active_indices"]], "update() (bitorch_engine.layers.qembedding.binary.layer.binaryembeddingparameter static method)": [[47, "bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingParameter.update"]], "bitorch_engine.layers.qlinear": [[48, "module-bitorch_engine.layers.qlinear"]], "bitorch_engine.layers.qlinear.binary": [[49, "module-bitorch_engine.layers.qlinear.binary"]], "bitorch_engine.layers.qlinear.binary.binary_implementation": [[50, "module-bitorch_engine.layers.qlinear.binary.binary_implementation"]], "binarylinearimplementationmixin (class in bitorch_engine.layers.qlinear.binary.binary_implementation)": [[51, "bitorch_engine.layers.qlinear.binary.binary_implementation.BinaryLinearImplementationMixin"]], "can_clone() (bitorch_engine.layers.qlinear.binary.binary_implementation.binarylinearimplementationmixin class method)": [[51, "id0"]], "can_clone() (bitorch_engine.layers.qlinear.binary.binary_implementation.binarylinearimplementationmixin method)": [[51, "bitorch_engine.layers.qlinear.binary.binary_implementation.BinaryLinearImplementationMixin.can_clone"]], "bitorch_engine.layers.qlinear.binary.cpp": [[52, "module-bitorch_engine.layers.qlinear.binary.cpp"]], "bitorch_engine.layers.qlinear.binary.cpp.extension": [[53, "module-bitorch_engine.layers.qlinear.binary.cpp.extension"]], "get_ext() (in module bitorch_engine.layers.qlinear.binary.cpp.extension)": [[54, "bitorch_engine.layers.qlinear.binary.cpp.extension.get_ext"]], "bitorch_engine.layers.qlinear.binary.cpp.layer": [[55, "module-bitorch_engine.layers.qlinear.binary.cpp.layer"]], "binarylinearcpp (class in bitorch_engine.layers.qlinear.binary.cpp.layer)": [[56, "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP"]], "__init__() (bitorch_engine.layers.qlinear.binary.cpp.layer.binarylinearcpp method)": [[56, "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP.__init__"]], "create_clone_from() (bitorch_engine.layers.qlinear.binary.cpp.layer.binarylinearcpp class method)": [[56, "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP.create_clone_from"]], "forward() (bitorch_engine.layers.qlinear.binary.cpp.layer.binarylinearcpp method)": [[56, "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP.forward"]], "generate_quantized_weight() (bitorch_engine.layers.qlinear.binary.cpp.layer.binarylinearcpp method)": [[56, "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP.generate_quantized_weight"]], "prepare_params() (bitorch_engine.layers.qlinear.binary.cpp.layer.binarylinearcpp method)": [[56, "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP.prepare_params"]], "binarylinearforward (class in bitorch_engine.layers.qlinear.binary.cpp.layer)": [[57, "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearForward"]], "forward() (bitorch_engine.layers.qlinear.binary.cpp.layer.binarylinearforward static method)": [[57, "bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearForward.forward"]], "bitorch_engine.layers.qlinear.binary.cuda": [[58, "module-bitorch_engine.layers.qlinear.binary.cuda"]], "bitorch_engine.layers.qlinear.binary.cuda.bmm": [[59, "module-bitorch_engine.layers.qlinear.binary.cuda.bmm"]], "adaptive (bitorch_engine.layers.qlinear.binary.cuda.bmm.bmm attribute)": [[60, "bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM.ADAPTIVE"]], "bmm (class in bitorch_engine.layers.qlinear.binary.cuda.bmm)": [[60, "bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM"]], "bstc32 (bitorch_engine.layers.qlinear.binary.cuda.bmm.bmm attribute)": [[60, "bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM.BSTC32"]], "btc32 (bitorch_engine.layers.qlinear.binary.cuda.bmm.bmm attribute)": [[60, "bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM.BTC32"]], "bitorch_engine.layers.qlinear.binary.cuda.extension": [[61, "module-bitorch_engine.layers.qlinear.binary.cuda.extension"]], "get_ext() (in module bitorch_engine.layers.qlinear.binary.cuda.extension)": [[62, "bitorch_engine.layers.qlinear.binary.cuda.extension.get_ext"]], "bitorch_engine.layers.qlinear.binary.cuda.layer": [[63, "module-bitorch_engine.layers.qlinear.binary.cuda.layer"]], "binarylinearcuda (class in bitorch_engine.layers.qlinear.binary.cuda.layer)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda"]], "__init__() (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda method)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.__init__"]], "bias_a (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda attribute)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.bias_a"]], "bits_binary_word (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda attribute)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.bits_binary_word"]], "bmm_type (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda attribute)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.bmm_type"]], "create_clone_from() (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda class method)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.create_clone_from"]], "device_id (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda property)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.device_id"]], "forward() (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda method)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.forward"]], "generate_quantized_weight() (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda method)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.generate_quantized_weight"]], "prepare_params() (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda method)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.prepare_params"]], "scale_a (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda attribute)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.scale_a"]], "scale_w (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda attribute)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.scale_w"]], "set_activation() (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda method)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.set_activation"]], "set_weight_data() (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda method)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.set_weight_data"]], "w_pack() (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearcuda static method)": [[64, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.w_pack"]], "binarylinearforward (class in bitorch_engine.layers.qlinear.binary.cuda.layer)": [[65, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward"]], "backward() (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearforward static method)": [[65, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.backward"]], "bmm_type (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearforward attribute)": [[65, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.bmm_type"]], "ctx (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearforward attribute)": [[65, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.ctx"]], "forward() (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearforward static method)": [[65, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.forward"]], "input (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearforward attribute)": [[65, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.input"]], "is_train (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearforward attribute)": [[65, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.is_train"]], "scale_a (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearforward attribute)": [[65, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.scale_a"]], "scale_w (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearforward attribute)": [[65, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.scale_w"]], "weight (bitorch_engine.layers.qlinear.binary.cuda.layer.binarylinearforward attribute)": [[65, "bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.weight"]], "bitorch_engine.layers.qlinear.binary.cutlass": [[66, "module-bitorch_engine.layers.qlinear.binary.cutlass"]], "bitorch_engine.layers.qlinear.binary.cutlass.extension": [[67, "module-bitorch_engine.layers.qlinear.binary.cutlass.extension"]], "get_ext() (in module bitorch_engine.layers.qlinear.binary.cutlass.extension)": [[68, "bitorch_engine.layers.qlinear.binary.cutlass.extension.get_ext"]], "bitorch_engine.layers.qlinear.binary.cutlass.layer": [[69, "module-bitorch_engine.layers.qlinear.binary.cutlass.layer"]], "binarylinearcutlass (class in bitorch_engine.layers.qlinear.binary.cutlass.layer)": [[70, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass"]], "__init__() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearcutlass method)": [[70, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.__init__"]], "bias_a (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearcutlass attribute)": [[70, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.bias_a"]], "bits_binary_word (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearcutlass attribute)": [[70, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.bits_binary_word"]], "forward() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearcutlass method)": [[70, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.forward"], [70, "id0"]], "gemm_kernel_id (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearcutlass attribute)": [[70, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.gemm_kernel_id"]], "generate_quantized_weight() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearcutlass method)": [[70, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.generate_quantized_weight"], [70, "id1"]], "prepare_params() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearcutlass method)": [[70, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.prepare_params"], [70, "id2"]], "scale_a (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearcutlass attribute)": [[70, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.scale_a"]], "scale_w (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearcutlass attribute)": [[70, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.scale_w"]], "select_gemm_kernel() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearcutlass method)": [[70, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.select_gemm_kernel"], [70, "id3"]], "set_activation() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearcutlass method)": [[70, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.set_activation"], [70, "id4"]], "set_weight_data() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearcutlass method)": [[70, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.set_weight_data"], [70, "id5"]], "binarylinearforward (class in bitorch_engine.layers.qlinear.binary.cutlass.layer)": [[71, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward"]], "backward() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearforward static method)": [[71, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward.backward"]], "forward() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarylinearforward static method)": [[71, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward.forward"]], "binarymatmul (class in bitorch_engine.layers.qlinear.binary.cutlass.layer)": [[72, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul"]], "__init__() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarymatmul method)": [[72, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul.__init__"]], "dtype (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarymatmul attribute)": [[72, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul.dtype"]], "forward() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarymatmul method)": [[72, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul.forward"]], "set_activation_scale() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarymatmul method)": [[72, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul.set_activation_scale"]], "x_clip (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarymatmul attribute)": [[72, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul.x_clip"]], "y_clip (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarymatmul attribute)": [[72, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul.y_clip"]], "binarymatmulfunction (class in bitorch_engine.layers.qlinear.binary.cutlass.layer)": [[73, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMulFunction"]], "backward() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarymatmulfunction static method)": [[73, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMulFunction.backward"]], "forward() (bitorch_engine.layers.qlinear.binary.cutlass.layer.binarymatmulfunction static method)": [[73, "bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMulFunction.forward"]], "get_best_binary_implementation() (in module bitorch_engine.layers.qlinear.binary)": [[74, "bitorch_engine.layers.qlinear.binary.get_best_binary_implementation"]], "bitorch_engine.layers.qlinear.binary.layer": [[75, "module-bitorch_engine.layers.qlinear.binary.layer"]], "binarylinearbase (class in bitorch_engine.layers.qlinear.binary.layer)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase"]], "__init__() (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase method)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.__init__"]], "_check_forward() (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase method)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase._check_forward"]], "bits_binary_word (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase attribute)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.bits_binary_word"]], "device (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase attribute)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.device"]], "dtype (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase attribute)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.dtype"]], "generate_quantized_weight() (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase method)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.generate_quantized_weight"], [76, "id0"]], "input_features (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase attribute)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.input_features"]], "opt_weight (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase property)": [[76, "id1"]], "opt_weight() (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase method)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.opt_weight"]], "output_features (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase attribute)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.output_features"]], "prepare_params() (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase method)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.prepare_params"]], "qweight (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase attribute)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.qweight"]], "reset_parameters() (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase method)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.reset_parameters"], [76, "id2"]], "set_bits_binary_word() (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase method)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.set_bits_binary_word"], [76, "id3"]], "set_quantized_weight_data() (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase method)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.set_quantized_weight_data"], [76, "id4"]], "set_weight_data() (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase method)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.set_weight_data"], [76, "id5"]], "symmetric (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase attribute)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.symmetric"]], "weight (bitorch_engine.layers.qlinear.binary.layer.binarylinearbase attribute)": [[76, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.weight"]], "binarylinearparameter (class in bitorch_engine.layers.qlinear.binary.layer)": [[77, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearParameter"]], "update() (bitorch_engine.layers.qlinear.binary.layer.binarylinearparameter static method)": [[77, "bitorch_engine.layers.qlinear.binary.layer.BinaryLinearParameter.update"]], "bitorch_engine.layers.qlinear.layer": [[78, "module-bitorch_engine.layers.qlinear.layer"]], "qlinearinf (class in bitorch_engine.layers.qlinear.layer)": [[79, "bitorch_engine.layers.qlinear.layer.QLinearInf"]], "__init__() (bitorch_engine.layers.qlinear.layer.qlinearinf method)": [[79, "bitorch_engine.layers.qlinear.layer.QLinearInf.__init__"]], "create_clone_from() (bitorch_engine.layers.qlinear.layer.qlinearinf class method)": [[79, "bitorch_engine.layers.qlinear.layer.QLinearInf.create_clone_from"]], "forward() (bitorch_engine.layers.qlinear.layer.qlinearinf method)": [[79, "bitorch_engine.layers.qlinear.layer.QLinearInf.forward"]], "generate_quantized_weight() (bitorch_engine.layers.qlinear.layer.qlinearinf method)": [[79, "bitorch_engine.layers.qlinear.layer.QLinearInf.generate_quantized_weight"]], "opt_weight (bitorch_engine.layers.qlinear.layer.qlinearinf property)": [[79, "bitorch_engine.layers.qlinear.layer.QLinearInf.opt_weight"]], "prepare_params() (bitorch_engine.layers.qlinear.layer.qlinearinf method)": [[79, "bitorch_engine.layers.qlinear.layer.QLinearInf.prepare_params"]], "set_quantized_weight_data() (bitorch_engine.layers.qlinear.layer.qlinearinf method)": [[79, "bitorch_engine.layers.qlinear.layer.QLinearInf.set_quantized_weight_data"]], "set_weight_data() (bitorch_engine.layers.qlinear.layer.qlinearinf method)": [[79, "bitorch_engine.layers.qlinear.layer.QLinearInf.set_weight_data"]], "weight (bitorch_engine.layers.qlinear.layer.qlinearinf property)": [[79, "bitorch_engine.layers.qlinear.layer.QLinearInf.weight"]], "bitorch_engine.layers.qlinear.nbit": [[80, "module-bitorch_engine.layers.qlinear.nbit"]], "bitorch_engine.layers.qlinear.nbit.cuda": [[81, "module-bitorch_engine.layers.qlinear.nbit.cuda"]], "bitorch_engine.layers.qlinear.nbit.cuda.extension": [[82, "module-bitorch_engine.layers.qlinear.nbit.cuda.extension"]], "get_ext() (in module bitorch_engine.layers.qlinear.nbit.cuda.extension)": [[83, "bitorch_engine.layers.qlinear.nbit.cuda.extension.get_ext"]], "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer": [[84, "module-bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer"]], "mbwqlinearcuda (class in bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda"]], "__init__() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda method)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.__init__"]], "check_parameters() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda method)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.check_parameters"], [85, "id0"]], "exl2fp_weight() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda method)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.exl2fp_weight"]], "exl2fp_weight() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda static method)": [[85, "id1"]], "forward() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda method)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.forward"], [85, "id2"]], "load_state_dict() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda method)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.load_state_dict"], [85, "id3"]], "prepare_params() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda method)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.prepare_params"], [85, "id4"]], "q42fp_weight() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda method)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.q42fp_weight"]], "q42fp_weight() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda static method)": [[85, "id5"]], "qweight (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda attribute)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.qweight"]], "rows (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda attribute)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.rows"]], "scales (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda attribute)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.scales"]], "set_scales() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda method)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.set_scales"], [85, "id6"]], "set_zeros() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda method)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.set_zeros"], [85, "id7"]], "use_mbw (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda attribute)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.use_mbw"]], "zeros (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcuda attribute)": [[85, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.zeros"]], "mbwqlinearcudafunction (class in bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer)": [[86, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction"]], "backward() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcudafunction static method)": [[86, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction.backward"]], "forward() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.mbwqlinearcudafunction static method)": [[86, "bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction.forward"]], "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer": [[87, "module-bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer"]], "mpqlinearcuda (class in bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer)": [[88, "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda"]], "__init__() (bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.mpqlinearcuda method)": [[88, "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.__init__"]], "a_bit (bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.mpqlinearcuda attribute)": [[88, "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.a_bit"]], "check_parameters() (bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.mpqlinearcuda method)": [[88, "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.check_parameters"], [88, "id0"]], "forward() (bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.mpqlinearcuda method)": [[88, "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.forward"], [88, "id1"]], "prepare_params() (bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.mpqlinearcuda method)": [[88, "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.prepare_params"], [88, "id2"]], "qweight (bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.mpqlinearcuda attribute)": [[88, "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.qweight"]], "scales (bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.mpqlinearcuda attribute)": [[88, "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.scales"]], "w_bit (bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.mpqlinearcuda attribute)": [[88, "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.w_bit"]], "zeros (bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.mpqlinearcuda attribute)": [[88, "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.zeros"]], "mpqlinearcudafunction (class in bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer)": [[89, "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCudaFunction"]], "backward() (bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.mpqlinearcudafunction static method)": [[89, "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCudaFunction.backward"]], "forward() (bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.mpqlinearcudafunction static method)": [[89, "bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCudaFunction.forward"]], "bitorch_engine.layers.qlinear.nbit.cuda.utils": [[90, "module-bitorch_engine.layers.qlinear.nbit.cuda.utils"]], "make_group_map() (in module bitorch_engine.layers.qlinear.nbit.cuda.utils)": [[91, "bitorch_engine.layers.qlinear.nbit.cuda.utils.make_group_map"]], "pack_fp_weight() (in module bitorch_engine.layers.qlinear.nbit.cuda.utils)": [[92, "bitorch_engine.layers.qlinear.nbit.cuda.utils.pack_fp_weight"]], "unpack_qweight() (in module bitorch_engine.layers.qlinear.nbit.cuda.utils)": [[93, "bitorch_engine.layers.qlinear.nbit.cuda.utils.unpack_qweight"]], "bitorch_engine.layers.qlinear.nbit.cutlass": [[94, "module-bitorch_engine.layers.qlinear.nbit.cutlass"]], "bitorch_engine.layers.qlinear.nbit.cutlass.extension": [[95, "module-bitorch_engine.layers.qlinear.nbit.cutlass.extension"]], "get_ext() (in module bitorch_engine.layers.qlinear.nbit.cutlass.extension)": [[96, "bitorch_engine.layers.qlinear.nbit.cutlass.extension.get_ext"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer": [[97, "module-bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer"]], "q4linearcutlass (class in bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer)": [[98, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass"]], "__init__() (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4linearcutlass method)": [[98, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.__init__"]], "_check_forward() (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4linearcutlass method)": [[98, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass._check_forward"]], "bias_a (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4linearcutlass attribute)": [[98, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.bias_a"]], "eps (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4linearcutlass attribute)": [[98, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.eps"]], "forward() (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4linearcutlass method)": [[98, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.forward"], [98, "id0"]], "generate_quantized_weight() (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4linearcutlass method)": [[98, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.generate_quantized_weight"], [98, "id1"]], "prepare_params() (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4linearcutlass method)": [[98, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.prepare_params"], [98, "id2"]], "scale_a (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4linearcutlass attribute)": [[98, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.scale_a"]], "scale_w (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4linearcutlass attribute)": [[98, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.scale_w"]], "set_activation() (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4linearcutlass method)": [[98, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.set_activation"], [98, "id3"]], "q4linearfunction (class in bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer)": [[99, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearFunction"]], "backward() (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4linearfunction static method)": [[99, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearFunction.backward"]], "forward() (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4linearfunction static method)": [[99, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearFunction.forward"]], "q4matmul (class in bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer)": [[100, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul"]], "__init__() (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4matmul method)": [[100, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.__init__"]], "device (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4matmul attribute)": [[100, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.device"]], "dtype (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4matmul attribute)": [[100, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.dtype"]], "eps (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4matmul attribute)": [[100, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.eps"]], "forward() (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4matmul method)": [[100, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.forward"]], "set_activation_scale() (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4matmul method)": [[100, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.set_activation_scale"]], "x_clip (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4matmul attribute)": [[100, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.x_clip"]], "y_clip (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4matmul attribute)": [[100, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.y_clip"]], "q4matmulfunction (class in bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer)": [[101, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMulFunction"]], "backward() (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4matmulfunction static method)": [[101, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMulFunction.backward"]], "forward() (bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.q4matmulfunction static method)": [[101, "bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMulFunction.forward"]], "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer": [[102, "module-bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer"]], "q8linearcutlass (class in bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer)": [[103, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass"]], "__init__() (bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.q8linearcutlass method)": [[103, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.__init__"]], "_check_forward() (bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.q8linearcutlass method)": [[103, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass._check_forward"]], "bias_a (bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.q8linearcutlass attribute)": [[103, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.bias_a"]], "eps (bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.q8linearcutlass attribute)": [[103, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.eps"]], "forward() (bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.q8linearcutlass method)": [[103, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.forward"], [103, "id0"]], "generate_quantized_weight() (bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.q8linearcutlass method)": [[103, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.generate_quantized_weight"], [103, "id1"]], "prepare_params() (bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.q8linearcutlass method)": [[103, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.prepare_params"], [103, "id2"]], "scale_a (bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.q8linearcutlass attribute)": [[103, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.scale_a"]], "scale_w (bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.q8linearcutlass attribute)": [[103, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.scale_w"]], "set_activation() (bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.q8linearcutlass method)": [[103, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.set_activation"], [103, "id3"]], "q8linearfunction (class in bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer)": [[104, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearFunction"]], "backward() (bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.q8linearfunction static method)": [[104, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearFunction.backward"]], "forward() (bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.q8linearfunction static method)": [[104, "bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearFunction.forward"]], "bitorch_engine.layers.qlinear.nbit.layer": [[105, "module-bitorch_engine.layers.qlinear.nbit.layer"]], "mpqlinearbase (class in bitorch_engine.layers.qlinear.nbit.layer)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase"]], "__init__() (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase method)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.__init__"]], "a_bit (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase attribute)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.a_bit"]], "asym (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase attribute)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.asym"]], "check_parameters() (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase method)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.check_parameters"], [106, "id0"]], "disable_bias (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase attribute)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.disable_bias"]], "dq_group_size (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase attribute)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.dq_group_size"]], "dq_mode (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase attribute)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.dq_mode"]], "dtype (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase attribute)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.dtype"]], "generate_quantized_weight() (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase method)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.generate_quantized_weight"], [106, "id1"]], "group_size (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase attribute)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.group_size"]], "in_channels (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase attribute)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.in_channels"]], "init_gba() (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase method)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.init_gba"], [106, "id2"]], "init_gptq() (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase method)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.init_gptq"], [106, "id3"]], "initialize() (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase method)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.initialize"], [106, "id4"]], "out_channels (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase attribute)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.out_channels"]], "prepare_params() (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase method)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.prepare_params"], [106, "id5"]], "set_qweight_data() (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase method)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.set_qweight_data"], [106, "id6"]], "use_gba_quant (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase attribute)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.use_gba_quant"]], "w_bit (bitorch_engine.layers.qlinear.nbit.layer.mpqlinearbase attribute)": [[106, "bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.w_bit"]], "mpqweightparameter (class in bitorch_engine.layers.qlinear.nbit.layer)": [[107, "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter"]], "__init__() (bitorch_engine.layers.qlinear.nbit.layer.mpqweightparameter method)": [[107, "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.__init__"]], "asym (bitorch_engine.layers.qlinear.nbit.layer.mpqweightparameter attribute)": [[107, "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.asym"]], "g_idx (bitorch_engine.layers.qlinear.nbit.layer.mpqweightparameter attribute)": [[107, "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.g_idx"]], "group_size (bitorch_engine.layers.qlinear.nbit.layer.mpqweightparameter attribute)": [[107, "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.group_size"]], "layer_type (bitorch_engine.layers.qlinear.nbit.layer.mpqweightparameter attribute)": [[107, "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.layer_type"]], "privileged_grad (bitorch_engine.layers.qlinear.nbit.layer.mpqweightparameter attribute)": [[107, "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.privileged_grad"]], "q_group_map (bitorch_engine.layers.qlinear.nbit.layer.mpqweightparameter attribute)": [[107, "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.q_group_map"]], "q_perm (bitorch_engine.layers.qlinear.nbit.layer.mpqweightparameter attribute)": [[107, "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.q_perm"]], "rows (bitorch_engine.layers.qlinear.nbit.layer.mpqweightparameter attribute)": [[107, "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.rows"]], "update() (bitorch_engine.layers.qlinear.nbit.layer.mpqweightparameter static method)": [[107, "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.update"]], "w_bit (bitorch_engine.layers.qlinear.nbit.layer.mpqweightparameter attribute)": [[107, "bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.w_bit"]], "__init__() (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearbase method)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.__init__"]], "a_bit (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearbase attribute)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.a_bit"]], "device (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearbase attribute)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.device"]], "dtype (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearbase attribute)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.dtype"]], "generate_quantized_weight() (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearbase method)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.generate_quantized_weight"]], "in_channels (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearbase attribute)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.in_channels"]], "nbitlinearbase (class in bitorch_engine.layers.qlinear.nbit.layer)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase"]], "opt_weight (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearbase property)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.opt_weight"]], "out_channels (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearbase attribute)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.out_channels"]], "prepare_params() (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearbase method)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.prepare_params"]], "reset_parameters() (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearbase method)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.reset_parameters"]], "set_quantized_weight_data() (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearbase method)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.set_quantized_weight_data"]], "set_weight_data() (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearbase method)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.set_weight_data"]], "w_bit (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearbase attribute)": [[108, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.w_bit"]], "nbitlinearparameter (class in bitorch_engine.layers.qlinear.nbit.layer)": [[109, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearParameter"]], "update() (bitorch_engine.layers.qlinear.nbit.layer.nbitlinearparameter static method)": [[109, "bitorch_engine.layers.qlinear.nbit.layer.nBitLinearParameter.update"]], "bitorch_engine.layers.qlinear.nbit.mps": [[110, "module-bitorch_engine.layers.qlinear.nbit.mps"]], "bitorch_engine.layers.qlinear.nbit.mps.extension": [[111, "module-bitorch_engine.layers.qlinear.nbit.mps.extension"]], "get_ext() (in module bitorch_engine.layers.qlinear.nbit.mps.extension)": [[112, "bitorch_engine.layers.qlinear.nbit.mps.extension.get_ext"]], "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer": [[113, "module-bitorch_engine.layers.qlinear.nbit.mps.mpq_layer"]], "mpqlinearmlx (class in bitorch_engine.layers.qlinear.nbit.mps.mpq_layer)": [[114, "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx"]], "__init__() (bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.mpqlinearmlx method)": [[114, "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.__init__"]], "a_bit (bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.mpqlinearmlx attribute)": [[114, "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.a_bit"]], "check_parameters() (bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.mpqlinearmlx method)": [[114, "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.check_parameters"], [114, "id0"]], "forward() (bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.mpqlinearmlx method)": [[114, "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.forward"], [114, "id1"]], "prepare_params() (bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.mpqlinearmlx method)": [[114, "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.prepare_params"], [114, "id2"]], "qweight (bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.mpqlinearmlx attribute)": [[114, "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.qweight"]], "scales (bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.mpqlinearmlx attribute)": [[114, "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.scales"]], "w_bit (bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.mpqlinearmlx attribute)": [[114, "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.w_bit"]], "zeros (bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.mpqlinearmlx attribute)": [[114, "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.zeros"]], "mpqlinearmlxfunction (class in bitorch_engine.layers.qlinear.nbit.mps.mpq_layer)": [[115, "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlxFunction"]], "backward() (bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.mpqlinearmlxfunction static method)": [[115, "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlxFunction.backward"]], "forward() (bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.mpqlinearmlxfunction static method)": [[115, "bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlxFunction.forward"]], "bitorch_engine.layers.qlinear.qlinear_implementation": [[116, "module-bitorch_engine.layers.qlinear.qlinear_implementation"]], "qlinearimplementationmixin (class in bitorch_engine.layers.qlinear.qlinear_implementation)": [[117, "bitorch_engine.layers.qlinear.qlinear_implementation.QLinearImplementationMixin"]], "can_clone() (bitorch_engine.layers.qlinear.qlinear_implementation.qlinearimplementationmixin class method)": [[117, "bitorch_engine.layers.qlinear.qlinear_implementation.QLinearImplementationMixin.can_clone"]], "bitorch_engine.layers.qmha": [[118, "module-bitorch_engine.layers.qmha"]], "bitorch_engine.layers.qmha.binary": [[119, "module-bitorch_engine.layers.qmha.binary"]], "bitorch_engine.layers.qmha.binary.layer": [[120, "module-bitorch_engine.layers.qmha.binary.layer"]], "bmha (class in bitorch_engine.layers.qmha.binary.layer)": [[121, "bitorch_engine.layers.qmha.binary.layer.BMHA"]], "__init__() (bitorch_engine.layers.qmha.binary.layer.bmha method)": [[121, "bitorch_engine.layers.qmha.binary.layer.BMHA.__init__"]], "dropout (bitorch_engine.layers.qmha.binary.layer.bmha attribute)": [[121, "bitorch_engine.layers.qmha.binary.layer.BMHA.dropout"]], "dtype (bitorch_engine.layers.qmha.binary.layer.bmha attribute)": [[121, "bitorch_engine.layers.qmha.binary.layer.BMHA.dtype"]], "forward() (bitorch_engine.layers.qmha.binary.layer.bmha method)": [[121, "bitorch_engine.layers.qmha.binary.layer.BMHA.forward"]], "head_dim (bitorch_engine.layers.qmha.binary.layer.bmha attribute)": [[121, "bitorch_engine.layers.qmha.binary.layer.BMHA.head_dim"]], "hidden_dim (bitorch_engine.layers.qmha.binary.layer.bmha attribute)": [[121, "bitorch_engine.layers.qmha.binary.layer.BMHA.hidden_dim"]], "input_dim (bitorch_engine.layers.qmha.binary.layer.bmha attribute)": [[121, "bitorch_engine.layers.qmha.binary.layer.BMHA.input_dim"]], "k_linear (bitorch_engine.layers.qmha.binary.layer.bmha attribute)": [[121, "bitorch_engine.layers.qmha.binary.layer.BMHA.k_linear"]], "num_heads (bitorch_engine.layers.qmha.binary.layer.bmha attribute)": [[121, "bitorch_engine.layers.qmha.binary.layer.BMHA.num_heads"]], "out (bitorch_engine.layers.qmha.binary.layer.bmha attribute)": [[121, "bitorch_engine.layers.qmha.binary.layer.BMHA.out"]], "q_linear (bitorch_engine.layers.qmha.binary.layer.bmha attribute)": [[121, "bitorch_engine.layers.qmha.binary.layer.BMHA.q_linear"]], "v_linear (bitorch_engine.layers.qmha.binary.layer.bmha attribute)": [[121, "bitorch_engine.layers.qmha.binary.layer.BMHA.v_linear"]], "learnablebias (class in bitorch_engine.layers.qmha.binary.layer)": [[122, "bitorch_engine.layers.qmha.binary.layer.LearnableBias"]], "__init__() (bitorch_engine.layers.qmha.binary.layer.learnablebias method)": [[122, "bitorch_engine.layers.qmha.binary.layer.LearnableBias.__init__"]], "bias (bitorch_engine.layers.qmha.binary.layer.learnablebias attribute)": [[122, "bitorch_engine.layers.qmha.binary.layer.LearnableBias.bias"]], "forward() (bitorch_engine.layers.qmha.binary.layer.learnablebias method)": [[122, "bitorch_engine.layers.qmha.binary.layer.LearnableBias.forward"]], "bitorch_engine.optim": [[123, "module-bitorch_engine.optim"]], "bitorch_engine.optim.diode_beta": [[124, "module-bitorch_engine.optim.diode_beta"]], "diodemix (class in bitorch_engine.optim.diode_beta)": [[125, "bitorch_engine.optim.diode_beta.DiodeMix"]], "__init__() (bitorch_engine.optim.diode_beta.diodemix method)": [[125, "bitorch_engine.optim.diode_beta.DiodeMix.__init__"], [125, "id0"]], "betas (bitorch_engine.optim.diode_beta.diodemix attribute)": [[125, "bitorch_engine.optim.diode_beta.DiodeMix.betas"]], "correct_bias (bitorch_engine.optim.diode_beta.diodemix attribute)": [[125, "bitorch_engine.optim.diode_beta.DiodeMix.correct_bias"]], "dtype (bitorch_engine.optim.diode_beta.diodemix attribute)": [[125, "bitorch_engine.optim.diode_beta.DiodeMix.dtype"]], "eps (bitorch_engine.optim.diode_beta.diodemix attribute)": [[125, "bitorch_engine.optim.diode_beta.DiodeMix.eps"]], "lr (bitorch_engine.optim.diode_beta.diodemix attribute)": [[125, "bitorch_engine.optim.diode_beta.DiodeMix.lr"]], "params (bitorch_engine.optim.diode_beta.diodemix attribute)": [[125, "bitorch_engine.optim.diode_beta.DiodeMix.params"]], "step() (bitorch_engine.optim.diode_beta.diodemix method)": [[125, "bitorch_engine.optim.diode_beta.DiodeMix.step"], [125, "id1"]], "weight_decay (bitorch_engine.optim.diode_beta.diodemix attribute)": [[125, "bitorch_engine.optim.diode_beta.DiodeMix.weight_decay"]], "check_pytorch_version() (in module bitorch_engine.optim.diode_beta)": [[126, "bitorch_engine.optim.diode_beta.check_pytorch_version"]], "bitorch_engine.optim.galore_projector": [[127, "module-bitorch_engine.optim.galore_projector"]], "galoreprojector (class in bitorch_engine.optim.galore_projector)": [[128, "bitorch_engine.optim.galore_projector.GaLoreProjector"]], "__init__() (bitorch_engine.optim.galore_projector.galoreprojector method)": [[128, "bitorch_engine.optim.galore_projector.GaLoreProjector.__init__"]], "bitorch_engine.utils": [[129, "module-bitorch_engine.utils"]], "bitorch_engine.utils.arch_helper": [[130, "module-bitorch_engine.utils.arch_helper"]], "arch_cpu (class in bitorch_engine.utils.arch_helper)": [[131, "bitorch_engine.utils.arch_helper.ARCH_CPU"]], "check_cpu_instruction_support() (in module bitorch_engine.utils.arch_helper)": [[132, "bitorch_engine.utils.arch_helper.check_cpu_instruction_support"]], "get_arm_model() (bitorch_engine.utils.arch_helper.linux_arch_ident static method)": [[133, "bitorch_engine.utils.arch_helper.linux_arch_ident.get_arm_model"]], "is_arm() (bitorch_engine.utils.arch_helper.linux_arch_ident static method)": [[133, "bitorch_engine.utils.arch_helper.linux_arch_ident.is_arm"]], "linux_arch_ident (class in bitorch_engine.utils.arch_helper)": [[133, "bitorch_engine.utils.arch_helper.linux_arch_ident"]], "bitorch_engine.utils.convert": [[134, "module-bitorch_engine.utils.convert"]], "collect_layers() (in module bitorch_engine.utils.convert)": [[135, "bitorch_engine.utils.convert.collect_layers"]], "get_mpq_config() (in module bitorch_engine.utils.convert)": [[136, "bitorch_engine.utils.convert.get_mpq_config"]], "quantize_linear_with_binary_linear_cuda() (in module bitorch_engine.utils.convert)": [[137, "bitorch_engine.utils.convert.quantize_linear_with_binary_linear_cuda"]], "quantize_linear_with_mpq_linear_cuda() (in module bitorch_engine.utils.convert)": [[138, "bitorch_engine.utils.convert.quantize_linear_with_mpq_linear_cuda"]], "quantize_linear_with_q4_linear_cutlass() (in module bitorch_engine.utils.convert)": [[139, "bitorch_engine.utils.convert.quantize_linear_with_q4_linear_cutlass"]], "replace_layers() (in module bitorch_engine.utils.convert)": [[140, "bitorch_engine.utils.convert.replace_layers"]], "bitorch_engine.utils.cpp_extension": [[141, "module-bitorch_engine.utils.cpp_extension"]], "get_cpp_extension() (in module bitorch_engine.utils.cpp_extension)": [[142, "bitorch_engine.utils.cpp_extension.get_cpp_extension"]], "get_kwargs() (in module bitorch_engine.utils.cpp_extension)": [[143, "bitorch_engine.utils.cpp_extension.get_kwargs"]], "bitorch_engine.utils.cuda_extension": [[144, "module-bitorch_engine.utils.cuda_extension"]], "gcc_version() (in module bitorch_engine.utils.cuda_extension)": [[145, "bitorch_engine.utils.cuda_extension.gcc_version"]], "get_cuda_extension() (in module bitorch_engine.utils.cuda_extension)": [[146, "bitorch_engine.utils.cuda_extension.get_cuda_extension"]], "get_kwargs() (in module bitorch_engine.utils.cuda_extension)": [[147, "bitorch_engine.utils.cuda_extension.get_kwargs"]], "bitorch_engine.utils.cutlass_path": [[148, "module-bitorch_engine.utils.cutlass_path"]], "check_path() (in module bitorch_engine.utils.cutlass_path)": [[149, "bitorch_engine.utils.cutlass_path.check_path"]], "find_cutlass() (in module bitorch_engine.utils.cutlass_path)": [[150, "bitorch_engine.utils.cutlass_path.find_cutlass"]], "get_cutlass_include_path() (in module bitorch_engine.utils.cutlass_path)": [[151, "bitorch_engine.utils.cutlass_path.get_cutlass_include_path"]], "is_cutlass_available() (in module bitorch_engine.utils.cutlass_path)": [[152, "bitorch_engine.utils.cutlass_path.is_cutlass_available"]], "bitorch_engine.utils.mlx_extension": [[153, "module-bitorch_engine.utils.mlx_extension"]], "get_mlx_extension() (in module bitorch_engine.utils.mlx_extension)": [[154, "bitorch_engine.utils.mlx_extension.get_mlx_extension"]], "bitorch_engine.utils.mlx_path": [[155, "module-bitorch_engine.utils.mlx_path"]], "get_mlx_include_path() (in module bitorch_engine.utils.mlx_path)": [[156, "bitorch_engine.utils.mlx_path.get_mlx_include_path"]], "get_mlx_lib_path() (in module bitorch_engine.utils.mlx_path)": [[157, "bitorch_engine.utils.mlx_path.get_mlx_lib_path"]], "is_mlx_available() (in module bitorch_engine.utils.mlx_path)": [[158, "bitorch_engine.utils.mlx_path.is_mlx_available"]], "bitorch_engine.utils.model_helper": [[159, "module-bitorch_engine.utils.model_helper"]], "binary_matmul_forward_post_processing() (in module bitorch_engine.utils.model_helper)": [[160, "bitorch_engine.utils.model_helper.binary_matmul_forward_post_processing"]], "flatten_x() (in module bitorch_engine.utils.model_helper)": [[161, "bitorch_engine.utils.model_helper.flatten_x"]], "init_weight() (in module bitorch_engine.utils.model_helper)": [[162, "bitorch_engine.utils.model_helper.init_weight"]], "load_checkpoint() (in module bitorch_engine.utils.model_helper)": [[163, "bitorch_engine.utils.model_helper.load_checkpoint"]], "pack_bie_layers() (in module bitorch_engine.utils.model_helper)": [[164, "bitorch_engine.utils.model_helper.pack_bie_layers"]], "pad_embedding_dim() (in module bitorch_engine.utils.model_helper)": [[165, "bitorch_engine.utils.model_helper.pad_embedding_dim"]], "pad_last_2_dims_to_multiple_of_128() (in module bitorch_engine.utils.model_helper)": [[166, "bitorch_engine.utils.model_helper.pad_last_2_dims_to_multiple_of_128"]], "prepare_bie_layers() (in module bitorch_engine.utils.model_helper)": [[167, "bitorch_engine.utils.model_helper.prepare_bie_layers"]], "qweight_update_fn() (in module bitorch_engine.utils.model_helper)": [[168, "bitorch_engine.utils.model_helper.qweight_update_fn"]], "save_checkpoint() (in module bitorch_engine.utils.model_helper)": [[169, "bitorch_engine.utils.model_helper.save_checkpoint"]], "unflatten_x() (in module bitorch_engine.utils.model_helper)": [[170, "bitorch_engine.utils.model_helper.unflatten_x"]], "bitorch_engine.utils.quant_operators": [[171, "module-bitorch_engine.utils.quant_operators"]], "bit_set() (in module bitorch_engine.utils.quant_operators)": [[172, "bitorch_engine.utils.quant_operators.bit_set"]], "get_binary_col() (in module bitorch_engine.utils.quant_operators)": [[173, "bitorch_engine.utils.quant_operators.get_binary_col"]], "get_binary_row() (in module bitorch_engine.utils.quant_operators)": [[174, "bitorch_engine.utils.quant_operators.get_binary_row"]], "gptq_stype_unpacking() (in module bitorch_engine.utils.quant_operators)": [[175, "bitorch_engine.utils.quant_operators.gptq_stype_unpacking"]], "nv_tensor_quant() (in module bitorch_engine.utils.quant_operators)": [[176, "bitorch_engine.utils.quant_operators.nv_tensor_quant"]], "q4_quantization() (in module bitorch_engine.utils.quant_operators)": [[177, "bitorch_engine.utils.quant_operators.q4_quantization"]], "q8_quantization() (in module bitorch_engine.utils.quant_operators)": [[178, "bitorch_engine.utils.quant_operators.q8_quantization"]], "bitorch_engine.utils.safe_import": [[179, "module-bitorch_engine.utils.safe_import"]], "extensionmoduleplaceholder (class in bitorch_engine.utils.safe_import)": [[180, "bitorch_engine.utils.safe_import.ExtensionModulePlaceholder"]], "__getattr__() (bitorch_engine.utils.safe_import.extensionmoduleplaceholder method)": [[180, "bitorch_engine.utils.safe_import.ExtensionModulePlaceholder.__getattr__"]], "__init__() (bitorch_engine.utils.safe_import.extensionmoduleplaceholder method)": [[180, "bitorch_engine.utils.safe_import.ExtensionModulePlaceholder.__init__"], [180, "id0"]], "__setattr__() (bitorch_engine.utils.safe_import.extensionmoduleplaceholder method)": [[180, "bitorch_engine.utils.safe_import.ExtensionModulePlaceholder.__setattr__"]], "_name (bitorch_engine.utils.safe_import.extensionmoduleplaceholder attribute)": [[180, "bitorch_engine.utils.safe_import.ExtensionModulePlaceholder._name"]], "import_extension() (in module bitorch_engine.utils.safe_import)": [[181, "bitorch_engine.utils.safe_import.import_extension"]]}})