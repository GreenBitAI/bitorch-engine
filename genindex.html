<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Index &mdash; Bitorch Engine 0.2.5 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="_static/sphinx-toolbox-code.css?v=4ee5d529" />

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="_static/documentation_options.js?v=cb850272"></script>
        <script src="_static/doctools.js?v=888ff710"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="#" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Bitorch Engine
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="build_options.html">Build options</a></li>
<li class="toctree-l1"><a class="reference internal" href="documentation.html">Full Documentation</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Bitorch Engine</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Index</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             

<h1 id="index">Index</h1>

<div class="genindex-jumpbox">
 <a href="#_"><strong>_</strong></a>
 | <a href="#A"><strong>A</strong></a>
 | <a href="#B"><strong>B</strong></a>
 | <a href="#C"><strong>C</strong></a>
 | <a href="#D"><strong>D</strong></a>
 | <a href="#E"><strong>E</strong></a>
 | <a href="#F"><strong>F</strong></a>
 | <a href="#G"><strong>G</strong></a>
 | <a href="#H"><strong>H</strong></a>
 | <a href="#I"><strong>I</strong></a>
 | <a href="#K"><strong>K</strong></a>
 | <a href="#L"><strong>L</strong></a>
 | <a href="#M"><strong>M</strong></a>
 | <a href="#N"><strong>N</strong></a>
 | <a href="#O"><strong>O</strong></a>
 | <a href="#P"><strong>P</strong></a>
 | <a href="#Q"><strong>Q</strong></a>
 | <a href="#R"><strong>R</strong></a>
 | <a href="#S"><strong>S</strong></a>
 | <a href="#T"><strong>T</strong></a>
 | <a href="#U"><strong>U</strong></a>
 | <a href="#V"><strong>V</strong></a>
 | <a href="#W"><strong>W</strong></a>
 | <a href="#X"><strong>X</strong></a>
 | <a href="#Y"><strong>Y</strong></a>
 | <a href="#Z"><strong>Z</strong></a>
 
</div>
<h2 id="_">_</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.utils.safe_import.ExtensionModulePlaceholder.html#bitorch_engine.utils.safe_import.ExtensionModulePlaceholder.__getattr__">__getattr__() (bitorch_engine.utils.safe_import.ExtensionModulePlaceholder method)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP.html#bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP.__init__">__init__() (bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP method)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.html#bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.__init__">(bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.html#bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.__init__">(bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.html#bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.__init__">(bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.html#bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.__init__">(bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.html#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.__init__">(bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.html#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.__init__">(bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP.html#bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP.__init__">(bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.html#bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.__init__">(bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.html#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.__init__">(bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul.html#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul.__init__">(bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.html#bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.__init__">(bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.layer.QLinearInf.html#bitorch_engine.layers.qlinear.layer.QLinearInf.__init__">(bitorch_engine.layers.qlinear.layer.QLinearInf method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.html#bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.__init__">(bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.html#bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.__init__">(bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.html#bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.__init__">(bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.html#bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.__init__">(bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.html#bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.__init__">(bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.__init__">(bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.html#bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.__init__">(bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.__init__">(bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.html#bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.__init__">(bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qmha.binary.layer.BMHA.html#bitorch_engine.layers.qmha.binary.layer.BMHA.__init__">(bitorch_engine.layers.qmha.binary.layer.BMHA method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qmha.binary.layer.LearnableBias.html#bitorch_engine.layers.qmha.binary.layer.LearnableBias.__init__">(bitorch_engine.layers.qmha.binary.layer.LearnableBias method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.optim.diode_beta.DiodeMix.html#bitorch_engine.optim.diode_beta.DiodeMix.__init__">(bitorch_engine.optim.diode_beta.DiodeMix method)</a>, <a href="_autosummary/bitorch_engine.optim.diode_beta.DiodeMix.html#id0">[1]</a>
</li>
        <li><a href="_autosummary/bitorch_engine.optim.galore_projector.GaLoreProjector.html#bitorch_engine.optim.galore_projector.GaLoreProjector.__init__">(bitorch_engine.optim.galore_projector.GaLoreProjector method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.utils.safe_import.ExtensionModulePlaceholder.html#bitorch_engine.utils.safe_import.ExtensionModulePlaceholder.__init__">(bitorch_engine.utils.safe_import.ExtensionModulePlaceholder method)</a>, <a href="_autosummary/bitorch_engine.utils.safe_import.ExtensionModulePlaceholder.html#id0">[1]</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.utils.safe_import.ExtensionModulePlaceholder.html#bitorch_engine.utils.safe_import.ExtensionModulePlaceholder.__setattr__">__setattr__() (bitorch_engine.utils.safe_import.ExtensionModulePlaceholder method)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.html#bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase._check_forward">_check_forward() (bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase method)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.html#bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass._check_forward">(bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.html#bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass._check_forward">(bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass method)</a>
</li>
      </ul></li>
      <li><a href="_autosummary/bitorch_engine.utils.safe_import.ExtensionModulePlaceholder.html#bitorch_engine.utils.safe_import.ExtensionModulePlaceholder._name">_name (bitorch_engine.utils.safe_import.ExtensionModulePlaceholder attribute)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="A">A</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.html#bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.a_bit">a_bit (bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda attribute)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.a_bit">(bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.a_bit">(bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.html#bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.a_bit">(bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx attribute)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingParameter.html#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingParameter.active_indices">active_indices (bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingParameter attribute)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM.html#bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM.ADAPTIVE">ADAPTIVE (bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM attribute)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.utils.arch_helper.ARCH_CPU.html#bitorch_engine.utils.arch_helper.ARCH_CPU">ARCH_CPU (class in bitorch_engine.utils.arch_helper)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.asym">asym (bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase attribute)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.html#bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.asym">(bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter attribute)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="B">B</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward.html#bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward.backward">backward (bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward attribute)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dForward.html#bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dForward.backward">backward() (bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dForward static method)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward.html#id0">(bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward.html#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward.backward">(bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingForward.html#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingForward.backward">(bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingForward static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.html#bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.backward">(bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward.html#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward.backward">(bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMulFunction.html#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMulFunction.backward">(bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMulFunction static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction.html#bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction.backward">(bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCudaFunction.html#bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCudaFunction.backward">(bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCudaFunction static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearFunction.html#bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearFunction.backward">(bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearFunction static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMulFunction.html#bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMulFunction.backward">(bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMulFunction static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearFunction.html#bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearFunction.backward">(bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearFunction static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlxFunction.html#bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlxFunction.backward">(bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlxFunction static method)</a>
</li>
      </ul></li>
      <li><a href="_autosummary/bitorch_engine.optim.diode_beta.DiodeMix.html#bitorch_engine.optim.diode_beta.DiodeMix.betas">betas (bitorch_engine.optim.diode_beta.DiodeMix attribute)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qmha.binary.layer.LearnableBias.html#bitorch_engine.layers.qmha.binary.layer.LearnableBias.bias">bias (bitorch_engine.layers.qmha.binary.layer.LearnableBias attribute)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.html#bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.bias_a">bias_a (bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass attribute)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.html#bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.bias_a">(bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.html#bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.bias_a">(bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.html#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.bias_a">(bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.html#bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.bias_a">(bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.html#bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.bias_a">(bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass attribute)</a>
</li>
      </ul></li>
      <li><a href="_autosummary/bitorch_engine.utils.model_helper.binary_matmul_forward_post_processing.html#bitorch_engine.utils.model_helper.binary_matmul_forward_post_processing">binary_matmul_forward_post_processing() (in module bitorch_engine.utils.model_helper)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.html#bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase">BinaryConv2dBase (class in bitorch_engine.layers.qconv.binary.layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP.html#bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP">BinaryConv2dCPP (class in bitorch_engine.layers.qconv.binary.cpp.layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.html#bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass">BinaryConv2dCutlass (class in bitorch_engine.layers.qconv.binary.cutlass.layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dForward.html#bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dForward">BinaryConv2dForward (class in bitorch_engine.layers.qconv.binary.cpp.layer)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dForward.html#bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dForward">(class in bitorch_engine.layers.qconv.binary.cutlass.layer)</a>
</li>
      </ul></li>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.layer.BinaryConvParameter.html#bitorch_engine.layers.qconv.binary.layer.BinaryConvParameter">BinaryConvParameter (class in bitorch_engine.layers.qconv.binary.layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.html#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag">BinaryEmbeddingBag (class in bitorch_engine.layers.qembedding.binary.layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward.html#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward">BinaryEmbeddingBagForward (class in bitorch_engine.layers.qembedding.binary.layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.html#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda">BinaryEmbeddingCuda (class in bitorch_engine.layers.qembedding.binary.layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingForward.html#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingForward">BinaryEmbeddingForward (class in bitorch_engine.layers.qembedding.binary.layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingParameter.html#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingParameter">BinaryEmbeddingParameter (class in bitorch_engine.layers.qembedding.binary.layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.html#bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase">BinaryLinearBase (class in bitorch_engine.layers.qlinear.binary.layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP.html#bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP">BinaryLinearCPP (class in bitorch_engine.layers.qlinear.binary.cpp.layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.html#bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda">BinaryLinearCuda (class in bitorch_engine.layers.qlinear.binary.cuda.layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.html#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass">BinaryLinearCutlass (class in bitorch_engine.layers.qlinear.binary.cutlass.layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearForward.html#bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearForward">BinaryLinearForward (class in bitorch_engine.layers.qlinear.binary.cpp.layer)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.html#bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward">(class in bitorch_engine.layers.qlinear.binary.cuda.layer)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward.html#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward">(class in bitorch_engine.layers.qlinear.binary.cutlass.layer)</a>
</li>
      </ul></li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.binary_implementation.BinaryLinearImplementationMixin.html#bitorch_engine.layers.qlinear.binary.binary_implementation.BinaryLinearImplementationMixin">BinaryLinearImplementationMixin (class in bitorch_engine.layers.qlinear.binary.binary_implementation)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearParameter.html#bitorch_engine.layers.qlinear.binary.layer.BinaryLinearParameter">BinaryLinearParameter (class in bitorch_engine.layers.qlinear.binary.layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul.html#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul">BinaryMatMul (class in bitorch_engine.layers.qlinear.binary.cutlass.layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMulFunction.html#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMulFunction">BinaryMatMulFunction (class in bitorch_engine.layers.qlinear.binary.cutlass.layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.utils.quant_operators.bit_set.html#bitorch_engine.utils.quant_operators.bit_set">bit_set() (in module bitorch_engine.utils.quant_operators)</a>
</li>
      <li>
    bitorch_engine

      <ul>
        <li><a href="_autosummary/bitorch_engine.html#module-bitorch_engine">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.functions

      <ul>
        <li><a href="_autosummary/bitorch_engine.functions.html#module-bitorch_engine.functions">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.functions.cuda

      <ul>
        <li><a href="_autosummary/bitorch_engine.functions.cuda.html#module-bitorch_engine.functions.cuda">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.functions.cuda.extension

      <ul>
        <li><a href="_autosummary/bitorch_engine.functions.cuda.extension.html#module-bitorch_engine.functions.cuda.extension">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.functions.cuda.functions

      <ul>
        <li><a href="_autosummary/bitorch_engine.functions.cuda.functions.html#module-bitorch_engine.functions.cuda.functions">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.html#module-bitorch_engine.layers">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qconv

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.html#module-bitorch_engine.layers.qconv">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qconv.binary

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.html#module-bitorch_engine.layers.qconv.binary">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qconv.binary.cpp

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cpp.html#module-bitorch_engine.layers.qconv.binary.cpp">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qconv.binary.cpp.extension

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cpp.extension.html#module-bitorch_engine.layers.qconv.binary.cpp.extension">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qconv.binary.cpp.layer

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cpp.layer.html#module-bitorch_engine.layers.qconv.binary.cpp.layer">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qconv.binary.cutlass

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cutlass.html#module-bitorch_engine.layers.qconv.binary.cutlass">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qconv.binary.cutlass.extension

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cutlass.extension.html#module-bitorch_engine.layers.qconv.binary.cutlass.extension">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qconv.binary.cutlass.layer

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer.html#module-bitorch_engine.layers.qconv.binary.cutlass.layer">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qconv.binary.layer

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.layer.html#module-bitorch_engine.layers.qconv.binary.layer">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qconv.nbit

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.html#module-bitorch_engine.layers.qconv.nbit">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qconv.nbit.cutlass

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.html#module-bitorch_engine.layers.qconv.nbit.cutlass">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qconv.nbit.cutlass.extension

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.extension.html#module-bitorch_engine.layers.qconv.nbit.cutlass.extension">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qconv.nbit.cutlass.layer

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer.html#module-bitorch_engine.layers.qconv.nbit.cutlass.layer">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qconv.nbit.layer

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.layer.html#module-bitorch_engine.layers.qconv.nbit.layer">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qembedding

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qembedding.html#module-bitorch_engine.layers.qembedding">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qembedding.binary

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qembedding.binary.html#module-bitorch_engine.layers.qembedding.binary">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qembedding.binary.layer

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qembedding.binary.layer.html#module-bitorch_engine.layers.qembedding.binary.layer">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.html#module-bitorch_engine.layers.qlinear">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.binary

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.html#module-bitorch_engine.layers.qlinear.binary">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.binary.binary_implementation

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.binary_implementation.html#module-bitorch_engine.layers.qlinear.binary.binary_implementation">module</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li>
    bitorch_engine.layers.qlinear.binary.cpp

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cpp.html#module-bitorch_engine.layers.qlinear.binary.cpp">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.binary.cpp.extension

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cpp.extension.html#module-bitorch_engine.layers.qlinear.binary.cpp.extension">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.binary.cpp.layer

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cpp.layer.html#module-bitorch_engine.layers.qlinear.binary.cpp.layer">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.binary.cuda

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.html#module-bitorch_engine.layers.qlinear.binary.cuda">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.binary.cuda.bmm

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.bmm.html#module-bitorch_engine.layers.qlinear.binary.cuda.bmm">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.binary.cuda.extension

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.extension.html#module-bitorch_engine.layers.qlinear.binary.cuda.extension">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.binary.cuda.layer

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.html#module-bitorch_engine.layers.qlinear.binary.cuda.layer">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.binary.cutlass

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.html#module-bitorch_engine.layers.qlinear.binary.cutlass">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.binary.cutlass.extension

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.extension.html#module-bitorch_engine.layers.qlinear.binary.cutlass.extension">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.binary.cutlass.layer

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.html#module-bitorch_engine.layers.qlinear.binary.cutlass.layer">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.binary.layer

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.html#module-bitorch_engine.layers.qlinear.binary.layer">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.layer

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.layer.html#module-bitorch_engine.layers.qlinear.layer">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.nbit

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.html#module-bitorch_engine.layers.qlinear.nbit">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.nbit.cuda

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.html#module-bitorch_engine.layers.qlinear.nbit.cuda">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.nbit.cuda.extension

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.extension.html#module-bitorch_engine.layers.qlinear.nbit.cuda.extension">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.html#module-bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.html#module-bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.nbit.cuda.utils

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.utils.html#module-bitorch_engine.layers.qlinear.nbit.cuda.utils">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.nbit.cutlass

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.html#module-bitorch_engine.layers.qlinear.nbit.cutlass">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.nbit.cutlass.extension

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.extension.html#module-bitorch_engine.layers.qlinear.nbit.cutlass.extension">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.html#module-bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.html#module-bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.nbit.layer

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.html#module-bitorch_engine.layers.qlinear.nbit.layer">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.nbit.mps

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.mps.html#module-bitorch_engine.layers.qlinear.nbit.mps">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.nbit.mps.extension

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.mps.extension.html#module-bitorch_engine.layers.qlinear.nbit.mps.extension">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.nbit.mps.mpq_layer

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.html#module-bitorch_engine.layers.qlinear.nbit.mps.mpq_layer">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qlinear.qlinear_implementation

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.qlinear_implementation.html#module-bitorch_engine.layers.qlinear.qlinear_implementation">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qmha

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qmha.html#module-bitorch_engine.layers.qmha">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qmha.binary

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qmha.binary.html#module-bitorch_engine.layers.qmha.binary">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.layers.qmha.binary.layer

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qmha.binary.layer.html#module-bitorch_engine.layers.qmha.binary.layer">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.optim

      <ul>
        <li><a href="_autosummary/bitorch_engine.optim.html#module-bitorch_engine.optim">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.optim.diode_beta

      <ul>
        <li><a href="_autosummary/bitorch_engine.optim.diode_beta.html#module-bitorch_engine.optim.diode_beta">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.optim.galore_projector

      <ul>
        <li><a href="_autosummary/bitorch_engine.optim.galore_projector.html#module-bitorch_engine.optim.galore_projector">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.utils

      <ul>
        <li><a href="_autosummary/bitorch_engine.utils.html#module-bitorch_engine.utils">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.utils.arch_helper

      <ul>
        <li><a href="_autosummary/bitorch_engine.utils.arch_helper.html#module-bitorch_engine.utils.arch_helper">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.utils.convert

      <ul>
        <li><a href="_autosummary/bitorch_engine.utils.convert.html#module-bitorch_engine.utils.convert">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.utils.cpp_extension

      <ul>
        <li><a href="_autosummary/bitorch_engine.utils.cpp_extension.html#module-bitorch_engine.utils.cpp_extension">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.utils.cuda_extension

      <ul>
        <li><a href="_autosummary/bitorch_engine.utils.cuda_extension.html#module-bitorch_engine.utils.cuda_extension">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.utils.cutlass_path

      <ul>
        <li><a href="_autosummary/bitorch_engine.utils.cutlass_path.html#module-bitorch_engine.utils.cutlass_path">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.utils.mlx_extension

      <ul>
        <li><a href="_autosummary/bitorch_engine.utils.mlx_extension.html#module-bitorch_engine.utils.mlx_extension">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.utils.mlx_path

      <ul>
        <li><a href="_autosummary/bitorch_engine.utils.mlx_path.html#module-bitorch_engine.utils.mlx_path">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.utils.model_helper

      <ul>
        <li><a href="_autosummary/bitorch_engine.utils.model_helper.html#module-bitorch_engine.utils.model_helper">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.utils.quant_operators

      <ul>
        <li><a href="_autosummary/bitorch_engine.utils.quant_operators.html#module-bitorch_engine.utils.quant_operators">module</a>
</li>
      </ul></li>
      <li>
    bitorch_engine.utils.safe_import

      <ul>
        <li><a href="_autosummary/bitorch_engine.utils.safe_import.html#module-bitorch_engine.utils.safe_import">module</a>
</li>
      </ul></li>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP.html#bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP.bits_binary_word">bits_binary_word (bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP attribute)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.html#bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.bits_binary_word">(bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.html#bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.bits_binary_word">(bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.html#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.bits_binary_word">(bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.html#bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.bits_binary_word">(bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase attribute)</a>
</li>
      </ul></li>
      <li><a href="_autosummary/bitorch_engine.layers.qmha.binary.layer.BMHA.html#bitorch_engine.layers.qmha.binary.layer.BMHA">BMHA (class in bitorch_engine.layers.qmha.binary.layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM.html#bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM">BMM (class in bitorch_engine.layers.qlinear.binary.cuda.bmm)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.html#bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.bmm_type">bmm_type (bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda attribute)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.html#bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.bmm_type">(bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward attribute)</a>
</li>
      </ul></li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM.html#bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM.BSTC32">BSTC32 (bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM attribute)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM.html#bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM.BTC32">BTC32 (bitorch_engine.layers.qlinear.binary.cuda.bmm.BMM attribute)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="C">C</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.binary_implementation.BinaryLinearImplementationMixin.html#id0">can_clone() (bitorch_engine.layers.qlinear.binary.binary_implementation.BinaryLinearImplementationMixin class method)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.binary_implementation.BinaryLinearImplementationMixin.html#bitorch_engine.layers.qlinear.binary.binary_implementation.BinaryLinearImplementationMixin.can_clone">(bitorch_engine.layers.qlinear.binary.binary_implementation.BinaryLinearImplementationMixin method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.qlinear_implementation.QLinearImplementationMixin.html#bitorch_engine.layers.qlinear.qlinear_implementation.QLinearImplementationMixin.can_clone">(bitorch_engine.layers.qlinear.qlinear_implementation.QLinearImplementationMixin class method)</a>
</li>
      </ul></li>
      <li><a href="_autosummary/bitorch_engine.utils.arch_helper.check_cpu_instruction_support.html#bitorch_engine.utils.arch_helper.check_cpu_instruction_support">check_cpu_instruction_support() (in module bitorch_engine.utils.arch_helper)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.html#bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.check_parameters">check_parameters() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.html#id0">[1]</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.html#bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.check_parameters">(bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.html#id0">[1]</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.check_parameters">(bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.html#id0">[1]</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.html#bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.check_parameters">(bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.html#id0">[1]</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.utils.cutlass_path.check_path.html#bitorch_engine.utils.cutlass_path.check_path">check_path() (in module bitorch_engine.utils.cutlass_path)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.optim.diode_beta.check_pytorch_version.html#bitorch_engine.optim.diode_beta.check_pytorch_version">check_pytorch_version() (in module bitorch_engine.optim.diode_beta)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.utils.convert.collect_layers.html#bitorch_engine.utils.convert.collect_layers">collect_layers() (in module bitorch_engine.utils.convert)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.optim.diode_beta.DiodeMix.html#bitorch_engine.optim.diode_beta.DiodeMix.correct_bias">correct_bias (bitorch_engine.optim.diode_beta.DiodeMix attribute)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP.html#bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP.create_clone_from">create_clone_from() (bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP class method)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.html#bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.create_clone_from">(bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda class method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.layer.QLinearInf.html#bitorch_engine.layers.qlinear.layer.QLinearInf.create_clone_from">(bitorch_engine.layers.qlinear.layer.QLinearInf class method)</a>
</li>
      </ul></li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.html#bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.ctx">ctx (bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward attribute)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="D">D</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.html#bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.device">device (bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase attribute)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.html#bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.device">(bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.device">(bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase attribute)</a>
</li>
      </ul></li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.html#bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.device_id">device_id (bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda property)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.optim.diode_beta.DiodeMix.html#bitorch_engine.optim.diode_beta.DiodeMix">DiodeMix (class in bitorch_engine.optim.diode_beta)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.disable_bias">disable_bias (bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase attribute)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.dq_group_size">dq_group_size (bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase attribute)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.dq_mode">dq_mode (bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase attribute)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qmha.binary.layer.BMHA.html#bitorch_engine.layers.qmha.binary.layer.BMHA.dropout">dropout (bitorch_engine.layers.qmha.binary.layer.BMHA attribute)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul.html#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul.dtype">dtype (bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul attribute)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.html#bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.dtype">(bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.html#bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.dtype">(bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.dtype">(bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.dtype">(bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qmha.binary.layer.BMHA.html#bitorch_engine.layers.qmha.binary.layer.BMHA.dtype">(bitorch_engine.layers.qmha.binary.layer.BMHA attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.optim.diode_beta.DiodeMix.html#bitorch_engine.optim.diode_beta.DiodeMix.dtype">(bitorch_engine.optim.diode_beta.DiodeMix attribute)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="E">E</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.html#bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.eps">eps (bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass attribute)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.html#bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.eps">(bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.html#bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.eps">(bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.html#bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.eps">(bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.optim.diode_beta.DiodeMix.html#bitorch_engine.optim.diode_beta.DiodeMix.eps">(bitorch_engine.optim.diode_beta.DiodeMix attribute)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.html#bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.exl2fp_weight">exl2fp_weight() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda method)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.html#id1">(bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda static method)</a>
</li>
      </ul></li>
      <li><a href="_autosummary/bitorch_engine.utils.safe_import.ExtensionModulePlaceholder.html#bitorch_engine.utils.safe_import.ExtensionModulePlaceholder">ExtensionModulePlaceholder (class in bitorch_engine.utils.safe_import)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="F">F</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.utils.cutlass_path.find_cutlass.html#bitorch_engine.utils.cutlass_path.find_cutlass">find_cutlass() (in module bitorch_engine.utils.cutlass_path)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.utils.model_helper.flatten_x.html#bitorch_engine.utils.model_helper.flatten_x">flatten_x() (in module bitorch_engine.utils.model_helper)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward.html#bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward.forward">forward (bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward attribute)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP.html#bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP.forward">forward() (bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP method)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dForward.html#bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dForward.forward">(bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dForward static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.html#bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.forward">(bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dForward.html#bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dForward.forward">(bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dForward static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.html#bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.forward">(bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward.html#id1">(bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.html#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.forward">(bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward.html#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward.forward">(bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.html#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.forward">(bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingForward.html#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingForward.forward">(bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingForward static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP.html#bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP.forward">(bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearForward.html#bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearForward.forward">(bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearForward static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.html#bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.forward">(bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.html#bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.forward">(bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.html#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.forward">(bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.html#id0">[1]</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward.html#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward.forward">(bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul.html#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul.forward">(bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMulFunction.html#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMulFunction.forward">(bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMulFunction static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.layer.QLinearInf.html#bitorch_engine.layers.qlinear.layer.QLinearInf.forward">(bitorch_engine.layers.qlinear.layer.QLinearInf method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.html#bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.forward">(bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.html#id2">[1]</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction.html#bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction.forward">(bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.html#bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.forward">(bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.html#id1">[1]</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCudaFunction.html#bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCudaFunction.forward">(bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCudaFunction static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.html#bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.forward">(bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.html#id0">[1]</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearFunction.html#bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearFunction.forward">(bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearFunction static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.html#bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.forward">(bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMulFunction.html#bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMulFunction.forward">(bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMulFunction static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.html#bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.forward">(bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.html#id0">[1]</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearFunction.html#bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearFunction.forward">(bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearFunction static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.html#bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.forward">(bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.html#id1">[1]</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlxFunction.html#bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlxFunction.forward">(bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlxFunction static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qmha.binary.layer.BMHA.html#bitorch_engine.layers.qmha.binary.layer.BMHA.forward">(bitorch_engine.layers.qmha.binary.layer.BMHA method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qmha.binary.layer.LearnableBias.html#bitorch_engine.layers.qmha.binary.layer.LearnableBias.forward">(bitorch_engine.layers.qmha.binary.layer.LearnableBias method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.functions.cuda.functions.fp32toint4.html#bitorch_engine.functions.cuda.functions.fp32toint4">fp32toint4() (in module bitorch_engine.functions.cuda.functions)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="G">G</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.html#bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.g_idx">g_idx (bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter attribute)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.optim.galore_projector.GaLoreProjector.html#bitorch_engine.optim.galore_projector.GaLoreProjector">GaLoreProjector (class in bitorch_engine.optim.galore_projector)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.utils.cuda_extension.gcc_version.html#bitorch_engine.utils.cuda_extension.gcc_version">gcc_version() (in module bitorch_engine.utils.cuda_extension)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.html#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.gemm_kernel_id">gemm_kernel_id (bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass attribute)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP.html#bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP.generate_quantized_weight">generate_quantized_weight() (bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP method)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.html#bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.generate_quantized_weight">(bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.html#bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.generate_quantized_weight">(bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.html#bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.generate_quantized_weight">(bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.html#bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.generate_quantized_weight">(bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP.html#bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP.generate_quantized_weight">(bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.html#bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.generate_quantized_weight">(bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.html#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.generate_quantized_weight">(bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.html#id1">[1]</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.html#bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.generate_quantized_weight">(bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.html#id0">[1]</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.layer.QLinearInf.html#bitorch_engine.layers.qlinear.layer.QLinearInf.generate_quantized_weight">(bitorch_engine.layers.qlinear.layer.QLinearInf method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.html#bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.generate_quantized_weight">(bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.html#id1">[1]</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.html#bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.generate_quantized_weight">(bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.html#id1">[1]</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.generate_quantized_weight">(bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.html#id1">[1]</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.generate_quantized_weight">(bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase method)</a>
</li>
      </ul></li>
      <li><a href="_autosummary/bitorch_engine.utils.arch_helper.linux_arch_ident.html#bitorch_engine.utils.arch_helper.linux_arch_ident.get_arm_model">get_arm_model() (bitorch_engine.utils.arch_helper.linux_arch_ident static method)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.get_best_binary_implementation.html#bitorch_engine.layers.qlinear.binary.get_best_binary_implementation">get_best_binary_implementation() (in module bitorch_engine.layers.qlinear.binary)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.utils.quant_operators.get_binary_col.html#bitorch_engine.utils.quant_operators.get_binary_col">get_binary_col() (in module bitorch_engine.utils.quant_operators)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.utils.quant_operators.get_binary_row.html#bitorch_engine.utils.quant_operators.get_binary_row">get_binary_row() (in module bitorch_engine.utils.quant_operators)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.utils.cpp_extension.get_cpp_extension.html#bitorch_engine.utils.cpp_extension.get_cpp_extension">get_cpp_extension() (in module bitorch_engine.utils.cpp_extension)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.utils.cuda_extension.get_cuda_extension.html#bitorch_engine.utils.cuda_extension.get_cuda_extension">get_cuda_extension() (in module bitorch_engine.utils.cuda_extension)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.utils.cutlass_path.get_cutlass_include_path.html#bitorch_engine.utils.cutlass_path.get_cutlass_include_path">get_cutlass_include_path() (in module bitorch_engine.utils.cutlass_path)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.functions.cuda.extension.get_ext.html#bitorch_engine.functions.cuda.extension.get_ext">get_ext() (in module bitorch_engine.functions.cuda.extension)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cpp.extension.get_ext.html#bitorch_engine.layers.qconv.binary.cpp.extension.get_ext">(in module bitorch_engine.layers.qconv.binary.cpp.extension)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cutlass.extension.get_ext.html#bitorch_engine.layers.qconv.binary.cutlass.extension.get_ext">(in module bitorch_engine.layers.qconv.binary.cutlass.extension)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.extension.get_ext.html#bitorch_engine.layers.qconv.nbit.cutlass.extension.get_ext">(in module bitorch_engine.layers.qconv.nbit.cutlass.extension)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cpp.extension.get_ext.html#bitorch_engine.layers.qlinear.binary.cpp.extension.get_ext">(in module bitorch_engine.layers.qlinear.binary.cpp.extension)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.extension.get_ext.html#bitorch_engine.layers.qlinear.binary.cuda.extension.get_ext">(in module bitorch_engine.layers.qlinear.binary.cuda.extension)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.extension.get_ext.html#bitorch_engine.layers.qlinear.binary.cutlass.extension.get_ext">(in module bitorch_engine.layers.qlinear.binary.cutlass.extension)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.extension.get_ext.html#bitorch_engine.layers.qlinear.nbit.cuda.extension.get_ext">(in module bitorch_engine.layers.qlinear.nbit.cuda.extension)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.extension.get_ext.html#bitorch_engine.layers.qlinear.nbit.cutlass.extension.get_ext">(in module bitorch_engine.layers.qlinear.nbit.cutlass.extension)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.mps.extension.get_ext.html#bitorch_engine.layers.qlinear.nbit.mps.extension.get_ext">(in module bitorch_engine.layers.qlinear.nbit.mps.extension)</a>
</li>
      </ul></li>
      <li><a href="_autosummary/bitorch_engine.utils.cpp_extension.get_kwargs.html#bitorch_engine.utils.cpp_extension.get_kwargs">get_kwargs() (in module bitorch_engine.utils.cpp_extension)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.utils.cuda_extension.get_kwargs.html#bitorch_engine.utils.cuda_extension.get_kwargs">(in module bitorch_engine.utils.cuda_extension)</a>
</li>
      </ul></li>
      <li><a href="_autosummary/bitorch_engine.utils.mlx_extension.get_mlx_extension.html#bitorch_engine.utils.mlx_extension.get_mlx_extension">get_mlx_extension() (in module bitorch_engine.utils.mlx_extension)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.utils.mlx_path.get_mlx_include_path.html#bitorch_engine.utils.mlx_path.get_mlx_include_path">get_mlx_include_path() (in module bitorch_engine.utils.mlx_path)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.utils.mlx_path.get_mlx_lib_path.html#bitorch_engine.utils.mlx_path.get_mlx_lib_path">get_mlx_lib_path() (in module bitorch_engine.utils.mlx_path)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.utils.convert.get_mpq_config.html#bitorch_engine.utils.convert.get_mpq_config">get_mpq_config() (in module bitorch_engine.utils.convert)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.utils.quant_operators.gptq_style_unpacking.html#bitorch_engine.utils.quant_operators.gptq_style_unpacking">gptq_style_unpacking() (in module bitorch_engine.utils.quant_operators)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.utils.quant_operators.gptq_style_zeros_packing.html#bitorch_engine.utils.quant_operators.gptq_style_zeros_packing">gptq_style_zeros_packing() (in module bitorch_engine.utils.quant_operators)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.group_size">group_size (bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase attribute)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.html#bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.group_size">(bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter attribute)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="H">H</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qmha.binary.layer.BMHA.html#bitorch_engine.layers.qmha.binary.layer.BMHA.head_dim">head_dim (bitorch_engine.layers.qmha.binary.layer.BMHA attribute)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qmha.binary.layer.BMHA.html#bitorch_engine.layers.qmha.binary.layer.BMHA.hidden_dim">hidden_dim (bitorch_engine.layers.qmha.binary.layer.BMHA attribute)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="I">I</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.utils.safe_import.import_extension.html#bitorch_engine.utils.safe_import.import_extension">import_extension() (in module bitorch_engine.utils.safe_import)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.in_channels">in_channels (bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase attribute)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.in_channels">(bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase attribute)</a>
</li>
      </ul></li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.init_gba">init_gba() (bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.html#id2">[1]</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.init_gptq">init_gptq() (bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.html#id3">[1]</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.html#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.init_weight">init_weight() (bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda method)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.utils.model_helper.init_weight.html#bitorch_engine.utils.model_helper.init_weight">(in module bitorch_engine.utils.model_helper)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.initialize">initialize() (bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.html#id4">[1]</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.html#bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.input">input (bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward attribute)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qmha.binary.layer.BMHA.html#bitorch_engine.layers.qmha.binary.layer.BMHA.input_dim">input_dim (bitorch_engine.layers.qmha.binary.layer.BMHA attribute)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.html#bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.input_features">input_features (bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase attribute)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.utils.arch_helper.linux_arch_ident.html#bitorch_engine.utils.arch_helper.linux_arch_ident.is_arm">is_arm() (bitorch_engine.utils.arch_helper.linux_arch_ident static method)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.utils.cutlass_path.is_cutlass_available.html#bitorch_engine.utils.cutlass_path.is_cutlass_available">is_cutlass_available() (in module bitorch_engine.utils.cutlass_path)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.utils.mlx_path.is_mlx_available.html#bitorch_engine.utils.mlx_path.is_mlx_available">is_mlx_available() (in module bitorch_engine.utils.mlx_path)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.html#bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.is_train">is_train (bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward attribute)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="K">K</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qmha.binary.layer.BMHA.html#bitorch_engine.layers.qmha.binary.layer.BMHA.k_linear">k_linear (bitorch_engine.layers.qmha.binary.layer.BMHA attribute)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="L">L</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.html#bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.layer_type">layer_type (bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter attribute)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qmha.binary.layer.LearnableBias.html#bitorch_engine.layers.qmha.binary.layer.LearnableBias">LearnableBias (class in bitorch_engine.layers.qmha.binary.layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.utils.arch_helper.linux_arch_ident.html#bitorch_engine.utils.arch_helper.linux_arch_ident">linux_arch_ident (class in bitorch_engine.utils.arch_helper)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.utils.model_helper.load_checkpoint.html#bitorch_engine.utils.model_helper.load_checkpoint">load_checkpoint() (in module bitorch_engine.utils.model_helper)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.html#bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.load_state_dict">load_state_dict() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.html#id3">[1]</a>
</li>
      <li><a href="_autosummary/bitorch_engine.optim.diode_beta.DiodeMix.html#bitorch_engine.optim.diode_beta.DiodeMix.lr">lr (bitorch_engine.optim.diode_beta.DiodeMix attribute)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="M">M</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.utils.make_group_map.html#bitorch_engine.layers.qlinear.nbit.cuda.utils.make_group_map">make_group_map() (in module bitorch_engine.layers.qlinear.nbit.cuda.utils)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.html#bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda">MBWQLinearCuda (class in bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction.html#bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction">MBWQLinearCudaFunction (class in bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer)</a>
</li>
      <li>
    module

      <ul>
        <li><a href="_autosummary/bitorch_engine.html#module-bitorch_engine">bitorch_engine</a>
</li>
        <li><a href="_autosummary/bitorch_engine.functions.html#module-bitorch_engine.functions">bitorch_engine.functions</a>
</li>
        <li><a href="_autosummary/bitorch_engine.functions.cuda.html#module-bitorch_engine.functions.cuda">bitorch_engine.functions.cuda</a>
</li>
        <li><a href="_autosummary/bitorch_engine.functions.cuda.extension.html#module-bitorch_engine.functions.cuda.extension">bitorch_engine.functions.cuda.extension</a>
</li>
        <li><a href="_autosummary/bitorch_engine.functions.cuda.functions.html#module-bitorch_engine.functions.cuda.functions">bitorch_engine.functions.cuda.functions</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.html#module-bitorch_engine.layers">bitorch_engine.layers</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.html#module-bitorch_engine.layers.qconv">bitorch_engine.layers.qconv</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.html#module-bitorch_engine.layers.qconv.binary">bitorch_engine.layers.qconv.binary</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cpp.html#module-bitorch_engine.layers.qconv.binary.cpp">bitorch_engine.layers.qconv.binary.cpp</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cpp.extension.html#module-bitorch_engine.layers.qconv.binary.cpp.extension">bitorch_engine.layers.qconv.binary.cpp.extension</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cpp.layer.html#module-bitorch_engine.layers.qconv.binary.cpp.layer">bitorch_engine.layers.qconv.binary.cpp.layer</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cutlass.html#module-bitorch_engine.layers.qconv.binary.cutlass">bitorch_engine.layers.qconv.binary.cutlass</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cutlass.extension.html#module-bitorch_engine.layers.qconv.binary.cutlass.extension">bitorch_engine.layers.qconv.binary.cutlass.extension</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer.html#module-bitorch_engine.layers.qconv.binary.cutlass.layer">bitorch_engine.layers.qconv.binary.cutlass.layer</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.layer.html#module-bitorch_engine.layers.qconv.binary.layer">bitorch_engine.layers.qconv.binary.layer</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.html#module-bitorch_engine.layers.qconv.nbit">bitorch_engine.layers.qconv.nbit</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.html#module-bitorch_engine.layers.qconv.nbit.cutlass">bitorch_engine.layers.qconv.nbit.cutlass</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.extension.html#module-bitorch_engine.layers.qconv.nbit.cutlass.extension">bitorch_engine.layers.qconv.nbit.cutlass.extension</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer.html#module-bitorch_engine.layers.qconv.nbit.cutlass.layer">bitorch_engine.layers.qconv.nbit.cutlass.layer</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.layer.html#module-bitorch_engine.layers.qconv.nbit.layer">bitorch_engine.layers.qconv.nbit.layer</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qembedding.html#module-bitorch_engine.layers.qembedding">bitorch_engine.layers.qembedding</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qembedding.binary.html#module-bitorch_engine.layers.qembedding.binary">bitorch_engine.layers.qembedding.binary</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qembedding.binary.layer.html#module-bitorch_engine.layers.qembedding.binary.layer">bitorch_engine.layers.qembedding.binary.layer</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.html#module-bitorch_engine.layers.qlinear">bitorch_engine.layers.qlinear</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.html#module-bitorch_engine.layers.qlinear.binary">bitorch_engine.layers.qlinear.binary</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.binary_implementation.html#module-bitorch_engine.layers.qlinear.binary.binary_implementation">bitorch_engine.layers.qlinear.binary.binary_implementation</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cpp.html#module-bitorch_engine.layers.qlinear.binary.cpp">bitorch_engine.layers.qlinear.binary.cpp</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cpp.extension.html#module-bitorch_engine.layers.qlinear.binary.cpp.extension">bitorch_engine.layers.qlinear.binary.cpp.extension</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cpp.layer.html#module-bitorch_engine.layers.qlinear.binary.cpp.layer">bitorch_engine.layers.qlinear.binary.cpp.layer</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.html#module-bitorch_engine.layers.qlinear.binary.cuda">bitorch_engine.layers.qlinear.binary.cuda</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.bmm.html#module-bitorch_engine.layers.qlinear.binary.cuda.bmm">bitorch_engine.layers.qlinear.binary.cuda.bmm</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.extension.html#module-bitorch_engine.layers.qlinear.binary.cuda.extension">bitorch_engine.layers.qlinear.binary.cuda.extension</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.html#module-bitorch_engine.layers.qlinear.binary.cuda.layer">bitorch_engine.layers.qlinear.binary.cuda.layer</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.html#module-bitorch_engine.layers.qlinear.binary.cutlass">bitorch_engine.layers.qlinear.binary.cutlass</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.extension.html#module-bitorch_engine.layers.qlinear.binary.cutlass.extension">bitorch_engine.layers.qlinear.binary.cutlass.extension</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.html#module-bitorch_engine.layers.qlinear.binary.cutlass.layer">bitorch_engine.layers.qlinear.binary.cutlass.layer</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.html#module-bitorch_engine.layers.qlinear.binary.layer">bitorch_engine.layers.qlinear.binary.layer</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.layer.html#module-bitorch_engine.layers.qlinear.layer">bitorch_engine.layers.qlinear.layer</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.html#module-bitorch_engine.layers.qlinear.nbit">bitorch_engine.layers.qlinear.nbit</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.html#module-bitorch_engine.layers.qlinear.nbit.cuda">bitorch_engine.layers.qlinear.nbit.cuda</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.extension.html#module-bitorch_engine.layers.qlinear.nbit.cuda.extension">bitorch_engine.layers.qlinear.nbit.cuda.extension</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.html#module-bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer">bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.html#module-bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer">bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.utils.html#module-bitorch_engine.layers.qlinear.nbit.cuda.utils">bitorch_engine.layers.qlinear.nbit.cuda.utils</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.html#module-bitorch_engine.layers.qlinear.nbit.cutlass">bitorch_engine.layers.qlinear.nbit.cutlass</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.extension.html#module-bitorch_engine.layers.qlinear.nbit.cutlass.extension">bitorch_engine.layers.qlinear.nbit.cutlass.extension</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.html#module-bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer">bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.html#module-bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer">bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.html#module-bitorch_engine.layers.qlinear.nbit.layer">bitorch_engine.layers.qlinear.nbit.layer</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.mps.html#module-bitorch_engine.layers.qlinear.nbit.mps">bitorch_engine.layers.qlinear.nbit.mps</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.mps.extension.html#module-bitorch_engine.layers.qlinear.nbit.mps.extension">bitorch_engine.layers.qlinear.nbit.mps.extension</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.html#module-bitorch_engine.layers.qlinear.nbit.mps.mpq_layer">bitorch_engine.layers.qlinear.nbit.mps.mpq_layer</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.qlinear_implementation.html#module-bitorch_engine.layers.qlinear.qlinear_implementation">bitorch_engine.layers.qlinear.qlinear_implementation</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qmha.html#module-bitorch_engine.layers.qmha">bitorch_engine.layers.qmha</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qmha.binary.html#module-bitorch_engine.layers.qmha.binary">bitorch_engine.layers.qmha.binary</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qmha.binary.layer.html#module-bitorch_engine.layers.qmha.binary.layer">bitorch_engine.layers.qmha.binary.layer</a>
</li>
        <li><a href="_autosummary/bitorch_engine.optim.html#module-bitorch_engine.optim">bitorch_engine.optim</a>
</li>
        <li><a href="_autosummary/bitorch_engine.optim.diode_beta.html#module-bitorch_engine.optim.diode_beta">bitorch_engine.optim.diode_beta</a>
</li>
        <li><a href="_autosummary/bitorch_engine.optim.galore_projector.html#module-bitorch_engine.optim.galore_projector">bitorch_engine.optim.galore_projector</a>
</li>
        <li><a href="_autosummary/bitorch_engine.utils.html#module-bitorch_engine.utils">bitorch_engine.utils</a>
</li>
        <li><a href="_autosummary/bitorch_engine.utils.arch_helper.html#module-bitorch_engine.utils.arch_helper">bitorch_engine.utils.arch_helper</a>
</li>
        <li><a href="_autosummary/bitorch_engine.utils.convert.html#module-bitorch_engine.utils.convert">bitorch_engine.utils.convert</a>
</li>
        <li><a href="_autosummary/bitorch_engine.utils.cpp_extension.html#module-bitorch_engine.utils.cpp_extension">bitorch_engine.utils.cpp_extension</a>
</li>
        <li><a href="_autosummary/bitorch_engine.utils.cuda_extension.html#module-bitorch_engine.utils.cuda_extension">bitorch_engine.utils.cuda_extension</a>
</li>
        <li><a href="_autosummary/bitorch_engine.utils.cutlass_path.html#module-bitorch_engine.utils.cutlass_path">bitorch_engine.utils.cutlass_path</a>
</li>
        <li><a href="_autosummary/bitorch_engine.utils.mlx_extension.html#module-bitorch_engine.utils.mlx_extension">bitorch_engine.utils.mlx_extension</a>
</li>
        <li><a href="_autosummary/bitorch_engine.utils.mlx_path.html#module-bitorch_engine.utils.mlx_path">bitorch_engine.utils.mlx_path</a>
</li>
        <li><a href="_autosummary/bitorch_engine.utils.model_helper.html#module-bitorch_engine.utils.model_helper">bitorch_engine.utils.model_helper</a>
</li>
        <li><a href="_autosummary/bitorch_engine.utils.quant_operators.html#module-bitorch_engine.utils.quant_operators">bitorch_engine.utils.quant_operators</a>
</li>
        <li><a href="_autosummary/bitorch_engine.utils.safe_import.html#module-bitorch_engine.utils.safe_import">bitorch_engine.utils.safe_import</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase">MPQLinearBase (class in bitorch_engine.layers.qlinear.nbit.layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.html#bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda">MPQLinearCuda (class in bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCudaFunction.html#bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCudaFunction">MPQLinearCudaFunction (class in bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.html#bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx">MPQLinearMlx (class in bitorch_engine.layers.qlinear.nbit.mps.mpq_layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlxFunction.html#bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlxFunction">MPQLinearMlxFunction (class in bitorch_engine.layers.qlinear.nbit.mps.mpq_layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.html#bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter">MPQWeightParameter (class in bitorch_engine.layers.qlinear.nbit.layer)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="N">N</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.html#bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase">nBitConv2dBase (class in bitorch_engine.layers.qconv.nbit.layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.layer.nBitConvParameter.html#bitorch_engine.layers.qconv.nbit.layer.nBitConvParameter">nBitConvParameter (class in bitorch_engine.layers.qconv.nbit.layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase">nBitLinearBase (class in bitorch_engine.layers.qlinear.nbit.layer)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.nBitLinearParameter.html#bitorch_engine.layers.qlinear.nbit.layer.nBitLinearParameter">nBitLinearParameter (class in bitorch_engine.layers.qlinear.nbit.layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qmha.binary.layer.BMHA.html#bitorch_engine.layers.qmha.binary.layer.BMHA.num_heads">num_heads (bitorch_engine.layers.qmha.binary.layer.BMHA attribute)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.utils.quant_operators.nv_tensor_quant.html#bitorch_engine.utils.quant_operators.nv_tensor_quant">nv_tensor_quant() (in module bitorch_engine.utils.quant_operators)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="O">O</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.html#bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.opt_weight">opt_weight (bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase property)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.html#bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.opt_weight">(bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase property)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.html#id1">(bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase property)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.layer.QLinearInf.html#bitorch_engine.layers.qlinear.layer.QLinearInf.opt_weight">(bitorch_engine.layers.qlinear.layer.QLinearInf property)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.opt_weight">(bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase property)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.html#bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.opt_weight">opt_weight() (bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase method)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qmha.binary.layer.BMHA.html#bitorch_engine.layers.qmha.binary.layer.BMHA.out">out (bitorch_engine.layers.qmha.binary.layer.BMHA attribute)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.out_channels">out_channels (bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase attribute)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.out_channels">(bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase attribute)</a>
</li>
      </ul></li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.html#bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.output_features">output_features (bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase attribute)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="P">P</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.utils.model_helper.pack_bie_layers.html#bitorch_engine.utils.model_helper.pack_bie_layers">pack_bie_layers() (in module bitorch_engine.utils.model_helper)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.utils.pack_fp_weight.html#bitorch_engine.layers.qlinear.nbit.cuda.utils.pack_fp_weight">pack_fp_weight() (in module bitorch_engine.layers.qlinear.nbit.cuda.utils)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.utils.model_helper.pad_embedding_dim.html#bitorch_engine.utils.model_helper.pad_embedding_dim">pad_embedding_dim() (in module bitorch_engine.utils.model_helper)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.utils.model_helper.pad_last_2_dims_to_multiple_of_128.html#bitorch_engine.utils.model_helper.pad_last_2_dims_to_multiple_of_128">pad_last_2_dims_to_multiple_of_128() (in module bitorch_engine.utils.model_helper)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.optim.diode_beta.DiodeMix.html#bitorch_engine.optim.diode_beta.DiodeMix.params">params (bitorch_engine.optim.diode_beta.DiodeMix attribute)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.utils.model_helper.prepare_bie_layers.html#bitorch_engine.utils.model_helper.prepare_bie_layers">prepare_bie_layers() (in module bitorch_engine.utils.model_helper)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP.html#bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP.prepare_params">prepare_params() (bitorch_engine.layers.qconv.binary.cpp.layer.BinaryConv2dCPP method)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.html#bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.prepare_params">(bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.html#bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.prepare_params">(bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.html#bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.prepare_params">(bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.html#bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.prepare_params">(bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.html#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.prepare_params">(bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP.html#bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP.prepare_params">(bitorch_engine.layers.qlinear.binary.cpp.layer.BinaryLinearCPP method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.html#bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.prepare_params">(bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.html#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.prepare_params">(bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.html#id2">[1]</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.html#bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.prepare_params">(bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.layer.QLinearInf.html#bitorch_engine.layers.qlinear.layer.QLinearInf.prepare_params">(bitorch_engine.layers.qlinear.layer.QLinearInf method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.html#bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.prepare_params">(bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.html#id4">[1]</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.html#bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.prepare_params">(bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.html#id2">[1]</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.html#bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.prepare_params">(bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.html#id2">[1]</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.html#bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.prepare_params">(bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.html#id2">[1]</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.prepare_params">(bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.html#id5">[1]</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.prepare_params">(bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.html#bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.prepare_params">(bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.html#id2">[1]</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.html#bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.privileged_grad">privileged_grad (bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter attribute)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="Q">Q</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.html#bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.q42fp_weight">q42fp_weight() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda method)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.html#id5">(bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda static method)</a>
</li>
      </ul></li>
      <li><a href="_autosummary/bitorch_engine.functions.cuda.functions.q4_pack_tensor.html#bitorch_engine.functions.cuda.functions.q4_pack_tensor">q4_pack_tensor() (in module bitorch_engine.functions.cuda.functions)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.utils.quant_operators.q4_quantization.html#bitorch_engine.utils.quant_operators.q4_quantization">q4_quantization() (in module bitorch_engine.utils.quant_operators)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.functions.cuda.functions.q4_unpack_and_scaling_tensor.html#bitorch_engine.functions.cuda.functions.q4_unpack_and_scaling_tensor">q4_unpack_and_scaling_tensor() (in module bitorch_engine.functions.cuda.functions)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.functions.cuda.functions.q4_unpack_tensor.html#bitorch_engine.functions.cuda.functions.q4_unpack_tensor">q4_unpack_tensor() (in module bitorch_engine.functions.cuda.functions)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.html#bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass">Q4Conv2dCutlass (class in bitorch_engine.layers.qconv.nbit.cutlass.layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward.html#bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlassForward">Q4Conv2dCutlassForward (class in bitorch_engine.layers.qconv.nbit.cutlass.layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.html#bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass">Q4LinearCutlass (class in bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearFunction.html#bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearFunction">Q4LinearFunction (class in bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.html#bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul">Q4MatMul (class in bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMulFunction.html#bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMulFunction">Q4MatMulFunction (class in bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.utils.quant_operators.q8_quantization.html#bitorch_engine.utils.quant_operators.q8_quantization">q8_quantization() (in module bitorch_engine.utils.quant_operators)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.html#bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass">Q8LinearCutlass (class in bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearFunction.html#bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearFunction">Q8LinearFunction (class in bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.html#bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.q_group_map">q_group_map (bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter attribute)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qmha.binary.layer.BMHA.html#bitorch_engine.layers.qmha.binary.layer.BMHA.q_linear">q_linear (bitorch_engine.layers.qmha.binary.layer.BMHA attribute)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.html#bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.q_perm">q_perm (bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter attribute)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.qlinear_implementation.QLinearImplementationMixin.html#bitorch_engine.layers.qlinear.qlinear_implementation.QLinearImplementationMixin">QLinearImplementationMixin (class in bitorch_engine.layers.qlinear.qlinear_implementation)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.layer.QLinearInf.html#bitorch_engine.layers.qlinear.layer.QLinearInf">QLinearInf (class in bitorch_engine.layers.qlinear.layer)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.utils.convert.quantize_linear_with_binary_linear_cuda.html#bitorch_engine.utils.convert.quantize_linear_with_binary_linear_cuda">quantize_linear_with_binary_linear_cuda() (in module bitorch_engine.utils.convert)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.utils.convert.quantize_linear_with_mpq_linear_cuda.html#bitorch_engine.utils.convert.quantize_linear_with_mpq_linear_cuda">quantize_linear_with_mpq_linear_cuda() (in module bitorch_engine.utils.convert)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.utils.convert.quantize_linear_with_q4_linear_cutlass.html#bitorch_engine.utils.convert.quantize_linear_with_q4_linear_cutlass">quantize_linear_with_q4_linear_cutlass() (in module bitorch_engine.utils.convert)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.html#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.qweight">qweight (bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda attribute)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.html#bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.qweight">(bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.html#bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.qweight">(bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.html#bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.qweight">(bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.html#bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.qweight">(bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx attribute)</a>
</li>
      </ul></li>
      <li><a href="_autosummary/bitorch_engine.utils.model_helper.qweight_update_fn.html#bitorch_engine.utils.model_helper.qweight_update_fn">qweight_update_fn() (in module bitorch_engine.utils.model_helper)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="R">R</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.utils.convert.replace_layers.html#bitorch_engine.utils.convert.replace_layers">replace_layers() (in module bitorch_engine.utils.convert)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.html#bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.reset_parameters">reset_parameters() (bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase method)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.html#bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.reset_parameters">(bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.html#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.reset_parameters">(bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.html#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.reset_parameters">(bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.html#bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.reset_parameters">(bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.html#id2">[1]</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.reset_parameters">(bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.html#bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.rows">rows (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda attribute)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.html#bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.rows">(bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter attribute)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="S">S</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.utils.model_helper.save_checkpoint.html#bitorch_engine.utils.model_helper.save_checkpoint">save_checkpoint() (in module bitorch_engine.utils.model_helper)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.html#bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.scale_a">scale_a (bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass attribute)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.html#bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.scale_a">(bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.html#bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.scale_a">(bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.html#bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.scale_a">(bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.html#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.scale_a">(bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.html#bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.scale_a">(bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.html#bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.scale_a">(bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass attribute)</a>
</li>
      </ul></li>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.html#bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.scale_w">scale_w (bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass attribute)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.html#bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.scale_w">(bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.html#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.scale_w">(bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.html#bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.scale_w">(bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.html#bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.scale_w">(bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.html#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.scale_w">(bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.html#bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.scale_w">(bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.html#bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.scale_w">(bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass attribute)</a>
</li>
      </ul></li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.html#bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.scales">scales (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda attribute)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.html#bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.scales">(bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.html#bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.scales">(bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx attribute)</a>
</li>
      </ul></li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.html#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.select_gemm_kernel">select_gemm_kernel() (bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.html#id3">[1]</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.html#bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.set_activation">set_activation() (bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass method)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.html#bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass.set_activation">(bitorch_engine.layers.qconv.nbit.cutlass.layer.Q4Conv2dCutlass method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.html#bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.set_activation">(bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.html#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.set_activation">(bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.html#id4">[1]</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.html#bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.set_activation">(bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4LinearCutlass.html#id3">[1]</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.html#bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.set_activation">(bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q8_layer.Q8LinearCutlass.html#id3">[1]</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul.html#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul.set_activation_scale">set_activation_scale() (bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul method)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.html#bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.set_activation_scale">(bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul method)</a>
</li>
      </ul></li>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.html#bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.set_bits_binary_word">set_bits_binary_word() (bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase method)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.html#bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.set_bits_binary_word">(bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.html#id3">[1]</a>
</li>
      </ul></li>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.html#bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.set_quantized_weight_data">set_quantized_weight_data() (bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase method)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.html#bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.set_quantized_weight_data">(bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.html#bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.set_quantized_weight_data">(bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.html#id4">[1]</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.layer.QLinearInf.html#bitorch_engine.layers.qlinear.layer.QLinearInf.set_quantized_weight_data">(bitorch_engine.layers.qlinear.layer.QLinearInf method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.set_quantized_weight_data">(bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase method)</a>
</li>
      </ul></li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.set_qweight_data">set_qweight_data() (bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.html#id6">[1]</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.html#bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.set_scales">set_scales() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.html#id6">[1]</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.html#bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass.set_weight_data">set_weight_data() (bitorch_engine.layers.qconv.binary.cutlass.layer.BinaryConv2dCutlass method)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.html#bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase.set_weight_data">(bitorch_engine.layers.qconv.binary.layer.BinaryConv2dBase method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.html#bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase.set_weight_data">(bitorch_engine.layers.qconv.nbit.layer.nBitConv2dBase method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.html#bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.set_weight_data">(bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.html#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.set_weight_data">(bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.html#id5">[1]</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.html#bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.set_weight_data">(bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.html#id5">[1]</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.layer.QLinearInf.html#bitorch_engine.layers.qlinear.layer.QLinearInf.set_weight_data">(bitorch_engine.layers.qlinear.layer.QLinearInf method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.set_weight_data">(bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase method)</a>
</li>
      </ul></li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.html#bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.set_zeros">set_zeros() (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda method)</a>, <a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.html#id7">[1]</a>
</li>
      <li><a href="_autosummary/bitorch_engine.optim.diode_beta.DiodeMix.html#bitorch_engine.optim.diode_beta.DiodeMix.step">step() (bitorch_engine.optim.diode_beta.DiodeMix method)</a>, <a href="_autosummary/bitorch_engine.optim.diode_beta.DiodeMix.html#id1">[1]</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.html#bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.symmetric">symmetric (bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase attribute)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="T">T</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.functions.cuda.functions.tensor_to_packed_uint8.html#bitorch_engine.functions.cuda.functions.tensor_to_packed_uint8">tensor_to_packed_uint8() (in module bitorch_engine.functions.cuda.functions)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="U">U</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.utils.model_helper.unflatten_x.html#bitorch_engine.utils.model_helper.unflatten_x">unflatten_x() (in module bitorch_engine.utils.model_helper)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.utils.unpack_qweight.html#bitorch_engine.layers.qlinear.nbit.cuda.utils.unpack_qweight">unpack_qweight() (in module bitorch_engine.layers.qlinear.nbit.cuda.utils)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.functions.cuda.functions.unpack_uint8_tensor.html#bitorch_engine.functions.cuda.functions.unpack_uint8_tensor">unpack_uint8_tensor() (in module bitorch_engine.functions.cuda.functions)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qconv.binary.layer.BinaryConvParameter.html#bitorch_engine.layers.qconv.binary.layer.BinaryConvParameter.update">update() (bitorch_engine.layers.qconv.binary.layer.BinaryConvParameter static method)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qconv.nbit.layer.nBitConvParameter.html#bitorch_engine.layers.qconv.nbit.layer.nBitConvParameter.update">(bitorch_engine.layers.qconv.nbit.layer.nBitConvParameter static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingParameter.html#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingParameter.update">(bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingParameter static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearParameter.html#bitorch_engine.layers.qlinear.binary.layer.BinaryLinearParameter.update">(bitorch_engine.layers.qlinear.binary.layer.BinaryLinearParameter static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.html#bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.update">(bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter static method)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.nBitLinearParameter.html#bitorch_engine.layers.qlinear.nbit.layer.nBitLinearParameter.update">(bitorch_engine.layers.qlinear.nbit.layer.nBitLinearParameter static method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.utils.model_helper.update_zeros.html#bitorch_engine.utils.model_helper.update_zeros">update_zeros() (in module bitorch_engine.utils.model_helper)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.use_gba_quant">use_gba_quant (bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase attribute)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.html#bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.use_mbw">use_mbw (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda attribute)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="V">V</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qmha.binary.layer.BMHA.html#bitorch_engine.layers.qmha.binary.layer.BMHA.v_linear">v_linear (bitorch_engine.layers.qmha.binary.layer.BMHA attribute)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="W">W</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.html#bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.w_bit">w_bit (bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda attribute)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase.w_bit">(bitorch_engine.layers.qlinear.nbit.layer.MPQLinearBase attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.html#bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter.w_bit">(bitorch_engine.layers.qlinear.nbit.layer.MPQWeightParameter attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.html#bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase.w_bit">(bitorch_engine.layers.qlinear.nbit.layer.nBitLinearBase attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.html#bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.w_bit">(bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx attribute)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.html#bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda.w_pack">w_pack() (bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearCuda static method)</a>
</li>
      <li><a href="_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.html#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda.weight">weight (bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingCuda attribute)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.html#bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward.weight">(bitorch_engine.layers.qlinear.binary.cuda.layer.BinaryLinearForward attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.html#bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase.weight">(bitorch_engine.layers.qlinear.binary.layer.BinaryLinearBase attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.layer.QLinearInf.html#bitorch_engine.layers.qlinear.layer.QLinearInf.weight">(bitorch_engine.layers.qlinear.layer.QLinearInf property)</a>
</li>
      </ul></li>
      <li><a href="_autosummary/bitorch_engine.optim.diode_beta.DiodeMix.html#bitorch_engine.optim.diode_beta.DiodeMix.weight_decay">weight_decay (bitorch_engine.optim.diode_beta.DiodeMix attribute)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="X">X</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul.html#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul.x_clip">x_clip (bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul attribute)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.html#bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.x_clip">(bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul attribute)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="Y">Y</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul.html#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul.y_clip">y_clip (bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryMatMul attribute)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.html#bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul.y_clip">(bitorch_engine.layers.qlinear.nbit.cutlass.q4_layer.Q4MatMul attribute)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="Z">Z</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.html#bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.zeros">zeros (bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda attribute)</a>

      <ul>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.html#bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda.zeros">(bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.MPQLinearCuda attribute)</a>
</li>
        <li><a href="_autosummary/bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.html#bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx.zeros">(bitorch_engine.layers.qlinear.nbit.mps.mpq_layer.MPQLinearMlx attribute)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>



           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Haojin Yang, Joseph Bethge, Nianhui Guo, Maximilian Schulze, Hong Guo, Paul Mattes.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>