<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass &mdash; Bitorch Engine 0.2.5 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/sphinx-toolbox-code.css?v=4ee5d529" />
      <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=87e54e7c" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=cb850272"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward" href="bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward.html" />
    <link rel="prev" title="bitorch_engine.layers.qlinear.binary.cutlass.layer" href="bitorch_engine.layers.qlinear.binary.cutlass.layer.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Bitorch Engine
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../build_options.html">Build options</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../documentation.html">Full Documentation</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="bitorch_engine.html">bitorch_engine</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="bitorch_engine.functions.html">bitorch_engine.functions</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="bitorch_engine.layers.html">bitorch_engine.layers</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="bitorch_engine.layers.qconv.html">bitorch_engine.layers.qconv</a></li>
<li class="toctree-l4"><a class="reference internal" href="bitorch_engine.layers.qembedding.html">bitorch_engine.layers.qembedding</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="bitorch_engine.layers.qlinear.html">bitorch_engine.layers.qlinear</a></li>
<li class="toctree-l4"><a class="reference internal" href="bitorch_engine.layers.qmha.html">bitorch_engine.layers.qmha</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="bitorch_engine.optim.html">bitorch_engine.optim</a></li>
<li class="toctree-l3"><a class="reference internal" href="bitorch_engine.utils.html">bitorch_engine.utils</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Bitorch Engine</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../documentation.html">Full Documentation</a></li>
          <li class="breadcrumb-item"><a href="bitorch_engine.html">bitorch_engine</a></li>
          <li class="breadcrumb-item"><a href="bitorch_engine.layers.html">bitorch_engine.layers</a></li>
          <li class="breadcrumb-item"><a href="bitorch_engine.layers.qlinear.html">bitorch_engine.layers.qlinear</a></li>
          <li class="breadcrumb-item"><a href="bitorch_engine.layers.qlinear.binary.html">bitorch_engine.layers.qlinear.binary</a></li>
          <li class="breadcrumb-item"><a href="bitorch_engine.layers.qlinear.binary.cutlass.html">bitorch_engine.layers.qlinear.binary.cutlass</a></li>
          <li class="breadcrumb-item"><a href="bitorch_engine.layers.qlinear.binary.cutlass.layer.html">bitorch_engine.layers.qlinear.binary.cutlass.layer</a></li>
      <li class="breadcrumb-item active">bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/_autosummary/bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="bitorch-engine-layers-qlinear-binary-cutlass-layer-binarylinearcutlass">
<h1>bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass<a class="headerlink" href="#bitorch-engine-layers-qlinear-binary-cutlass-layer-binarylinearcutlass" title="Link to this heading"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bitorch_engine.layers.qlinear.binary.cutlass.layer.</span></span><span class="sig-name descname"><span class="pre">BinaryLinearCutlass</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bitorch_engine/layers/qlinear/binary/cutlass/layer.html#BinaryLinearCutlass"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass" title="Link to this definition"></a></dt>
<dd><p>A specialized binary linear layer that leverages CUTLASS for efficient low-precision computations.</p>
<p>This class extends BinaryLinearBase, incorporating specific optimizations for binary neural networks.
It uses CUTLASS kernels for binary GEMM operations, optimizing the execution on GPUs. The layer supports
both training and inference in binary precision, significantly reducing memory footprint and computational
costs.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.bits_binary_word">
<span class="sig-name descname"><span class="pre">bits_binary_word</span></span><a class="headerlink" href="#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.bits_binary_word" title="Link to this definition"></a></dt>
<dd><p>The bit-width of the binary words used in CUTLASS operations, typically set to 8.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.gemm_kernel_id">
<span class="sig-name descname"><span class="pre">gemm_kernel_id</span></span><a class="headerlink" href="#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.gemm_kernel_id" title="Link to this definition"></a></dt>
<dd><p>Identifier for the CUTLASS kernel to be used for the GEMM operation.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.bias_a">
<span class="sig-name descname"><span class="pre">bias_a</span></span><a class="headerlink" href="#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.bias_a" title="Link to this definition"></a></dt>
<dd><p>Layer-wise bias parameter for input activations.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Parameter</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.scale_a">
<span class="sig-name descname"><span class="pre">scale_a</span></span><a class="headerlink" href="#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.scale_a" title="Link to this definition"></a></dt>
<dd><p>Scale factor for input activations, aiding in quantization.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Parameter</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.scale_w">
<span class="sig-name descname"><span class="pre">scale_w</span></span><a class="headerlink" href="#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.scale_w" title="Link to this definition"></a></dt>
<dd><p>Scale factor for weights, essential for maintaining numerical accuracy.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Parameter</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.prepare_params">
<span class="sig-name descname"><span class="pre">prepare_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bitorch_engine/layers/qlinear/binary/cutlass/layer.html#BinaryLinearCutlass.prepare_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.prepare_params" title="Link to this definition"></a></dt>
<dd><p>Prepares and initializes model parameters for training, converting weights to int8 format.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.generate_quantized_weight">
<span class="sig-name descname"><span class="pre">generate_quantized_weight</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">qweight_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bitorch_engine/layers/qlinear/binary/cutlass/layer.html#BinaryLinearCutlass.generate_quantized_weight"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.generate_quantized_weight" title="Link to this definition"></a></dt>
<dd><p>Performs bit-packing on 32-bit weights to reduce memory usage.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.set_activation">
<span class="sig-name descname"><span class="pre">set_activation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bitorch_engine/layers/qlinear/binary/cutlass/layer.html#BinaryLinearCutlass.set_activation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.set_activation" title="Link to this definition"></a></dt>
<dd><p>Normalizes input activations using layer-wise scale and bias parameters.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.set_weight_data">
<span class="sig-name descname"><span class="pre">set_weight_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bitorch_engine/layers/qlinear/binary/cutlass/layer.html#BinaryLinearCutlass.set_weight_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.set_weight_data" title="Link to this definition"></a></dt>
<dd><p>Prepares the weight data for computation, calling <cite>prepare_params</cite> internally.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.select_gemm_kernel">
<span class="sig-name descname"><span class="pre">select_gemm_kernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bitorch_engine/layers/qlinear/binary/cutlass/layer.html#BinaryLinearCutlass.select_gemm_kernel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.select_gemm_kernel" title="Link to this definition"></a></dt>
<dd><p>Evaluates and selects the appropriate CUTLASS kernel based on input dimensions.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bitorch_engine/layers/qlinear/binary/cutlass/layer.html#BinaryLinearCutlass.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.forward" title="Link to this definition"></a></dt>
<dd><p>Defines the forward pass for the binary linear layer, leveraging CUTLASS for efficient computation.</p>
</dd></dl>

<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.__init__" title="bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.__init__"><code class="xref py py-obj docutils literal notranslate"><span class="pre">__init__</span></code></a></p></td>
<td><p>Initializes the BinaryLinearBase class with specified configurations.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#id0" title="bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a></p></td>
<td><p>Defines the forward pass of the binary linear layer.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#id1" title="bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.generate_quantized_weight"><code class="xref py py-obj docutils literal notranslate"><span class="pre">generate_quantized_weight</span></code></a></p></td>
<td><p>Performs bit-packing on the 32-bit floating-point weights to reduce the model's memory footprint.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#id2" title="bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.prepare_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">prepare_params</span></code></a></p></td>
<td><p>Prepares and initializes the model parameters for training, specifically converting floating-point weights to int8 format.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#id3" title="bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.select_gemm_kernel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">select_gemm_kernel</span></code></a></p></td>
<td><p>Selects the most appropriate GEMM kernel from the available CUTLASS kernels for the binary operation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#id4" title="bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.set_activation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_activation</span></code></a></p></td>
<td><p>Normalizes input activations using a layer-wise scale factor and adds bias.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#id5" title="bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.set_weight_data"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_weight_data</span></code></a></p></td>
<td><p>Prepares the weight data for the binary linear operation.</p></td>
</tr>
</tbody>
</table>
<p class="rubric">Attributes</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">training</span></code></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bitorch_engine/layers/qlinear/binary/cutlass/layer.html#BinaryLinearCutlass.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearCutlass.__init__" title="Link to this definition"></a></dt>
<dd><p>Initializes the BinaryLinearBase class with specified configurations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_features</strong> (<em>int</em>) – Dimension of input features after bit-packing.</p></li>
<li><p><strong>out_features</strong> (<em>int</em>) – Dimension of output features or hidden states.</p></li>
<li><p><strong>device</strong> (<em>torch.device</em><em>, </em><em>optional</em>) – Device on which to allocate tensors. Defaults to None.</p></li>
<li><p><strong>dtype</strong> (<em>torch.dtype</em><em>, </em><em>optional</em>) – Data type for floating-point weights. Defaults to torch.float.</p></li>
<li><p><strong>symmetric</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True, quantization is symmetric around 0. Defaults to True.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id0">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/bitorch_engine/layers/qlinear/binary/cutlass/layer.html#BinaryLinearCutlass.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id0" title="Link to this definition"></a></dt>
<dd><p>Defines the forward pass of the binary linear layer.</p>
<p>This method applies normalization and bias to the input activations, selects the appropriate
GEMM kernel, and performs the binary linear operation using the optimized CUTLASS kernel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – Input tensor with shape (batch size, number of input features).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The output of the binary linear operation, ready for further processing in the network.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id1">
<span class="sig-name descname"><span class="pre">generate_quantized_weight</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">qweight_only</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/bitorch_engine/layers/qlinear/binary/cutlass/layer.html#BinaryLinearCutlass.generate_quantized_weight"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id1" title="Link to this definition"></a></dt>
<dd><p>Performs bit-packing on the 32-bit floating-point weights to reduce the model’s memory footprint.</p>
<p>This method converts the full-precision weights to quantized format, specifically designed for
binary linear operations. It facilitates efficient computation on hardware that supports binary
operations by reducing the weight representation to 8 bits.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>qweight_only</strong> (<em>bool</em>) – If True, the original floating-point weights are discarded to save memory,
leaving only the quantized weights.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The quantized weights are stored as a new parameter <cite>qweight</cite> within the class.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id2">
<span class="sig-name descname"><span class="pre">prepare_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/bitorch_engine/layers/qlinear/binary/cutlass/layer.html#BinaryLinearCutlass.prepare_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id2" title="Link to this definition"></a></dt>
<dd><p>Prepares and initializes the model parameters for training, specifically converting floating-point weights
to int8 format.</p>
<p>This method leverages the <cite>init_weight</cite> function to convert the model’s floating-point weights to int8,
achieving a significant reduction in memory usage. It also computes a scale for the weights, which is essential
for maintaining the numerical fidelity of the model’s computations in the lower precision format. The conversion
to int8 format is particularly beneficial for accelerating training and inference on hardware that supports
lower precision arithmetic.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method MUST be called after model initialization and before training starts to ensure the weights are
properly prepared for efficient computation.</p>
<p>One can use “prepare_bie_layers” method from project_root.utils.model_helper to call this function.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id3">
<span class="sig-name descname"><span class="pre">select_gemm_kernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/bitorch_engine/layers/qlinear/binary/cutlass/layer.html#BinaryLinearCutlass.select_gemm_kernel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id3" title="Link to this definition"></a></dt>
<dd><p>Selects the most appropriate GEMM kernel from the available CUTLASS kernels for the binary operation.</p>
<p>This selection is based on the dimensions of the input activation tensor and the layer’s output features.
The method evaluates available kernels and chooses the optimal one for the given dimensions, enhancing
computational efficiency.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – The input activation tensor used to determine the optimal GEMM kernel.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The ID of the selected GEMM kernel which will be used for subsequent operations.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is intended to be called during the warmup phase of the model, before actual training
or inference begins.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id4">
<span class="sig-name descname"><span class="pre">set_activation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/bitorch_engine/layers/qlinear/binary/cutlass/layer.html#BinaryLinearCutlass.set_activation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id4" title="Link to this definition"></a></dt>
<dd><p>Normalizes input activations using a layer-wise scale factor and adds bias. This method is called
during the forward pass to apply preprocessing to the input activations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – The input activations to the binary linear layer.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The normalized and biased activations ready for the binary linear operation.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The scale factor <cite>scale_a</cite> is dynamically initialized based on the input’s statistical properties
if it has not been set previously.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id5">
<span class="sig-name descname"><span class="pre">set_weight_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bitorch_engine/layers/qlinear/binary/cutlass/layer.html#BinaryLinearCutlass.set_weight_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id5" title="Link to this definition"></a></dt>
<dd><p>Prepares the weight data for the binary linear operation. This method is an extension of the
base class’s method and additionally calls <cite>prepare_params</cite> to ensure that the weights are
properly formatted for efficient computation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – The activation tensor that may influence how weights are prepared.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="bitorch_engine.layers.qlinear.binary.cutlass.layer.html" class="btn btn-neutral float-left" title="bitorch_engine.layers.qlinear.binary.cutlass.layer" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward.html" class="btn btn-neutral float-right" title="bitorch_engine.layers.qlinear.binary.cutlass.layer.BinaryLinearForward" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Haojin Yang, Joseph Bethge, Nianhui Guo, Maximilian Schulze, Hong Guo, Paul Mattes.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>