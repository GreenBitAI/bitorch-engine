<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction &mdash; Bitorch Engine 0.2.5 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/sphinx-toolbox-code.css?v=4ee5d529" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=cb850272"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer" href="bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.html" />
    <link rel="prev" title="bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda" href="bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Bitorch Engine
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../build_options.html">Build options</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../documentation.html">Full Documentation</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="bitorch_engine.html">bitorch_engine</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="bitorch_engine.functions.html">bitorch_engine.functions</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="bitorch_engine.layers.html">bitorch_engine.layers</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="bitorch_engine.layers.qconv.html">bitorch_engine.layers.qconv</a></li>
<li class="toctree-l4"><a class="reference internal" href="bitorch_engine.layers.qembedding.html">bitorch_engine.layers.qembedding</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="bitorch_engine.layers.qlinear.html">bitorch_engine.layers.qlinear</a></li>
<li class="toctree-l4"><a class="reference internal" href="bitorch_engine.layers.qmha.html">bitorch_engine.layers.qmha</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="bitorch_engine.optim.html">bitorch_engine.optim</a></li>
<li class="toctree-l3"><a class="reference internal" href="bitorch_engine.utils.html">bitorch_engine.utils</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Bitorch Engine</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../documentation.html">Full Documentation</a></li>
          <li class="breadcrumb-item"><a href="bitorch_engine.html">bitorch_engine</a></li>
          <li class="breadcrumb-item"><a href="bitorch_engine.layers.html">bitorch_engine.layers</a></li>
          <li class="breadcrumb-item"><a href="bitorch_engine.layers.qlinear.html">bitorch_engine.layers.qlinear</a></li>
          <li class="breadcrumb-item"><a href="bitorch_engine.layers.qlinear.nbit.html">bitorch_engine.layers.qlinear.nbit</a></li>
          <li class="breadcrumb-item"><a href="bitorch_engine.layers.qlinear.nbit.cuda.html">bitorch_engine.layers.qlinear.nbit.cuda</a></li>
          <li class="breadcrumb-item"><a href="bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.html">bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer</a></li>
      <li class="breadcrumb-item active">bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/_autosummary/bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="bitorch-engine-layers-qlinear-nbit-cuda-mbwq-layer-mbwqlinearcudafunction">
<h1>bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction<a class="headerlink" href="#bitorch-engine-layers-qlinear-nbit-cuda-mbwq-layer-mbwqlinearcudafunction" title="Link to this heading"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.</span></span><span class="sig-name descname"><span class="pre">MBWQLinearCudaFunction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bitorch_engine/layers/qlinear/nbit/cuda/mbwq_layer.html#MBWQLinearCudaFunction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction" title="Link to this definition"></a></dt>
<dd><p>Custom CUDA function for performing forward and backward passes in MBWQ Linear layers.</p>
<p>This function supports both forward and backward passes, implemented as static methods.
The forward pass calculates the output of the MBWQ Linear layer based on the input tensor and quantized weights.
The backward pass computes gradients with respect to the input tensor and quantized weights.</p>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction.backward" title="bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction.backward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">backward</span></code></a></p></td>
<td><p>Perform the backward pass of MBWQ Linear layer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction.forward" title="bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a></p></td>
<td><p>Perform the forward pass of MBWQ Linear layer using CUDA.</p></td>
</tr>
</tbody>
</table>
<p class="rubric">Attributes</p>
<table class="autosummary longtable docutils align-default">
<tbody>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction.backward">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">BackwardCFunction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_gradient</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/bitorch_engine/layers/qlinear/nbit/cuda/mbwq_layer.html#MBWQLinearCudaFunction.backward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction.backward" title="Link to this definition"></a></dt>
<dd><p>Perform the backward pass of MBWQ Linear layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ctx</strong> (<em>Any</em>) – Autograd context.</p></li>
<li><p><strong>output_gradient</strong> (<em>torch.Tensor</em>) – Output gradient.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple[torch.Tensor, …]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method is experimental and may not guarantee error-free or consistent behavior.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction.forward">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ctx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qweight</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_mbw</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_train</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scales</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zeros</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q_perm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bits</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">privileged_grad</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q_group_map</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rows</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/bitorch_engine/layers/qlinear/nbit/cuda/mbwq_layer.html#MBWQLinearCudaFunction.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCudaFunction.forward" title="Link to this definition"></a></dt>
<dd><p>Perform the forward pass of MBWQ Linear layer using CUDA.</p>
<p>This method computes the output of a linear layer with mixed binary weight quantization (MBWQ), optimizing the
computation for CUDA-enabled devices. It supports both standard quantization and MBWQ modes, dynamically adjusting
the computation based on the <cite>use_mbw</cite> flag. Additionally, it can operate in both training and inference modes,
indicated by the <cite>is_train</cite> flag.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ctx</strong> (<em>Any</em>) – Autograd context, used for saving variables needed for backward computation.</p></li>
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Input tensor, representing the data that will be processed by the layer.</p></li>
<li><p><strong>qweight</strong> (<em>torch.Tensor</em>) – Quantized weights tensor, which contains the quantized values of the weights used in the layer.</p></li>
<li><p><strong>use_mbw</strong> (<em>bool</em>) – Flag indicating whether to use Mixed Binary Weight Quantization (MBWQ) mode for processing.</p></li>
<li><p><strong>is_train</strong> (<em>bool</em>) – Flag indicating whether the operation is being performed in training mode.</p></li>
<li><p><strong>scales</strong> (<em>torch.Tensor</em>) – Scale factors for quantization.</p></li>
<li><p><strong>zeros</strong> (<em>torch.Tensor</em>) – Zero points for quantization.</p></li>
<li><p><strong>group_size</strong> (<em>int</em>) – The size of groups for group-wise quantization.</p></li>
<li><p><strong>q_perm</strong> (<em>torch.Tensor</em><em>, </em><em>optional</em>) – Permutation tensor for reordering the quantized weights.</p></li>
<li><p><strong>q_group_map</strong> (<em>torch.Tensor</em><em>, </em><em>optional</em>) – Mapping tensor for group-wise quantization.</p></li>
<li><p><strong>rows</strong> (<em>list</em><em>, </em><em>optional</em>) – Contains distribution and permutation information for weights in MBWQ mode.</p></li>
<li><p><strong>bits</strong> (<em>int</em>) – q_weight’s bitwidth.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The output tensor of the forward pass, after processing by the MBWQ Linear layer.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method is specifically optimized for CUDA computation and should be used when performance on CUDA-enabled
devices is a priority. The implementation details and parameter usage may be subject to change as the method is
experimental and optimized for advanced use cases.</p>
</div>
</dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda.html" class="btn btn-neutral float-left" title="bitorch_engine.layers.qlinear.nbit.cuda.mbwq_layer.MBWQLinearCuda" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer.html" class="btn btn-neutral float-right" title="bitorch_engine.layers.qlinear.nbit.cuda.mpq_layer" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Haojin Yang, Joseph Bethge, Nianhui Guo, Maximilian Schulze, Hong Guo, Paul Mattes.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>