<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag &mdash; Bitorch Engine 0.2.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/sphinx-toolbox-code.css" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=938c9ccc"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward" href="bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward.html" />
    <link rel="prev" title="bitorch_engine.layers.qembedding.binary.layer" href="bitorch_engine.layers.qembedding.binary.layer.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Bitorch Engine
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../build_options.html">Build options</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../documentation.html">Full Documentation</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="bitorch_engine.html">bitorch_engine</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="bitorch_engine.functions.html">bitorch_engine.functions</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="bitorch_engine.layers.html">bitorch_engine.layers</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="bitorch_engine.layers.qconv.html">bitorch_engine.layers.qconv</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="bitorch_engine.layers.qembedding.html">bitorch_engine.layers.qembedding</a></li>
<li class="toctree-l4"><a class="reference internal" href="bitorch_engine.layers.qlinear.html">bitorch_engine.layers.qlinear</a></li>
<li class="toctree-l4"><a class="reference internal" href="bitorch_engine.layers.qmha.html">bitorch_engine.layers.qmha</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="bitorch_engine.optim.html">bitorch_engine.optim</a></li>
<li class="toctree-l3"><a class="reference internal" href="bitorch_engine.utils.html">bitorch_engine.utils</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Bitorch Engine</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../documentation.html">Full Documentation</a></li>
          <li class="breadcrumb-item"><a href="bitorch_engine.html">bitorch_engine</a></li>
          <li class="breadcrumb-item"><a href="bitorch_engine.layers.html">bitorch_engine.layers</a></li>
          <li class="breadcrumb-item"><a href="bitorch_engine.layers.qembedding.html">bitorch_engine.layers.qembedding</a></li>
          <li class="breadcrumb-item"><a href="bitorch_engine.layers.qembedding.binary.html">bitorch_engine.layers.qembedding.binary</a></li>
          <li class="breadcrumb-item"><a href="bitorch_engine.layers.qembedding.binary.layer.html">bitorch_engine.layers.qembedding.binary.layer</a></li>
      <li class="breadcrumb-item active">bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/_autosummary/bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="bitorch-engine-layers-qembedding-binary-layer-binaryembeddingbag">
<h1>bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag<a class="headerlink" href="#bitorch-engine-layers-qembedding-binary-layer-binaryembeddingbag" title="Link to this heading"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bitorch_engine.layers.qembedding.binary.layer.</span></span><span class="sig-name descname"><span class="pre">BinaryEmbeddingBag</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bitorch_engine/layers/qembedding/binary/layer.html#BinaryEmbeddingBag"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag" title="Link to this definition"></a></dt>
<dd><p>An binary embedding bag implementation.</p>
<p>This module implements a binarized version of the standard embedding layer,
utilizing boolean weights for embeddings. It is specifically designed for scenarios
requiring binary weight parameters and includes an experimental optimizer for training.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This module is EXPERIMENTAL and not guaranteed to be error-free or always operational.</p>
</div>
<p>Training requires a custom optimizer due to the boolean nature of weight parameters and gradients.</p>
<p>Note on Boolean Weight Representation in PyTorch:</p>
<p>PyTorch represents boolean (bool) type tensors using the Char type, which occupies 8 bits per value.
Thus, despite being boolean in nature, the weights in this implementation are not truly 1-bit weights,
as each boolean value is stored in an 8-bit format. This is important to consider when evaluating
the memory efficiency and computational performance of models using these binary weights.</p>
<p>The boolean weight.shape = (num_embeddings, embedding_dim), which is as same as the standard embedding layers,
with 4x memory reduction by using Char tensor type.</p>
<p>Note on Optimizer Requirements for Boolean Weights:</p>
<p>When both weights and their gradients are of boolean type, the optimizer must employ a specialized
update mechanism. Traditional gradient descent methods cannot be directly applied since boolean
values do not support the typical arithmetic operations involved in weight updates. Instead, the
optimizer should implement logic that decides the binary state of weights based on certain criteria
or rules derived from the boolean gradients. This might involve strategies like flipping the state
of a weight based on the presence or absence of a gradient, or using a voting system across multiple
training steps to determine the change. The development of such an optimizer requires careful
consideration to effectively train models with binary weights while adhering to the limitations
and characteristics of boolean algebra.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_embeddings</strong> (<em>int</em>) – Size of the dictionary of embeddings.</p></li>
<li><p><strong>embedding_dim</strong> (<em>int</em>) – The size of each embedding vector.</p></li>
<li><p><strong>padding_idx</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Specifies a padding index. Embeddings at this index will be zeroed out.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.__init__" title="bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.__init__"><code class="xref py py-obj docutils literal notranslate"><span class="pre">__init__</span></code></a></p></td>
<td><p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.forward" title="bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a></p></td>
<td><p>Computes the binary embedding bag for given input indices.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.reset_parameters" title="bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.reset_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_parameters</span></code></a></p></td>
<td><p>Resets parameters by zeroing out the padding index if specified.</p></td>
</tr>
</tbody>
</table>
<p class="rubric">Attributes</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">training</span></code></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/bitorch_engine/layers/qembedding/binary/layer.html#BinaryEmbeddingBag.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.__init__" title="Link to this definition"></a></dt>
<dd><p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/bitorch_engine/layers/qembedding/binary/layer.html#BinaryEmbeddingBag.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.forward" title="Link to this definition"></a></dt>
<dd><p>Computes the binary embedding bag for given input indices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> (<em>Tensor</em>) – Tensor of indices to fetch embeddings for.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The resulting tensor after applying binary embedding bag logic.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.reset_parameters">
<span class="sig-name descname"><span class="pre">reset_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/bitorch_engine/layers/qembedding/binary/layer.html#BinaryEmbeddingBag.reset_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBag.reset_parameters" title="Link to this definition"></a></dt>
<dd><p>Resets parameters by zeroing out the padding index if specified.</p>
</dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="bitorch_engine.layers.qembedding.binary.layer.html" class="btn btn-neutral float-left" title="bitorch_engine.layers.qembedding.binary.layer" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward.html" class="btn btn-neutral float-right" title="bitorch_engine.layers.qembedding.binary.layer.BinaryEmbeddingBagForward" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Haojin Yang, Joseph Bethge, Nianhui Guo, Maximilian Schulze, Hong Guo, Paul Mattes.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>